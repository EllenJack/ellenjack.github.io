<!doctype html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no">
    
    
    <!--Simple SEO-->

<meta name="description" content="程序员的梦工厂/">


<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">
    <!--Title-->

<title>深入理解Kafka | 小小杰博客</title>

<link rel="alternate" href="/atom.xml" title="小小杰博客" type="application/atom+xml">


<link rel="icon" href="/favicon.ico">

    
<link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/css/pages/post.css">
<link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/thirdParty/highlight/github.css">


    <!--script-->



<!--<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>-->



    
    
</head>
</html>
<body id="normal">
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<style>
    header{ top: 71px; position: absolute!important;}
    #container{padding-top: 151px!important;}
</style>
<div style="position:fixed;z-index:9999;left:0;top:0;width:100%;height:70px;background-color:#e0e0e0;color:#396CA5;border-bottom:1px solid #cecece;text-align:center;line-height:70px;white-space: nowrap;overflow: hidden;text-overflow: ellipsis">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<div id="wrap">
    <header style="position: absolute;">
    <div id="site-meta">
        <a href="/" id="logo">
            <h1 class="title">小小杰博客</h1>
        </a>
        
        <h2 class="subtitle">锦绣前程</h2>
        
    </div>
    <ul id="nav">
        
            <li><a href="/"><i class="fa fa-home"></i>首页</a></li>
        
            <li><a href="/2018/12/15/about/"><i class="fa fa-user"></i>关于我</a></li>
        
            <li><a href="/atom.xml"><i class="fa fa-rss"></i>RSS</a></li>
        
        <li id="search"><a href="javascript:void(0)"><i class="fa fa-search"></i>搜索</a></li>
    </ul>
</header>

    <div id="container">
        
<ul id="sidebar">
    
    
<li class="widget notification">
    <i class="fa fa-bell-o"></i>
    <div>
        
<p>学而时习之，不亦乐乎</p>
    </div>
</li>

    
    
<li class="widget widget-normal category">
    <h3 class="fa fa-th widget-title">分类</h3>
    <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/工具/"><i class="fa" aria-hidden="true">工具</i></a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/工具/Maven/"><i class="fa" aria-hidden="true">Maven</i></a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/docker/"><i class="fa" aria-hidden="true">docker</i></a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/并发编程/"><i class="fa" aria-hidden="true">并发编程</i></a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架/"><i class="fa" aria-hidden="true">框架</i></a><span class="category-list-count">10</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/框架/Spring/"><i class="fa" aria-hidden="true">Spring</i></a><span class="category-list-count">10</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/消息中间件/"><i class="fa" aria-hidden="true">消息中间件</i></a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/消息中间件/Kafka/"><i class="fa" aria-hidden="true">Kafka</i></a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/消息中间件/RabbitMQ/"><i class="fa" aria-hidden="true">RabbitMQ</i></a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link current" href="/categories/随笔/"><i class="fa" aria-hidden="true">随笔</i></a><span class="category-list-count">5</span></li></ul>
</li>


    
    
<li class="widget widget-normal archive">
  <h3 class="fa fa-archive widget-title">时光轴</h3>
    <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/"><i class="fa" aria-hidden="true">四月 2020</i></a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/"><i class="fa" aria-hidden="true">七月 2019</i></a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/"><i class="fa" aria-hidden="true">六月 2019</i></a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/"><i class="fa" aria-hidden="true">三月 2019</i></a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/"><i class="fa" aria-hidden="true">二月 2019</i></a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/"><i class="fa" aria-hidden="true">十二月 2018</i></a><span class="archive-list-count">5</span></li></ul>
</li>


    
    

    
    
<li class="widget widget-normal tags">
  <h3 class="fa fa-tags widget-title">标签云</h3>
  <div class="tagcloud-content">
    
      <a href="/tags/排序/" style="font-size: 0.14rem; color: #69c">排序</a> <a href="/tags/关于我/" style="font-size: 0.14rem; color: #69c">关于我</a> <a href="/tags/事务/" style="font-size: 0.14rem; color: #69c">事务</a> <a href="/tags/类加载/" style="font-size: 0.14rem; color: #69c">类加载</a> <a href="/tags/索引/" style="font-size: 0.14rem; color: #69c">索引</a> <a href="/tags/jvm/" style="font-size: 0.14rem; color: #69c">jvm</a> <a href="/tags/docker/" style="font-size: 0.16rem; color: #4f83b8">docker</a> <a href="/tags/Kafka/" style="font-size: 0.17rem; color: #386da4">Kafka</a> <a href="/tags/Maven/" style="font-size: 0.14rem; color: #69c">Maven</a> <a href="/tags/RabbitMQ/" style="font-size: 0.14rem; color: #69c">RabbitMQ</a> <a href="/tags/Spring/" style="font-size: 0.2rem; color: #0a407c">Spring</a> <a href="/tags/多线程/" style="font-size: 0.18rem; color: #215690">多线程</a>
  </div>
</li>


    
    
<li class="widget widget-normal friends-link">
    <h3 class="fa fa-globe widget-title">友情链接</h3><br>

    
        <a href="http://enjoy.ke.qq.com" class="fa" target="_blank">享学课堂</a>

    
        <a href="http://wuwenliang.net" class="fa" target="_blank">朝·闻·道</a>

    
        <a href="https://pleuvoir.github.io" class="fa" target="_blank">撄而后成</a>

    

</li>


    
</ul>


        <div id="main">
    <article id="post">
        <div id="post-header">

            <h1 id="深入理解Kafka">
                
                深入理解Kafka
                
            </h1>
            <div class="article-meta">
    
    
    <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
        <span>Kafka</span>
    </span>
    
    
    <span class="fa-wrap">
         <i class="fa fa-tags"></i>
        <span class="tags-meta">
            
            Kafka
            
        </span>
    </span>
    
    
    <span class="fa-wrap">
        <i class="fa fa-clock-o"></i>
        <span class="date-meta ">2019/07/03</span>
    </span>
    
    
    
</div>

            
            
        </div>
        
        <div id="post-body">
            <h1 id="深入理解Kafka"><a href="#深入理解Kafka" class="headerlink" title="深入理解Kafka"></a><strong>深入理解Kafka</strong></h1><h2 id="集群的成员关系"><a href="#集群的成员关系" class="headerlink" title="集群的成员关系"></a><strong>集群的成员关系</strong></h2><p>Kafka使用 zookeeper来维护集群成员的信息。每个 broker都有个唯一标识符, 这个标识符可以在配置文件里指定, 也可以自动生成。 在 broker启动的时候, 它通过创建临时节点把自己的 ID注册到 zoo-keeper。 Kafka组件订阅 Zookeeper的/brokers/ids路径(broker在 zookeeper上的注册路径) , 当有 broker加入集群或退出集群时, 这些组件就可以获得通知 。</p>
<p>如果你要启动另一个具有相同 ID的 broker, 会得到一个错误。新 broker会试着进行注册,但不会成功, 因为 zookeeper里已经有一个具有相同 ID的 broker。</p>
<p>在 broker停机、 出现网络分区或长时间垃圾回收停顿时, broker会从 Zookeeper上断开连接, 此时 broker在启动时创建的临时节点会自动从 Zookeeper上移除。 监听 broker列表的Kafka 组件会被告知该 broker已移除。</p>
<p>在关闭 broker时, 它对应的节点也会消失, 不过它的 ID会继续存在于其他数据结构中 。 例如,主题的副本列表里就可能包含这些ID。在完全关闭一个broker之后, 如果使用相同的ID启动另一个全新的 broker, 它会立刻加入集群, 并拥有与旧 broker 相同的分区和主题。</p>
<h2 id="什么是控制器"><a href="#什么是控制器" class="headerlink" title="什么是控制器"></a><strong>什么是控制器</strong></h2><p>控制器其实就是一个 broker, 只不过它除了具有一般 broker的功能之外, 还负责分区首领的选举。 集群里第一个启动的 broker通过在Zookeeper里创建一个临时节点/controuer让自己成为控制器。 其他 broker在启动时也会尝试创建这个节点,不过它们会收到一个“节点已存在”的异常,然后“意识”到控制器节点已存在, 也就是说集群里已经有一个控制器了 。 其他 broker在控制器节点上创建Zookeeperwatch对象,这样它们就可以收到这个节点的变更通知。这种方式可以确保集群里一次只有一个控制器存在。</p>
<p>如果控制器被关闭或者与 Zookeeper断开连接, zookeeper上的临时节点就会消失。 集群里的其他 broker通过 watch对象得到控制器节点消失的通知, 它们会尝试让自己成为新的控制器。 第一个在 Zookeeper里成功创建控制器节点的 broker就会成为新的控制器, 其他节点会收到“节点已存在”的异常,然后在新的控制器节点上再次创建watch对象。</p>
<p>当控制器发现一个 broker已经离开集群,它就知道,那些失去首领的分区需要一个新首领 (这些分区的首领刚好是在这个 broker上)。 控制器遍历这些分区, 并确定谁应该成为新首领 (简单来说就是分区副本列表里的下一个副本) , 然后向所有包含新首领或现有跟随者的 broker发送请求。该请求消息包含了谁是新首领以及谁是分区跟随者的信息。随后,新首领开始处理来自生产者和消费者的情求,而跟随者开始从新首领那里复制消息。</p>
<p>当控制器发现一个 broker加入集群时, 它会使用 broker ID来检査新加入的 broker是否包含现有分区的副本。 如果有, 控制器就把变更通知发送给新加入的 broker和其他 broker, 新 broker上的副本开始从首领那里复制消息。</p>
<p>简而言之, Kafka使用 Zookeeper的临时节点来选举控制器,并在节点加入集群或退出集群时通知控制器。 控制器负责在节点加入或离开集群时进行分区首领选举。 </p>
<h2 id="复制-Kafka的核心"><a href="#复制-Kafka的核心" class="headerlink" title="复制-Kafka的核心"></a><strong>复制-Kafka的核心</strong></h2><p>复制功能是 Kafka架构的核心。在 Kafka的文档里, Kafka把自己描述成“一个分布式的、可分区的、可复制的提交日志服务”。复制之所以这么关键,是因为它可以在个别节点失效时仍能保证 Kafka的可用性和持久性。</p>
<p>Kafka使用主题来组织数据, 每个主题被分为若干个分区,每个分区有多个副本。那些副本被保存在 broker上, 每个 broker可以保存成百上千个属于不同主题和分区的副本。</p>
<h3 id="副本类型。"><a href="#副本类型。" class="headerlink" title="副本类型。"></a><strong>副本类型。</strong></h3><h4 id="首领副本"><a href="#首领副本" class="headerlink" title="首领副本"></a><strong>首领副本</strong></h4><p>每个分区都有一个首领副本。为了保证一致性,所有生产者请求和消费者请求都会经过这个副本 。</p>
<h4 id="跟随者副本"><a href="#跟随者副本" class="headerlink" title="跟随者副本"></a><strong>跟随者副本</strong></h4><p>首领以外的副本都是跟随者副本。跟随者副本不处理来自客户端的请求,它们唯一一的任务就是从首领那里复制消息, 保持与首领一致的状态 。 如果首领发生崩溃, 其中的一个跟随者会被提升为新首领 。</p>
<h3 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a><strong>工作机制</strong></h3><p>首领的另一个任务是搞清楚哪个跟随者的状态与自己是一致的。 跟随者为了保持与首领的状态一致，在有新消息到达时尝试从首领那里复制消息, 不过有各种原因会导致同步失败。例如,网络拥塞导致复制变慢, broker发生崩演导致复制滞后,直到重启broker后复制才会继续。</p>
<p>为了与首领保持同步, 跟随者向首领发送获取数据的请求, 这种请求与消费者为了读取消息而发送的请求是一样的。首领将响应消息发给跟随者。请求消息里包含了跟随者想要获取消息的偏移量, 而且这些偏移量总是有序的 。</p>
<p>一个跟随者副本先请求消息1,接着请求消息2,然后请求消息3,在收到这3个请求的响应之前,它是不会发送第4个请求消息的。如果跟随者发送了请求消息4,那么首领就知道它已经收到了前面3个请求的响应。 通过査看每个跟随者请求的最新偏移量, 首领就会知道每个跟随者复制的进度。如果跟随者在10s内没有请求任何消息,或者虽然在请求消息,但在10s内没有请求最新的数据,那么它就会被认为是不同步的。如果一个副本无法与首领保持一致,在首领发生失效时,它就不可能成为新首领，因为它没有包含全部的消息。</p>
<p>相反,持续请求得到的最新消息副本被称为同步副本。在首领发生失效时,只有同步副本才有可能被选为新首领。</p>
<p>跟随者的正常不活跃时间或在成为不同步副本之前的时间可以通过replica.lag.time.max.ms参数来配置的。 这个时间间隔直接影响着首领选举期间的客户端行为和数据保留机制 。</p>
<p>除了当前首领之外, 每个分区都有一个优先副本（首选首领），创建主题时选定的首领分区就是分区的优先副本。 之所以把它叫作优先副本, 是因为在创建分区时, 需要在 broker之间均衡首领副本。 因此, 我们希望首选首领在成为真正的首领时, broker间的负载最终会得到均衡。 默认情况下, Kafka的 auto.leader.rebalance.enable被设为 true,它会检査优先副本是不是当前首领,如果不是,并且该副本是同步的, 那么就会触发首领选举, 让优先副本成为当前首领。</p>
<h2 id="处理请求的内部机制"><a href="#处理请求的内部机制" class="headerlink" title="处理请求的内部机制"></a><strong>处理请求的内部机制</strong></h2><p>broker的大部分工作是处理客户端、分区副本和控制器发送给分区首领的请求。 Kafka提供了一个二进制协议(基于TCP),指定了请求消息的格式以及 broker如何对请求作出响应——包括成功处理请求或在处理请求过程中遇到错误。</p>
<p>客户端发起连接并发送请求,broker处理请求并作出响应。 broker按照请求到达的顺序来处理它们这种顺序保证让Kaka具有了消息队列的特性,同时保证保存的消息也是有序的。</p>
<p>所有的请求消息都包含一个标准消息头:</p>
<p>Request type(也就是 API key)</p>
<p>Request version( broker可以处理不同版本的客户端请求,并根据客户端版本作出不同的响应)</p>
<p>Correlation id-一个具有唯一性的数字,用于标识请求消息,同时也会出现在响应消息和错误日志里(用于诊断问题)</p>
<p>Client Id用于标识发送请求的客户端</p>
<p>broker会在它所监听的每一个端口上运行一个 Acceptor线程,这个线程会创建一个连接并把它交给 Processor线程去处理。 Processor线程(也被叫作“网络线程”)的数量是可配置的。网络线程负责从客户端获取请求消息,把它们放进请求队列,然后从响应队列获取响应消息,把它们发送给客户端。</p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4m17ddbn9j30bg0akq4e.jpg" alt="img"> </p>
<p>请求消息被放到请求队列后,IO线程会负责处理它们。比较常见的请求类型有：</p>
<p>生产请求：生产者发送的请求,它包含客户端要写入 broker的消息。</p>
<p>获取请求：在消费者和跟随者副本需要从 broker读取消息时发送的请求。</p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4m17cjhafj30iy0hbadk.jpg" alt="img"> </p>
<p>生产请求和获取请求都必须发送给分区的首领副本。如果broker 收到一个针对特定分区的请求，而该分区的首领在另一个broker 上，那么发送请求的客户端会收到一个“非分区首领”的错误响应。当针对特定分区的获取请求被发送到一个不含有该分区首领的broker上，也会出现同样的错误。Kafka 客户端要自己负责把生产请求和获取请求发送到正确的broker 上。</p>
<p>那么客户端怎么知道该往哪里发送请求呢？客户端使用了另一种请求类型，也就是元数据请求。这种请求包含了客户端感兴趣的主题列表。服务器端的响应消息里指明了这些主题所包含的分区、每个分区都有哪些副本， 以及哪个副本是首领。元数据请求可以发送给任意一个broker ，因为所有broker 都缓存了这些信息。</p>
<p>一般情况下，客户端会把这些信息缓存起来，并直接往目标broker 上发送生产请求和获取请求。它们需要时不时地通过发送元数据请求来刷新这些信息（刷新的时间间隔通过meta.max.age.ms参数来配置），从而知道元数据是否发生了变更, 比如，在新broker 加入集群时，部分副本会被移动到新的broker 上。另外，如果客户端收到“非首领”错误，它会在尝试重发请求之前先刷新元数据，因为这个错误说明了客户端正在使用过期的元数据信息，之前的请求被发到了错误的broker 上。</p>
<h4 id="生产请求"><a href="#生产请求" class="headerlink" title="生产请求"></a><strong>生产请求</strong></h4><p>我们曾经说过， acks这个配置参数，该参数指定了需要多少个 broker确认才可以认为一个消息写入是成功的。不同的配置对“写入成功”的界定是不一样的,如果acks=1,那么只要首领收到消息就认为写入成功;如果acks=all,那么需要所有同步副本收到消息才算写入成功; 如果 acks=0, 那么生产者在把消息发出去之后, 完全不需要等待 broker的响应。</p>
<p>包含首领副本的 broker在收到生产请求时, 会对请求做一些验证。</p>
<p>•  发送数据的用户是否有主题写入权限?</p>
<p>  请求里包含的acks值是否有效(只允许出现0、1或all) ?</p>
<p>  如果 acks=all, 是否有足够多的同步副本保证消息已经被安全写入? </p>
<p>之后,消息被写入本地磁盘。在Linux系统上,消息会被写到文件系统缓存里,并不保证它们何时会被刷新到磁盘上。Kafka不会一直等待数据被写到磁盘上，它依赖复制功能来保证消息的持久性。</p>
<p>在消息被写入分区的首领之后, broker开始检査 acks配置参数一如果 acks被设为 0或1, 那么 broker立即返回响应;如果 acks被设为 all,那么请求会被保存在一个叫作炼狱的缓冲区里, 直到首领发现所有跟随者副本都复制了消息, 响应才会被返回给客户端。</p>
<h4 id="获取请求"><a href="#获取请求" class="headerlink" title="获取请求"></a><strong>获取请求</strong></h4><p>broker处理获取请求的方式与处理生产请求的方式很相似。客户端发送请求,向 broker请求主题分区里具有特定偏移量的消息, 好像在说: “请把主题 Test分区 0偏移量从53开始的消息以及主题 Test分区3偏移量从64开始的消息发给我。”客户端还可以指定 broker最多可以从一个分区里返回多少数据。 这个限制是非常重要的, 因为客户端需要为 broker返回的数据分配足够的内存。 如果没有这个限制, broker返回的大量数据有可能耗尽客户端的内存。</p>
<p>我们之前讨论过,请求需要先到达指定的分区首领上,然后客户端通过査询元数据来确保请求的路由是正确的。首领在收到请求时,它会先检査请求是否有效，比如,指定的偏移量在分区上是否存在?如果客户端请求的是已经被删除的数据,或者请求的偏移量不存在, 那么 broker将返回一个错误。</p>
<p>如果请求的偏移量存在, broker将按照客户端指定的数量上限从分区里读取消息, 再把消息返回给客户端。 Kafka使用零复制技术向客户端发送消息一一也就是说, Kafka直接把消息从文件(或者更确切地说是 Linux文件系统缓存)里发送到网络通道,而不需要经过任何中间缓冲区。 这是 Kafka与其他大部分数据库系统不一样的地方, 其他数据库在将数据发送给客户端之前会先把它们保存在本地缓存里。 这项技术避免了字节复制, 也不需要管理内存缓冲区, 从而获得更好的性能。</p>
<p>客户端除了可以设置 broker返回数据的上限, 也可以设置下限。 例如, 如果把下限设置为10KB,就好像是在告诉broker:“等到有10KB数据的时候再把它们发送给我。”在主题消息流量不是很大的情况下,这样可以减少 CPU和网络开销。 客户端发送一个请求, broker 等到有足够的数据时才把它们返回给客户端, 然后客户端再发出情求, 而不是让客户端每隔几毫秒就发送一次请求,每次只能得到很少的数据甚至没有数据。对比这两种情况, 它们最终读取的数据总量是一样的, 但前者的来回传送次数更少, 因此开销也更小。</p>
<p> <img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4m179vhrhj30jm07x0u9.jpg" alt="img"></p>
<p>当然,我们不会让客户端一直等待broker累积数据。在等待了一段时间之后,就可以把可用的数据拿回处理,而不是一直等待下去。所以,客户端可以定义一个超时时间,告诉 broker: “如果你无法在 K毫秒内累积满足要求的数据量, 那么就把当前这些数据返回给我。”</p>
<h4 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a><strong>ISR</strong></h4><p>并不是所有保存在分区首领上的数据都可以被客户端读取。大部分客户端只能读取已经被写入所有同步副本的消息。 分区首领知道每个消息会被复制到哪个副本上, 在消息还没有被写入所有同步副本之前, 是不会发送给消费者的，尝试获取这些消息的请求会得到空的响应而不是错误。</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4m17edgrlj30py08uwhb.jpg" alt="img"> </p>
<p>因为还没有被足够多副本复制的消息被认为是“不安全”的，如果首领发生崩横,另一 个副本成为新首领,那么这些消息就丢失了。如果我们允许消费者读取这些消息,可能就会破坏一致性。试想, 一个消费者读取并处理了这样的一个消息,而另一个消费者发现这个消息其实并不存在。所以,我们会等到所有同步副本复制了这些消息,才允许消费者读取它们。这也意味着,如果broker间的消息复制因为某些原因变慢,那么消息到达消费者的时间也会随之变长 (因为我们会先等待消息复制完毕) 。延迟时间可以通过参数replica. lag. time. max. ms来配置, 它指定了副本在复制消息时可被允许的最大延迟时间。</p>
<p>Kafka的数据复制是以Partition为单位的。而多个备份间的数据复制，通过Follower向Leader拉取数据完成。从一这点来讲，有点像Master-Slave方案。不同的是，Kafka既不是完全的同步复制，也不是完全的异步复制，而是基于ISR的动态复制方案。</p>
<p>ISR，也即In-Sync Replica。每个Partition的Leader都会维护这样一个列表，该列表中，包含了所有与之同步的Replica（包含Leader自己）。每次数据写入时，只有ISR中的所有Replica都复制完，Leader才会将其置为Commit，它才能被Consumer所消费。</p>
<p>这种方案，与同步复制非常接近。但不同的是，这个ISR是由Leader动态维护的。如果Follower不能紧“跟上”Leader，它将被Leader从ISR中移除，待它又重新“跟上”Leader后，会被Leader再次加加ISR中。每次改变ISR后，Leader都会将最新的ISR持久化到Zookeeper中。</p>
<p>至于如何判断某个Follower是否“跟上”Leader，不同版本的Kafka的策略稍微有些区别。</p>
<p>从0.9.0.0版本开始，replica.lag.max.messages被移除，故Leader不再考虑Follower落后的消息条数。另外，Leader不仅会判断Follower是否在replica.lag.time.max.ms时间内向其发送Fetch请求，同时还会考虑Follower是否在该时间内与之保持同步。</p>
<h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4m17dt7b0j30lr0b0acm.jpg" alt="img"> </p>
<p>在第一步中，Leader A总共收到3条消息，但由于ISR中的Follower只同步了第1条消息（m1），故只有m1被Commit，也即只有m1可被Consumer消费。此时Follower B与Leader A的差距是1，而Follower C与Leader A的差距是2，虽然有消息的差距，但是满足同步副本的要求保留在ISR中。同步副本概念参见<a href="#_复制">《复制》</a></p>
<p>在第二步中，由于旧的Leader A宕机，新的Leader B在replica.lag.time.max.ms时间内未收到来自A的Fetch请求，故将A从ISR中移除，此时ISR={B，C}。同时，由于此时新的Leader B中只有2条消息，并未包含m3（m3从未被任何Leader所Commit），所以m3无法被Consumer消费。</p>
<h5 id="使用ISR方案的原因"><a href="#使用ISR方案的原因" class="headerlink" title="使用ISR方案的原因"></a>使用ISR方案的原因</h5><p>由于Leader可移除不能及时与之同步的Follower，故与同步复制相比可避免最慢的Follower拖慢整体速度，也即ISR提高了系统可用性。</p>
<p>ISR中的所有Follower都包含了所有Commit过的消息，而只有Commit过的消息才会被Consumer消费，故从Consumer的角度而言，ISR中的所有Replica都始终处于同步状态，从而与异步复制方案相比提高了数据一致性。</p>
<h5 id="ISR相关配置说明"><a href="#ISR相关配置说明" class="headerlink" title="ISR相关配置说明"></a>ISR相关配置说明</h5><p>Broker的min.insync.replicas参数指定了Broker所要求的ISR最小长度，默认值为1。也即极限情况下ISR可以只包含Leader。但此时如果Leader宕机，则该Partition不可用，可用性得不到保证。</p>
<p>只有被ISR中所有Replica同步的消息才被Commit，但Producer发布数据时，Leader并不需要ISR中的所有Replica同步该数据才确认收到数据。Producer可以通过acks参数指定最少需要多少个Replica确认收到该消息才视为该消息发送成功。acks的默认值是1，即Leader收到该消息后立即告诉Producer收到该消息，此时如果在ISR中的消息复制完该消息前Leader宕机，那该条消息会丢失。而如果将该值设置为0，则Producer发送完数据后，立即认为该数据发送成功，不作任何等待，而实际上该数据可能发送失败，并且Producer的Retry机制将不生效。更推荐的做法是，将acks设置为all或者-1，此时只有ISR中的所有Replica都收到该数据（也即该消息被Commit），Leader才会告诉Producer该消息发送成功，从而保证不会有未知的数据丢失。</p>
<h2 id="物理存储机制"><a href="#物理存储机制" class="headerlink" title="物理存储机制"></a><strong>物理存储机制</strong></h2><p>Kafka的基本存储单元是分区。分区无法在多个broker间进行再细分,也无法在同一个broker的多个磁盘上进行再细分。</p>
<p>在配置 Kafka的时候, 管理员指定了一个用于存储分区的目录清单——也就是log.dirs参数的值 (不要把它与存放错误日志的目录混淆了, 日志目录是配置在1og4j.properties文件里的)。 该参数一般会包含每个挂载点的目录。</p>
<h3 id="分区分配"><a href="#分区分配" class="headerlink" title="分区分配"></a><strong>分区分配</strong></h3><p>在创建主题时, Kafka首先会决定如何在 broker间分配分区。假设你有6个 broker, 打算创建一个包含10个分区的主题,并且复制系数为3。那么 Kafka就会有30个分区副本, 它们可以被分配给6个 broker。 在进行分区分配时, 我们要达到如下的目标。</p>
<p>•  在 broker间平均地分布分区副本。对于我们的例子来说, 就是要保证每个 broker可以分到5个副本。</p>
<p>•  确保每个分区的每个副本分布在不同的 broker上。假设分区 0的首领副本在 broker2上,,那么可以把跟随者副本放在 broker3和 broker4上, 但不能放在 broker2上,也不能两个都放在 broker3上。</p>
<p>•  如果为 broker指定了机架信息,那么尽可能把每个分区的副本分配到不同机架的 broker上 。 这样做是为了保证一个机架的不可用不会导致整体的分区不可用 。</p>
<p>为了实现这个目标, 我们先随机选择一个 broker(假设是4) , 然后使用轮询的方式给每个 broker分配分区来确定首领分区的位置。于是,首领分区 0会在 broker4上,首领分区l会在 broker5上, 首领分区2会在 broker 0上(只有6个 broker), 并以此类推。然后, 我们从分区首领开始,依次分配跟随者副本。如果分区 0的首领在broker4上,那么它的第一个跟随者副本会在 broker5上,第二个跟随者副本会在 broker 0上。分区1的首领在broker5上,那么它的第一个跟随者副本在 broker0上,第二个跟随者副本在 broker1上。</p>
<p>为分区和副本选好合适的 broker之后, 接下来要决定这些分区应该使用哪个目录。 我们单独为每个分区分配目录, 规则很简单: 计算每个目录里的分区数量, 新的分区总是被添加到数量最小的那个目录里。 也就是说, 如果添加了一个新磁量, 所有新的分区都会被创建到这个磁盘上。因为在完成分配工作之前,新磁盘的分区数量总是最少的。</p>
<h3 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a><strong>文件管理</strong></h3><p>保留数据是 Kafka的一个基本特性, Kafka不会一直保留数据, 也不会等到所有消费者都读取了消息之后才删除消息。 相反, Kafka管理员为每个主题配置了数据保留期限, 规定数据被删除之前可以保留多长时间, 或者清理数据之前可以保留的数据量大小 。</p>
<p>因为在一个大文件里査找和删除消息是很费时的, 也很容易出错, 所以分区分成若干个片段。默认情况下,每个片段包含1GB或一周的数据,以较小的那个为准。在broker 往分区写入数据时,如果达到片段上限,就关闭当前文件,并打开一个新文件。</p>
<p>当前正在写入数据的片段叫作活跃片段。 活动片段永远不会被删除, 所以如果你要保留数据1天,但片段里包含了5天的数据,那么这些数据会被保留5天,因为在片段被关闭之前这些数据无法被删除。如果你要保留数据一周,而且每天使用一个新片段,那么你就会看到,每天在使用一个新片段的同时会删除一个最老的片段一所以大部分时间该分区会有7个片段存在。</p>
<h3 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a><strong>文件格式</strong></h3><p>Kafka的消息和偏移量保存在文件里。保存在磁盘上的数据格式与从生产者发送过来或者发送给消费者的消息格式是一样的 。 因为使用了相同的消息格式进行磁盘存储和网络传输, Kafka可以使用零复制技术给消费者发送消息, 同时避免了对生产者已经压缩过的消息进行解压和再圧缩。</p>
<p>除了键、值和偏移量外,消息里还包含了消息大小、校验和、消息格式版本号、压缩算法(snappy、 Gzip或Lz4)和时间戳(在0.10.0版本里引入的)。时间戳可以是生产者发送消息的时间, 也可以是消息到达 broker的时间, 这个是可配置的。</p>
<p>如果生产者发送的是圧缩过的消息, 那么同一个批次的消息会被压缩在一起, 被当作 “包装消息”进行发送。于是, broker就会收到一个这样的消息,然后再把它发送给消费者。 消费者在解压这个消息之后, 会看到整个批次的消息, 它们都有自己的时间戳和偏移量。</p>
<p>如果在生产者端使用了压缩功能(极力推荐),那么发送的批次越大,就意味着在网络传输和磁盘存储方面会获得越好的压缩性能, 同时意味着如果修改了消费者使用的消息格式 (例如, 在消息里增加了时间戳) , 那么网络传输和磁盘存储的格式也要随之修改, 而且 broker要知道如何处理包含了两种消息格式的文件。</p>
<p>Kafka附带了一个叫 DumpLogSegment的工具, 可以用它査看片段的内容。 它可以显示每个消息的偏移量、校验和、魔术数字节、消息大小和压缩算法。</p>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a><strong>索引</strong></h3><p>消费者可以从Kafka的任意可用偏移量位置开始读取消息。假设消费者要读取从偏移量100开始的1MB消息,那么 broker必须立即定位到偏移量100(可能是在分区的任意一个片段里), 然后开始从这个位置读取消息。为了帮助 broker更快地定位到指定的偏移量, Kafka 为每个分区维护了一个索引。索引把偏移量映射到片段文件和偏移量在文件里的位置。</p>
<p>索引也被分成片段, 所以在删除消息时, 也可以删除相应的索引 。 Kafka不维护索引的校验和。 如果索引出现损坏, Kafka会通过重新读取消息并录制偏移量和位置来重新生成索引。 如果有必要, 管理员可以删除索引, 这样做是绝对安全的, Kafka会自动重新生成这些索引 。</p>
<h3 id="超时数据的清理机制"><a href="#超时数据的清理机制" class="headerlink" title="超时数据的清理机制"></a><strong>超时数据的清理机制</strong></h3><p>一般情况下, Kafka会根据设置的时间保留数据,把超过时效的旧数据删除掉。不过,试想一下这样的场景,如果你使用 Kafka保存客户的收货地址,那么保存客户的最新地址比保存客户上周甚至去年的地址要有意义得多,这样你就不用担心会用错旧地址,而且短时间内客户也不会修改新地址。另外一个场景, 一个应用程序使用 Kafka保存它的状态,每次状态发生变化,它就把状态写入 Kafka。在应用程序从崩演中恢复时,它从Kafka读取消息来恢复最近的状态。在这种情况下,应用程序只关心它在崩粉前的那个状态,而不关心运行过程中的那些状态。</p>
<p>Kafka通过改变主题的保留策略来满足这些使用场景 。 早于保留时间的事件会被删除, 为每个键保留最新的值, 从而达到清理的效果</p>
<p>每个日志片段可以分为以下两个部分 。</p>
<p><strong>干净的部分</strong>，这些消息之前被清理过, 每个键只有一个对应的值, 这个值是上一次清理时保留下来的。 <strong>污浊的部分</strong>，这些消息是在上一次清理之后写入的。</p>
<p>为了清理分区, 清理线程会读取分区的污独部分, 并在内存里创建一个 map。 map里的每个元素包含了消息键的散列值和消息的偏移量,键的散列值是16B,加上偏移量总共是24B。如果要清理一个1GB的日志片段,并假设每个消息大小为1KB,那么这个片段就包含_一百万个消息,而我们只需要用24MB的 map就可以清理这个片段。 (如果有重复的键, 可以重用散列项, 从而使用更少的内存。) </p>
<p>清理线程在创建好偏移量map后,开始从干净的片段处读取消息,从最旧的消息开始,把它们的内容与 map里的内容进行比对。它会检査消息的键是否存在于 map中, 如果不存在, 那么说明消息的值是最新的,就把消息复制到替換片段上。如果键已存在,消息会被忽略, 因为在分区的后部已经有一个具有相同键的消息存在。在复制完所有的消息之后,我们就将替換片段与原始片段进行交换,然后开始清理下一个片段。完成整个清理过程之后,每个键对应一个不同的消息一这些消息的值都是最新的。 清理前后的分区片段如图所示。</p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4m17c08awj30j30b61kx.jpg" alt="img"> </p>
<h1 id="可靠的数据传递"><a href="#可靠的数据传递" class="headerlink" title="可靠的数据传递"></a><strong>可靠的数据传递</strong></h1><h2 id="Kafka提供的可靠性保证和架构上的权衡"><a href="#Kafka提供的可靠性保证和架构上的权衡" class="headerlink" title="Kafka提供的可靠性保证和架构上的权衡"></a><strong>Kafka提供的可靠性保证和架构上的权衡</strong></h2><p>可靠性时，我们一般会使用保证这个词，它是指确保系统在各种不同的环境下能够发生一致的行为。</p>
<p>ACID 大概是大家最熟悉的一个例子，它是关系型数据库普遍支持的标准可靠性保证。ACID 指的是原子性、一致性、隔离性和持久性。如果一个供应商说他们的数据库遵循ACID 规范，其实就是在说他们的数据库支持与事务相关的行为。</p>
<p>有了这些保证，我们才能相信关系型数据库的事务特性可以确保应用程序的安全。我们知道系统承诺可以做到些什么，也知道在不同条件下它们会发生怎样的行为。我们了解这些保证机制，井基于这些保证机制开发安全的应用程序。</p>
<p>所以，了解系统的保证机制对于构建可靠的应用程序来说至关重要，这也是能够在不同条件下解释系统行为的前提。那么Kafka 可以在哪些方面作出保证呢？</p>
<p>• Kafka 可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且消息B 在消息A 之后写入，那么Kafka 可以保证消息B 的偏移量比消息A 的偏移量大，而且消费者会先读取消息A 再读取消息B 。</p>
<p>• 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“ 已提交”的。生产者可以选择接收不同类型的确认，比如在消息被完全提交时的确认，或者在消息被写入首领副本时的确认，或者在消息被发送到网络时的确认。</p>
<p>• 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失。消费者只能读取已经提交的消息。</p>
<p>这些基本的保证机制可以用来构建可靠的系统，但仅仅依赖它们是无法保证系统完全可靠的。构建一个可靠的系统需要作出一些权衡， Kafka 管理员和开发者可以在配置参数上作出权衡，从而得到他们想要达到的可靠性。这种权衡一般是指消息存储的可靠性和一致性的重要程度与可用性、高吞吐量、低延迟和硬件成本的重要程度之间的权衡。</p>
<h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a><strong>复制</strong></h2><p>Kafka 的复制机制和分区的多副本架构是Kafka 可靠性保证的核心。把消息写入多个副本可以使Kafka 在发生崩愤时仍能保证消息的持久性。</p>
<p>回顾一下主要内容：</p>
<p>Kafka 的主题被分为多个分区，分区是基本的数据块。分区存储在单个磁盘上， Kafka 可以保证分区里的事件是有序的，分区可以在线（可用），也可以离线（不可用） 。每个分区可以有多个副本，其中一个副本是首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其他副本只需要与首领保持同步，并及时复制最新的事件。当首领副本不可用时，其中一个同步副本将成为新首领。</p>
<p>分区首领是同步副本，而对于跟随者副本来说，它需要满足以下条件才能被认为是同步的。</p>
<p>•与Zoo keeper 之间有一个活跃的会话，也就是说，它在过去的6秒（可配置）内向Zoo keeper 发送过心跳。</p>
<p>• 在过去的10s 内（可配置）从首领那里获取过消息。</p>
<p>• 在过去的10s 内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，它还必须是儿乎零延迟的。</p>
<p>如果跟随者副本不能满足以上任何一点，比如与Zookeep er 断开连接，或者不再获取新消息，或者获取消息滞后了10s 以上，那么它就被认为是不同步的。一个不同步的副本通过与Zookeeper 重新建立连接，井从首领那里获取最新消息，可以重新变成同步的。这个过程在网络出现临时问题井很快得到修复的情况下会很快完成，但如果broker 发生崩愤就需要较长的时间。</p>
<p><strong>注意</strong>：如果一个或多个副本在同步和非同步状态之间快速切换，说明集群内部出现了问题，通常是Java 不恰当的垃圾回收配置导致的。不恰当的垃圾回收配置会造成几秒钟的停顿，从而让broker 与Zoo keeper 之间断开连接，最后变成不同步的，进而发生状态切换。</p>
<h2 id="Broker配置对可靠性的影响"><a href="#Broker配置对可靠性的影响" class="headerlink" title="Broker配置对可靠性的影响"></a><strong>Broker配置对可靠性的影响</strong></h2><h3 id="复制系数"><a href="#复制系数" class="headerlink" title="复制系数"></a><strong>复制系数</strong></h3><p>主题级别的配置参数是replication.factor，而在b roker 级别则可以通过default. replication.factor来配置自动创建的主题。</p>
<p>Kafka 的默认复制系数就是3，不过用户可以修改它。</p>
<p>如果复制系数为N，那么在凡l 个broker 失效的情况下，仍然能够从主题读取数据或向主题写入数据。所以，更高的复制系数会带来更高的可用性、可靠性和更少的故障。另一方面，复制系数N 需要至少N 个broker ，而且会有N 个数据副本，也就是说它们会占用N倍的磁盘空间。我们一般会在可用性和存储硬件之间作出权衡。</p>
<p>那么该如何确定一个主题需要几个副本呢？这要看主题的重要程度，以及你愿意付出多少成本来换取可用性。。</p>
<p>如果因broker 重启导致的主题不可用是可接受的（这在集群里是很正常的行为），那么把复制系数设为1就可以了。在作出这个权衡的时候，要确保这样不会对你的组织和用户造成影响，因为你在节省了硬件成本的同时也降低了可用性。复制系数为2 意味着可以容忍1 个broker 发生失效，看起来已经足够了。不过要记住，有时候1 个broker 发生失效会导致集群不稳定（通常是旧版的Kafka ），迫使你重启另一个broker－一集群控制器。也就是说，如果将复制系数设为2 ，就有可能因为重启等问题导致集群不可用。</p>
<p>基于以上几点原因，在要求可用性的场景里把复制系数设为3 。在大多数情况下，这已经足够安全了，不过要求更可靠时，可以设为更高，比如我5 个副本，以防不测。</p>
<p>副本的分布也很重要。默认情况下， Kafka 会确保分区的每个副本被放在不同的broker 上。不过，有时候这样仍然不够安全。如果这些broker 处于同一个机架上， 一旦机架的交换机发生故障，分区就会不可用，这时候把复制系数设为多少都不管用。为了避免机架级别的故障，我们建议把broker 分布在多个不同的机架上。</p>
<h3 id="不完全的首领选举"><a href="#不完全的首领选举" class="headerlink" title="不完全的首领选举"></a><strong>不完全的首领选举</strong></h3><p>unclean.leader.election 只能在broker 级别（实际上是在集群范围内）进行配置， 它的默认值是true。</p>
<p>当分区首领不可用时， 一个同步副本会被选为新首领。如果在选举过程中没有丢失数据，也就是说提交的数据同时存在于所有的同步副本上，那么这个选举就是“完全”的。</p>
<p>但如果在首领不可用时其他副本都是不同步的，我们该怎么办呢？</p>
<p>这种情况会在以下两种场景里出现。</p>
<p>• 分区有3 个副本，其中的两个跟随者副本不可用（比如有两个broker 发生崩愤）。这个时候，如果生产者继续往首领写入数据，所有消息都会得到确认井被提交（因为此时首领是唯一的同步副本）。现在我们假设首领也不可用了（又一个broker 发生崩愤），这个时候，如果之前的一个跟随者重新启动，它就成为了分区的唯一不同步副本。</p>
<p>• 分区有3 个副本，因为网络问题导致两个跟随者副本复制消息滞后，所以尽管它们还在复制消息，但已经不同步了。首领作为唯一的同步副本继续接收消息。这个时候，如果首领变为不可用，另外两个副本就再也无法变成同步的了。</p>
<p>对于这两种场景，我们要作出一个两难的选择。</p>
<p>如果不同步的副本不能被提升为新首领，那么分区在旧首领（最后一个同步副本）恢复之前是不可用的。有时候这种状态会持续数小时（比如更换内存芯片）。</p>
<p>·如果不同步的副本可以被提升为新首领，那么在这个副本变为不同步之后写入旧首领的消息、会全部丢失，导致数据不一致。为什么会这样呢？假设在副本0 和副本1不可用时，偏移量100-200 的消息被写入副本2 （首领）。现在副本2 变为不可用的，而副本0 变为可用的。副本0 只包含偏移量0～ 100 的消息，不包含偏移量100～ 200 的悄息。如果我们允许副本0 成为新首领，生产者就可以继续写人数据，消费者可以继续读取数据。于是，新首领就有了偏移量100 ～200 的新消息。这样，部分消费者会读取到偏移量100 ～200 的旧消息，部分消费者会读取到偏移量100～200 的新消息，还有部分消费者读取的是二者的混合。这样会导致非常不好的结果，比如生成不准确的报表。另外，副本2 可能会重新变为可用，并成为新首领的跟随者。这个时候，它会把比当前首领旧的消息全部删除，而这些消息对于所有消费者来说都是不可用的。</p>
<p>简而言之，如果我们允许不同步的副本成为首领，那么就要承担丢失数据和出现数据不一致的风险。如果不允许它们成为首领，那么就要接受较低的可用性，因为我们必须等待原先的首领恢复到可用状态。</p>
<p>如果把unclean.leader.election设为true ，就是允许不同步的副本成为首领（也就是“ 不完全的选举”），那么我们将面临丢失消息的风险。如果把这个参数设为false ,就要等待原先的首领重新上线，从而降低了可用性。</p>
<p>我们经常看到一些对数据质量和数据一致性要求较高的系统会禁用这种不完全的首领选举（ 把这个参数设为false ） 。比如银行系统，大部分银行系统宁愿选择在几分钟甚至几个小时内不处理信用卡支付事务，也不会冒险处理错误的消息。不过在对可用性要求较高的系统里，比如实时点击流分析系统， 一般会启用不完全的首领选举。</p>
<h3 id="最少同步副本"><a href="#最少同步副本" class="headerlink" title="最少同步副本"></a><strong>最少同步副本</strong></h3><p>在主题级别和broker 级别上，这个参数都叫min.insync.replicas。</p>
<p>我们知道，尽管为一个主题配置了3 个副本，还是会出现只有一个同步副本的情况。如果这个同步副本变为不可用，我们必须在可用性和一致性之间作出选择—这又是一个两难的选择。根据Kafka 对可靠性保证的定义，消息只有在被写入到所有同步副本之后才被认为是已提交的。但如果这里的“所有副本”只包含一个同步副本，那么在这个副本变为不可用时，数据就会丢失。</p>
<p>如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大一点的值。对于一个包含3 个副本的主题，如果min.insync.replicas被设为2 ，那么至少要存在两个同步副本才能向分区写入数据。</p>
<p>如果3 个副本都是同步的，或者其中一个副本变为不可用，都不会有什么问题。不过，如果有两个副本变为不可用，那么broker 就会停止接受生产者的请求。尝试发送数据的生产者会收到N otEnoughReplicasException 异常。消费者仍然可以继续读取已有的数据。实际上，如果使用这样的配置，那么当只剩下一个同步副本时，它就变成只读了，这是为了避免在发生不完全选举时数据的写入和读取出现非预期的行为。为了从只读状态中恢复，必须让两个不可用分区中的一个重新变为可用的（比如重启broker ），并等待它变为同步的。</p>
<h2 id="可靠系统里的生产者"><a href="#可靠系统里的生产者" class="headerlink" title="可靠系统里的生产者"></a><strong>可靠系统里的生产者</strong></h2><p>即使我们尽可能把broker 配置得很可靠，但如果没有对生产者进行可靠性方面的配置， 整个系统仍然有可能出现突发性的数据丢失。</p>
<p>请看以下两个例子。</p>
<p> 为broker 配置了3 个副本，井且禁用了不完全首领选举，这样应该可以保证万无一失。我们把生产者发送消息的acks 设为1 （只要首领接收到消息就可以认为消息写入成功）。生产者发送一个消息给首领，首领成功写入，但跟随者副本还没有接收到这个消息。首领向生产者发送了一个响应，告诉它“消息写入成功”，然后它崩溃了，而此时消息还没有被其他副本复制过去。另外两个副本此时仍然被认为是同步的（毕竟判断一个副本不同步需要一小段时间），而且其中的一个副本成了新的首领。因为消息还没有被写入这个副本，所以就丢失了，但发送消息的客户端却认为消息已成功写入。因为消费者看不到丢失的消息，所以此时的系统仍然是一致的（因为副本没有收到这个消息，所以消息不算已提交），但从生产者角度来看，它丢失了一个消息。</p>
<p>• 为broker 配置了3 个副本，并且禁用了不完全首领选举。我们接受了之前的教训， 把生产者的acks 设为all 。假设现在往Kafka 发送消息，分区的首领刚好崩愤，新的首领正在选举当中， Kafka 会向生产者返回“首领不可用”的响应。在这个时候，如果生产者没能正确处理这个错误，也没有重试发送消息直到发送成功，那么消息也有可能丢失。这算不上是broker 的可靠性问题，因为broker 并没有收到这个消息。这也不是一致性问题，因为消费者并没有读到这个消息。问题在于如果生产者没能正确处理这些错误，弄丢消息的是它们自己。</p>
<p>那么，我们该如何避免这些悲剧性的后果呢？从上面两个例子可以看出，每个使用Kafk a的开发人员都要注意两件事情。</p>
<p>\1. 根据可靠性需求配置恰当的acks 值。</p>
<p>\2. 在参数配置和代码里正确处理错误。</p>
<h3 id="发送确认"><a href="#发送确认" class="headerlink" title="发送确认"></a><strong>发送确认</strong></h3><p>复习一下，生产者可以选择以下3 种不同的确认模式。</p>
<p>acks=0 意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入Kafka 。在这种情况下还是有可能发生错误，比如发送的对象无法被序列化或者网卡发生故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。即使是在发生完全首领选举的情况下，这种模式仍然会丢失消息，因为在新首领选举过程中它并不知道首领已经不可用了。在acks=0 模式下的运行速度是非常快的（这就是为什么很多基准测试都是基于这个模式），你可以得到惊人的吞吐量和带宽利用率，不过如果选择了这种模式， 一定会丢失一些消息。</p>
<p>acks=1 意味若首领在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。在这个模式下，如果发生正常的首领选举，生产者会在选举时收到一个LeadeNotAvailableExcepti.on 异常，如果生产者能恰当地处理这个错误，它会重试发送消息，最终消息会安全到达新的首领那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩溃。</p>
<p>acks=all 意味着首领在返回确认或错误响应之前，会等待所有同步副本都收到悄息。如果和min.insync.replicas参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到消息。这是最保险的做法——生产者会一直重试直到消息被成功提交。不过这也是最慢的做法，生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。可以通过使用异步模式和更大的批次来加快速度，但这样做通常会降低吞吐量。</p>
<h3 id="配置生产者的重试参数"><a href="#配置生产者的重试参数" class="headerlink" title="配置生产者的重试参数"></a><strong>配置生产者的重试参数</strong></h3><p>生产者需要处理的错误包括两部分： 一部分是生产者可以自动处理的错误，还有一部分是需要开发者手动处理的错民。</p>
<p>如果broker 返回的错误可以通过重试来解决，那么生产者会自动处理这些错误。生产者向broker 发送消息时， broker 可以返回一个成功响应码或者一个错误响应码。错民响应码可以分为两种， 一种是在重试之后可以解决的，还有一种是无法通过重试解决的。例如，如果broker 返回的是LEADER_NOT_AVAILABLE 错误，生产者可以尝试重新发送消息。也许在这个时候一个新的首领被选举出来了，那么这次发送就会成功。也就是说， LEADER_NOT_AVAILABLE是一个可重试错误。</p>
<p>另一方面，如果broker 返回的是INVALID_CONFIG 错误，即使通过重试也无能改变配置选项，所以这样的重试是没有意义的。这种错误是不可重试错误。</p>
<p>一般情况下，如果你的目标是不丢失任何消息，那么最好让生产者在遇到可重试错误时能够保持重试。为什么要这样？因为像首领选举或网络连接这类问题都可以在几秒钟之内得到解决，如果让生产者保持重试，就不需要额外去处理这些问题了。</p>
<p>那么为生产者配置多少重试次数比较好？这个要看在生产者放弃重试并抛出异常之后想做些什么。如果你想抓住异常并再多重试几次，那么就可以把重试次数设置得多一点， 让生产者继续重试；如果你想直接丢弃消息，多次重试造成的延迟已经失去发送消息的意义；如果你想把消息保存到某个地方然后回过头来再继续处理，那就可以停止重试。</p>
<p>Kafka 的跨数据中心复制工具（ MirrorMaker）默认会进行无限制的重试。作为一个具有高可靠性的复制工具，它决不会丢失消息。</p>
<p>要注意，重试发送一个已经失败的消息会带来一些风险，如果两个消息都写入成功，会导致消息重复。例如，生产者因为网络问题没有收到broker的确认，但实际上消息已经写入成功，生产者会认为网络出现了临时故障，就重试发送该消息（因为它不知道消息已经写入成功）。在这种情况下，broker 会收到两个相同的消息。重试和恰当的错误处理可以保证每个消息“至少被保存一次”，但无法保证每个消息“只被保存一次”。现实中的很多应用程序在消息里加入唯一标识符，用于检测重复消息，消费者在读取消息时可以对它们进行清理。还要一些应用程序可以做到消息的“幕等”，也就是说，即使出现了重复消息，也不会对处理结果的正确性造成负面影响。</p>
<h3 id="额外的错误处理"><a href="#额外的错误处理" class="headerlink" title="额外的错误处理"></a><strong>额外的错误处理</strong></h3><p>使用生产者内置的重试机制可以在不造成消息丢失的情况下轻松地处理大部分错误，不过对于开发人员来说，仍然需要处理其他类型的错误，包括：</p>
<p>• 不可重试的broker 错误，例如消息大小错误、认证错误等 . 在消息发送之前发生的错误，例如序列化错误：</p>
<p>• 在生产者达到重试次数上限时或者在消息占用的内存达到上限时发生的错误。</p>
<p>错误处理器的代码逻辑与具体的应用程序及其目标有关。丢弃“不合理的消息”？把错误记录下来？把这些消息保存在本地磁盘上？具体使用哪一种逻辑要根据具体的架构来决定。如果错误处理只是为了重试发送消息，那么最好还是使用生产者内置的重试机制。</p>
<h2 id="可靠系统里的消费者"><a href="#可靠系统里的消费者" class="headerlink" title="可靠系统里的消费者"></a><strong>可靠系统里的消费者</strong></h2><p>可以看到，只有那些被提交到Kafka 的数据，也就是那些已经被写入所有同步副本的数据，对消费者是可用的，这意味着消费者得到的消息已经具备了一致性。</p>
<p>消费者唯一要做的是跟踪哪些消息是已经读取过的，哪些是还没有读取过的。这是在读取消息时不丢失消息的关键。</p>
<p>在从分区读取数据时，消费者会获取一批事件，检查这批事件里最大的偏移量，然后从这个偏移量开始读取另外一批事件。这样可以保证消费者总能以正确的顺序获取新数据， 不会错过任何事件。</p>
<p>如果一个消费者退出，另一个消费者需要知道从什么地方开始继续处理，它需要知道前一个消费者在退出前处理的最后一个偏移量是多少。所谓的“另一个”消费者，也可能就是它自己重启之后重新回来工作。这也就是为什么消费者要“提交”它们的偏移量。它们把当前读取的偏移量保存起来，在退出之后，同一个群组里的其他消费者就可以接手它们的工作。如果消费者提交了偏移量却未能处理完消息，那么就有可能造成消息丢失，这也是消费者丢失消息的主要原因。在这种情况下，如果其他消费者接手了工作，那些没有被处理完的消息就会被忽略，永远得不到处理。所以我们要重视偏移量提交的时间点和提交的方式。</p>
<h3 id="消费者的可靠性配置"><a href="#消费者的可靠性配置" class="headerlink" title="消费者的可靠性配置"></a><strong>消费者的可靠性配置</strong></h3><p>为了保证消费者行为的可靠性，需要注意以下4 个非常重要的配置参数。</p>
<p>第1个是group.id 。如果两个消费者具有相同的group.id ， 并且订阅了同一个主题，那么每个消费者会分到主题分区的一个子集， 也就是说它们只能读到所有消息的一个子集（不过群组会读取主题所有的消息）。如果你希望消费者可以看到主题的所有消息，那么需要为它们设置唯一的group.id 。</p>
<p>第2 个是auto.offset.reset 。这个参数指定了在没有偏移量可提交时（比如消费者第1次启动时）或者请求的偏移量在broker 上不存在时，消费者会做些什么。这个参数有两种配置。一种是earliest ，如果选择了这种配置，消费者会从分区的开始位置读取数据，不管偏移量是否有效，这样会导致消费者读取大量的重复数据，但可以保证最少的数据丢失。一种是latest，如果选择了这种配置， 消费者会从分区的末尾开始读取数据，这样可以减少重复处理消息，但很有可能会错过一些消息。</p>
<p>第3 个是enable.auto.commit 。这是一个非常重要的配置参数，你可以让消费者基于任务调度自动提交偏移量，也可以在代码里手动提交偏移量。自动提交的一个最大好处是，在实现消费者逻辑时可以少考虑一些问题。如果你在消费者轮询操作里处理所有的数据，那么自动提交可以保证只提交已经处理过的偏移量。自动提交的主要缺点是，无法控制重复处理消息（比如消费者在自动提交偏移量之前停止处理消息），而且如果把消息交给另外一个后台线程去处理，自动提交机制可能会在消息还没有处理完毕就提交偏移量。</p>
<p>第4 个配置参数auto.commit.interval.ms与第3 个参数有直接的联系。如果选择了自动提交偏移盘，可以通过该参数配置提交的频度， 默认值是每5 秒钟提交一次。一般来说，频繁提交会增加额外的开销，但也会降低重复处理消息的概率。</p>
<h3 id="显式提交偏移量"><a href="#显式提交偏移量" class="headerlink" title="显式提交偏移量"></a><strong>显式提交偏移量</strong></h3><p>如果选择了自动提交偏移量，就不需要关心显式提交的问题。不过如果希望能够更多地控制偏移量提交的时间点，那么就要仔细想想该如何提交偏移量了一一要么是为了减少重复处理消息，要么是因为把消息处理逻辑放在了轮询之外。</p>
<p>在开发具有可靠性的消费者应用程序时需要注意的事项。我们先从简单的开始，再逐步深入。</p>
<h4 id="1-总是在处理完事件后再提交偏移量"><a href="#1-总是在处理完事件后再提交偏移量" class="headerlink" title="1 . 总是在处理完事件后再提交偏移量"></a><strong>1 .</strong> <strong>总是在处理完事件后再提交偏移量</strong></h4><p>如果所有的处理都是在轮询里完成，而且消息处理总是幂等的，或者少量消息丢失无关紧要， 那么可以使用自动提交，或者在轮询结束时进行手动提交。</p>
<h4 id="2-提交频度是性能和重复消息数量之间的权衡"><a href="#2-提交频度是性能和重复消息数量之间的权衡" class="headerlink" title="2. 提交频度是性能和重复消息数量之间的权衡"></a><strong>2.</strong> <strong>提交频度是性能和重复消息数量之间的权衡</strong></h4><p>即使是在最简单的场景里，比如所有的处理都在轮询里完成，并且不需要在轮询之间维护状态，你仍然可以在一个循环里多次提交偏移量（甚至可以在每处理完一个事件之后），或者多个循环里只提交一次，这完全取决于你在性能和重复处理消息之间作出的权衡。</p>
<h4 id="3-确保对提交的偏移量心里有数"><a href="#3-确保对提交的偏移量心里有数" class="headerlink" title="3. 确保对提交的偏移量心里有数"></a><strong>3.</strong> <strong>确保对提交的偏移量心里有数</strong></h4><p>在轮询过程中提交偏移量有一个不好的地方，就是提交的偏移量有可能是读取到的最新偏移量，而不是处理过的最新偏移量。要记住，在处理完消息后再提交偏移量是非常关键的，否则会导致消费者错过消息。</p>
<h4 id="4-再均衡"><a href="#4-再均衡" class="headerlink" title="4 . 再均衡"></a><strong>4 .</strong> <strong>再均衡</strong></h4><p>在设计应用程序时要注意处理消费者的再均衡问题。一般要在分区被撤销之前提交偏移量，井在分配到新分区时清理之前的状态。</p>
<h4 id="5-消费者可能需要重试"><a href="#5-消费者可能需要重试" class="headerlink" title="5 . 消费者可能需要重试"></a><strong>5 .</strong> <strong>消费者可能需要重试</strong></h4><p>有时候，在进行轮询之后，有些消息不会被完全处理，可能稍后再来处理。例如，假设要把Kafka 的数据写到数据库里，不过那个时候数据库不可用，于是你想稍后重试。要注意，你提交的是偏移量，而不是对消息的“确认”，这个与传统的发布和订阅消息系统不太一样。如果记录的#30 处理失败，但记录的#31处理成功，那么你不应该提交#31， 否则会导致的#31以内的偏移量都被提交，包括的#30在内。不过可以采用下面这种模式来解决这个问题。</p>
<p>在遇到可重试错误时，把错误写入一个独立的主题，然后继续。一个独立的消费者群组负责从该主题上读取错误消息，并进行重试，或者使用其中的一个消费者同时从该主题上读取错误消息并进行重试，不过在重试时需要暂停该主题。这种模式有点像其他消息系统里的死信队列 。</p>
<h4 id="6-消费者可能需要维护状态"><a href="#6-消费者可能需要维护状态" class="headerlink" title="6 . 消费者可能需要维护状态"></a><strong>6 .</strong> <strong>消费者可能需要维护状态</strong></h4><p>有时候你希望在多个轮询之间维护状态，例如，你想计算消息的移动平均数，希望在首次轮询之后计算平均数，然后在后续的轮询中更新这个结果。如果进程重启，你不仅需要从上一个偏移量开始处理数据，还要恢复移动平均数。有一种办法是在提交偏移量的同时把最近计算的平均数写到一个“结果”主题上。消费者线程在重新启动之后，它就可以拿到最近的平均数并接着计算。不过这并不能完全地解决问题，因为Kafka 并没有提供事务支持。消费者有可能在写入平均数之后来不及提交偏移量就崩溃了，或者反过来也一样。这是一个很复杂的问题，你不应该尝试自己去解决这个问题，建议尝试一下Kafka流计算，它为聚合、连接、时间窗和其他复杂的分析提供了高级的API 。</p>
<h4 id="7-长时间处理"><a href="#7-长时间处理" class="headerlink" title="7. 长时间处理"></a><strong>7.</strong> <strong>长时间处理</strong></h4><p>有时候处理数据需要很长时间：你可能会从发生阻塞的外部系统获取信息，或者把数据写到外部系统，或者进行一个非常复杂的计算，但是我们要尽量保持轮询。在这种情况下， 一种常见的做法是使用一个线程地来处理数据，因为使用多个线程可以进行并行处理，从而加快处理速度。在把数据移交给线程地去处理之后，你就可以暂停消费者，然后保持轮询，但不获取新数据，直到工作线程处理完成。在工作线程处理完成之后，可以让消费者继续获取新数据。</p>
<h4 id="8-仅一次传递"><a href="#8-仅一次传递" class="headerlink" title="8. 仅一次传递"></a><strong>8.</strong> <strong>仅一次传递</strong></h4><p>有些应用程序不仅仅需要“至少一次”（意味着没有数据丢失），还需要“仅一次”语义。Kafka 现在还不能完全支持仅一次语义，消费者还是有一些办法可以保证Kafka 里的每个消息只被写到外部系统一次（但不会处理向Kafka 写入数据时可能出现的重复数据） 。</p>
<p>实现仅一次处理最简单且最常用的办能是把结果写到一个支持唯一键的系统里，比如键值存储引擎、关系型数据库、ElasticSearch 或其他数据存储引擎。在这种情况下，要么消息本身包含一个唯一键（通常都是这样），要么使用主题、分区和偏移量的组合来创建唯一键一一－它们的组合可以唯一标识一个Kafka 记录。如果你把消息和一个唯一键写入系统，然后碰巧又读到一个相同的消息，只要把原先的键值覆盖掉即可。数据存储引擎会覆盖已经存在的键值对，就像没有出现过重复数据一样。这个模式被叫作幂等性写入，它是一种很常见也很有用的模式。</p>
<p>如果写入消息的系统支持事务， 那么就可以使用另一种方法。最简单的是使用关系型数据库。我们把消息和偏移量放在同一个事务里，这样它们就能保持同步。在消费者启动时，它会获取最近处理过的消息偏移量，然后调用seek （）方也从该偏移量位置继续读取数据。</p>
<h1 id="数据管道和流式处理（了解即可）"><a href="#数据管道和流式处理（了解即可）" class="headerlink" title="数据管道和流式处理（了解即可）"></a><strong>数据管道和流式处理（了解即可）</strong></h1><h2 id="数据管道基本概念"><a href="#数据管道基本概念" class="headerlink" title="数据管道基本概念"></a><strong>数据管道基本概念</strong></h2><p>在使用Kafka 构建数据管道时，通常有两种使用场景： 第一种，把Kafka 作为数据管道的两个端点之一，例如，把Kafka 里的数据移动到云上，或者把Mongo DB 里的数据移动到Kafka 里；第二种，把Kafka 作为数据管道两个端点的中间媒介，例如，为了把DB的数据移动到ElasticSearch 上，需要先把它们移动到Kafka 里，再将它们从Kafka 移动到Elastic Search 上。</p>
<p>Kafka 为数据管道带来的主要价值在于，它可以作为数据管道各个数据段之间的大型缓冲区， 有效地解耦管道数据的生产者和消费者。数据管道的重要作用之一是解耦数据源和数据池，Kafka在这方面的能力以及在安全和效率方面的可靠性，使它成为构建数据管道的最佳选择。</p>
<h3 id="数据管道需要考虑的问题"><a href="#数据管道需要考虑的问题" class="headerlink" title="数据管道需要考虑的问题"></a><strong>数据管道需要考虑的问题</strong></h3><h4 id="及时性"><a href="#及时性" class="headerlink" title="及时性"></a><strong>及时性</strong></h4><p>有些系统希望每天一次性地接收大量数据，而有些则希望在数据生成几毫秒之内就能拿到它们。大部分数据管道介于这两者之间。一个好的数据集成系统能够很好地支持数据管道的各种及时性需求，而且在业务需求发生变更时，具有不同及时性需求的数据表之间可以方便地进行迁移。</p>
<p>Kafka 作为一个基于流的数据平台，提供了可靠且可伸缩的数据存储，可以支持几近实时的数据管道和基于小时的批处理。生产者可以频繁地向Kafka 写入数据，也可以按需写入：消费者可以在数据到达的第一时间读取它们，也可以每隔一段时间读取一次积压的数据。</p>
<p>Kafka 在这里扮演了一个大型缓冲区的角色，降低了生产者和消费者之间的时间敏感度。实时的生产者和基于批处理的消费者可以同时存在，也可以任意组合。实现回压策略也因此变得更加容易， Kafka 本身就使用了回压策略（必要时可以延后向生产者发送确认），消费速率完全取决于消费者自己。</p>
<h4 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a><strong>可靠性</strong></h4><p>我们要避免单点故障，并能够自动从各种故障中快速恢复。数据通过数据管道到达业务系统，哪怕出现几秒钟的故障，也会造成灾难性的影响，对于那些要求毫秒级的及时性系统来说尤为如此。数据传递保证是可靠性的另一个重要因素。有些系统允许数据丢失，不过在大多数情况下，它们要求至少一次传递。也就是说，源系统的每一个事件都必须到达目的地，不过有时候需要进行重试，而重试可能造成重复传递。有些系统甚至要求仅一次传递一一源系统的每一个事件都必须到达目的地，不允许丢失，也不允许重复。</p>
<h4 id="高吞吐量和动态吞吐量"><a href="#高吞吐量和动态吞吐量" class="headerlink" title="高吞吐量和动态吞吐量"></a><strong>高吞吐量和动态吞吐量</strong></h4><p>为了满足现代数据系统的要求，数据管道需要支持非常高的吞吐量。更重要的是，在某些情况下，数据管道还需要能够应对突发的吞吐量增长。</p>
<p>由于我们将Kafka 作为生产者和消费者之间的缓冲区，消费者的吞吐量和生产者的吞吐量就不会耦合在一起了。如果生产者的吞吐量超过了消费者的吞吐量，可以把数据积压在Kafka 里，等待消费者追赶上来。通过增加额外的消费者或生产者可以实现Kafka 的伸缩，因此我们可以在数据管道的任何一边进行动态的伸缩，以便满足持续变化的需求。</p>
<p>因为Kafka 是一个高吞吐量的分布式系统， 一个适当规模的集群每秒钟可以处理数百兆的数据，所以根本无需担心数据管道无住满足伸缩性需求。另外， Connect API 不仅支持伸缩，而且擅长并行处理任务。</p>
<h4 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a><strong>数据格式</strong></h4><p>数据管道需要协调各种数据格式和数据类型，这是数据管道的一个非常重要的因素。数据类型取决于不同的数据库和数据存储系统。你可能会通过Avro 将XML 或关系型数据加载到Kafka 里，然后将它们转成JSON 写入ElasticSearch ，或者写入HDFS 等等。 </p>
<p>Kafka 和与数据格式无关。生产者和消费者可以使用各种序列化器来表示任意格式的数据。</p>
<h2 id="流式处理基本概念"><a href="#流式处理基本概念" class="headerlink" title="流式处理基本概念"></a><strong>流式处理基本概念</strong></h2><p>Kafka 早期版本一般被认为是一个强大的消息总线，可以传递事件流，但没有处理和转换事件的能力。Kafka 可靠的传递能力让它成为流式处理系统完美的数据来源。很多基于Kafka 构建的流式处理系统都将Kafka 作为唯一可靠的数据来隙，如Apache Storm 、Apache SparkStreaming 、Apache Flink 、Apache Samza 等。</p>
<p>从0 . 10 . 0 版本开始， Kafka 不仅为每一个流行的流式处理框架提供了可靠的数据来橱， 还提供了一个强大的流式处理类库，并将其作为客户端类库的一部分。这样，开发人员就可以在应用程序里读取、处理和生成事件，而不需要再依赖外部的处理框架。</p>
<h3 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a><strong>数据流</strong></h3><p>先来看看什么是数据流（也被称为“事件流”或“流数据”）。首先，数据流是无边界数据集的抽象表示。无边界意味着无限和持续增长。无边界数据集之所以是无限的，是因为随着时间的推移，新的记录会不断加入进来。</p>
<p>这个简单的模型（事件流）可以表示很多业务活动，比如信用卡交易、股票交易、包裹递送、流经交换机的网络事件、制造商设备传感器发出的事件、发送出去的邮件、游戏里物体的移动，等等。这个清单是无穷无尽的，因为几乎每一件事情都可以被看成事件的序列。</p>
<p>除了没有边界外，事件流模型还有其他一些属性。</p>
<h4 id="事件流是有序的"><a href="#事件流是有序的" class="headerlink" title="事件流是有序的"></a><strong>事件流是有序的</strong></h4><p>事件的发生总是有个先后顺序。以金融活动事件为例，先将钱存进账户后再花钱，这与先花钱再还钱的次序是完全不一样的。后者会出现透支，而前者不会。</p>
<h4 id="不可变的数据记录"><a href="#不可变的数据记录" class="headerlink" title="不可变的数据记录"></a><strong>不可变的数据记录</strong></h4><p>事件一旦发生，就不能被改变。一个金融交易被取消，并不是说它就消失了，相反，这需要往事件流里添加一个额外的事件，表示前一个交易的取消操作。顾客的一次退货并不意味着之前的销售记录被删除，相反，退货行为被当成一个额外的事件记录下来。这是数据流与数据表之间的另一个不同点一一可以删除和修改数据表里的记录，但这些操作只不过是发生在数据库里的事务，这些事务可以被看成事件流。假设你对数据库的二进制日志（ bin log ）、预写式日志（ WAL ）和重做日志（ redo log ）的概念都很熟悉，那么就会知道，如果往数据库表插入一条记录，然后将其删除，表里就不会再有这条记录。但重做日志里包含了两个事务：插入事务和删除事务。</p>
<h4 id="事件流是可重播的"><a href="#事件流是可重播的" class="headerlink" title="事件流是可重播的"></a><strong>事件流是可重播的</strong></h4><p>这是事件流非常有价值的一个属性。但对于大多数业务来说，重播发生在几个月前（甚至几年前）的原始事件流是一个很重要的需求。可能是为了尝试使用新的分析方法纠正过去的错误，或是为了进行审计。</p>
<h3 id="什么是流式处理"><a href="#什么是流式处理" class="headerlink" title="什么是流式处理"></a><strong>什么是流式处理</strong></h3><p>流式处理是指实时地处理一个或多个事件流。流式处理是一种编程范式，就像请求与响应范式和批处理范式那样。</p>
<h4 id="请求与响应"><a href="#请求与响应" class="headerlink" title="请求与响应"></a><strong>请求与响应</strong></h4><p>这是延迟最小的一种范式，响应时间处于亚毫秒到毫秒之间，而且响应时间一般非常稳定。这种处理模式一般是阻塞的，应用程序向处理系统发出请求，然后等待响应。在数据库领域。</p>
<h4 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a><strong>批处理</strong></h4><p>这种范式具有高延迟和高吞吐量的特点。处理系统按照设定的时间启动处理进程，比如每天的下午两点开始启动，每小时启动一次等。它读取所有的输入数据（从上－ 次执行之后的所有可用数据，或者从月初开始的所有数据等）．输出结果，然后等待下一次启动。处理时间从几分钟到几小时不等，并且用户从结果里读到的都是旧数据。它们每天加载巨大批次的数据，并生成报表，用户在下一次加载数据之前看到的都是相同的报表。从规模上来说，这种范式既高效又经挤。但在近几年，为了能够更及时、高效地作出决策，业务要求在更短的时间内能提供可用的数据，这就给那些为探索规模经济而开发却无法提供低延迟报表的系统带来了巨大的压力。</p>
<h4 id="流式处理"><a href="#流式处理" class="headerlink" title="流式处理"></a><strong>流式处理</strong></h4><p>这种范式介于上述两者之间。大部分的业务不要求亚毫秒级的响应，不过也接受不了要等到第二天才知道结果。大部分业务流程都是持续进行的，只要业务报告保持更新，业务产品线能够持续响应，那么业务流程就可以进行下去，而无需等待特定的响应，也不要求在几毫秒内得到响应。一些业务流程具有持续性和非阻塞的特点，比如针对可疑信用卡交易的警告、网络警告、根据供应关系实时调整价格、跟踪包衷。</p>
<p>流的定义不依赖任何一个特定的框架、API 或特性。只要持续地从一个无边界的数据集读取数据，然后对它们进行处理并生成结果，那就是在进行流式处理。重点是，整个处理过程必须是持续的。一个在每天凌晨两点启动的流程，从流里读取500 条记录，生成结果，然后结束，这样的流程不是流式处理。</p>
<h3 id="流式处理中的基本概念"><a href="#流式处理中的基本概念" class="headerlink" title="流式处理中的基本概念"></a><strong>流式处理中的基本概念</strong></h3><p>流式处理的很多方面与普通的数据处理是很相似的：写一些代码来接收数据，对数据进行处理，可能做一些转换、聚合和增强的操作，然后把生成的结果输出到某个地方。不过流式处理有一些特有的概念，我们可以适当了解一下。</p>
<h4 id="时间"><a href="#时间" class="headerlink" title="时间"></a><strong>时间</strong></h4><p>在流式处理里，时间是一个非常重要的概念，因为大部分流式应用的操作都是基于时间窗口的。</p>
<p>例如，流式应用可能会计算股价的5 分钟移动平均数。如果生产者因为网络问题离线了2小时，然后带着2 小时的数据重新连线，我们需要知道该如何处理这些数据。这些数据大部分都已经超过了5 分钟，而且没有参与之前的计算。</p>
<p>流式处理系统一般包含如下几个时间概念。</p>
<h5 id="事件时间"><a href="#事件时间" class="headerlink" title="事件时间"></a>事件时间</h5><p>事件时间是指所追踪事件的发生时间和记录的创建时间。例如，度量的获取时间、商店里商品的出售时间、网站用户访问网页的时间，等等。在处理数据流肘，事件时间是很重要的。</p>
<h5 id="日志追加时间"><a href="#日志追加时间" class="headerlink" title="日志追加时间"></a>日志追加时间</h5><p>日志追加时间是指事件保存到broker 的时间。这个时间戳一般与流式处理没有太大关系，因为用户一般只对事件的发生时间感兴趣。例如，如果要计算每天生产了多少台设备，就需要计算在那一天实际生产的设备数量，尽管这些事件有可能因为网络问题到了第二天才进入Kafka 。不过，如果真实的事件时间没有被记录下来，那么就可以使用日志追加时间，在记录创建之后，这个时间就不会发生改变。</p>
<h5 id="处理时间"><a href="#处理时间" class="headerlink" title="处理时间"></a>处理时间</h5><p>处理时间是指应用程序在收到事件之后要对其进行处理的时间。这个时间可以是在事件发生之后的几毫秒、几小时或几天。同一个事件可能会被分配不同的时间戳，这取决于应用程序何时读取这个事件。如果应用程序使用了两个线程来读取同一个事件，这个时间戳也会不一样。所以这个时间戳非常不可靠，应该避免使用它。</p>
<h4 id="状态"><a href="#状态" class="headerlink" title="状态"></a><strong>状态</strong></h4><p>如果只是单独处理每一个事件，那么流式处理就很简单。例如，如果想从Kafka 读取电商购物交易事件流，找出金额超过10 000元的交易，并将结果通过邮件发送给销售人员，那么可以使用Kafka 消费者客户端，几行代码就可以搞定。</p>
<p>如果操作里包含了多个事件，流式处理就会变得很有意思，比如根据类型计算事件的数量、移动平均数、合并两个流以便生成更丰富的信息流。在这些情况下，光处理单个事件是不够的，需要跟踪更多的信息，比如这个小时内看到的每种类型事件的个数、需要合并的事件、将每种类型的事件值相加等等。事件与事件之间的信息被称为状态。</p>
<p>这些状态一般被保存在应用程序的本地变量里。流式处理包含以下几种类型的状态。</p>
<h5 id="本地状态或内部状态"><a href="#本地状态或内部状态" class="headerlink" title="本地状态或内部状态"></a>本地状态或内部状态</h5><p>这种状态只能被单个应用程序实例访问，它们一般使用内嵌在应用程序里的数据库进行维护和管理。本地状态的优势在于它的速度，不足之处在于它受到内存大小的限制。所以，流式处理的很多设计模式都将数据拆分到多个子流，这样就可以使用有限的本地状态来处理它们。</p>
<h5 id="外部状态"><a href="#外部状态" class="headerlink" title="外部状态"></a>外部状态</h5><p>这种状态使用外部的数据存储来维护， 一般使用NoSQL 系统，比如HDFS 。使用外部存储的优势在于，它没有大小的限制，而且可以被应用程序的多个实例访问，甚至被不同的应用程序访问。不足之处在于，引人额外的系统会造成更大的延迟和复杂性。大部分流式处理应用尽量避免使用外部存储，或者将信息缓存在本地，减少与外部存储发生交互，以此来降低延迟。</p>
<h4 id="流和表区别"><a href="#流和表区别" class="headerlink" title="流和表区别"></a><strong>流和表区别</strong></h4><p>大家都熟悉数据库表，表就是记录的集合，每个表都有一个主键，并包含了一系列由schema 定义的属性。表的记录是可变的（可以在表上面执行更新和删除操作）。我们可以通过查询表数据获知某一时刻的数据状态。例如，通过查询客户信息这个表，就可以获取所有客户的联系信息。如果表被设计成不包含历史信息，那么就找不到客户过去的联系信息了。</p>
<p>在将表与流进行对比时，可以这么想：流包含了变更一一流是一系列事件，每个事件就是一个变更。表包含了当前的状态，是多个变更所产生的结果。</p>
<p>为了将表转化成流，需要捕捉到在表上所发生的变更，将“ insert ”、“ update ”和“ delete ”事件保存到流里。大部分数据库提供了用于捕捉变更的“ Change Data Capture” (CDC ）解决方案， Kafka 连接器将这些变更发送到Kafka ，用于后续的流式处理。</p>
<p>假设有一个商店，某零售活动可以使用一个事件流来表示：</p>
<p>“红色、蓝色和绿色鞋子到货”</p>
<p>“蓝色鞋子卖出”</p>
<p>“红色鞋子卖出”</p>
<p>“蓝色鞋子退货”</p>
<p>“绿色鞋子卖出”</p>
<p>如果想知道现在仓库里还有哪些库存，或者到目前为止赚了多少钱，可以用表。如果想知道鞋店的繁忙程度，可以查看整个事件流，会发现总共发生了5 个交易，还可以查出为什么蓝色鞋子被退货。</p>
<h3 id="流式处理的常见场景"><a href="#流式处理的常见场景" class="headerlink" title="流式处理的常见场景"></a><strong>流式处理的常见场景</strong></h3><p>现在很多公司每天都会产生数以TB级的大数据，如何对这些数据进行挖掘，分析成了很重要的课题。比如：</p>
<p><strong>电子商务</strong>：需要处理并且挖掘用户行为产生的数据，产生推荐，从而带来更多的流量和收益。最理想的推荐就是根据兴趣推荐给用户本来不需要的东西！而每天处理海量的用户数据，需要一个低延时高可靠的实时流式分布式计算系统。</p>
<p><strong>在线订购</strong>：假设客户向一个大型的连锁酒店预订了一个房间，连锁酒店的每一个系统在预订结束之后的几秒钟或者几分钟之内都能发出通知，包括客服中心、酒店、发送确认邮件的系统、网站等。有的酒店可能还希望客服中心能够立即获知用户在这家连锁酒店的历史入住数据，前台能够知道他是一个忠实的客户，从而提供更高级别的服务。如果使用流式处理应用来构建这些系统，就可以实现几近实时的接收和处理这些事件，从而带来更好的用户体验。</p>
<p><strong>新闻聚合</strong>：新闻时效性非常重要，如果在一个重大事情发生后能够实时的推荐给用户，那么肯定能增大用户粘性，带来可观的流量。</p>
<p><strong>社交网站</strong>：大家每天都会去社交网站是为了看看现在发生了什么，周围人在做什么。流式计算可以把用户关注的热点聚合，实时反馈给用户，从而达到一个圈子的聚合效果。</p>
<p><strong>交通监管</strong>：每个城市的交通监管部门每天都要产生海量的视频数据，这些视频数据也是以流的形式源源不断的输系统中。实时流式计算系统需要以最快的速度来处理这些数据。</p>
<p><strong>数据挖掘和机器学习</strong>：它们实际上是互联网公司内部使用的系统，主要为线上服务提供数据支撑。它们可以说是互联网公司的最核心的平台之一。系统的效率是挖掘的关键，理想条件下就是每天产生的海量数据都能得到有效处理，对于原来的数据进行全量更新。</p>
<p><strong>大型集群的监控</strong>：自动化运维很重要，集群监控的实时预警机制也非常重要，而流式系统对于日志的实时处理，往往是监控系统的关键。</p>
<p><strong>物联网</strong>：物联网包含很多东西。流式处理在传感器和设备上应用，最为常见的是用于预测何时该进行设备维护。这个与应用监控有点相似，不过这次是应用在硬件上，而且应用在很多不同的行业一一制造业、通信（识别故障基站）、有线电视（在用户投诉之前识别出故障机顶盒）等。每一种场景都有自己的特点，不过目标是一样的处理大量来自设备的事件，并识别出一些模式，这些模式预示着某些设备需要进行维护，比如交换机数据包的下降、生产过程中需要更大的力气来拧紧螺丝， 或者用户频繁重启有线电视的机顶盒。</p>
<h3 id="Kafka流式处理实战"><a href="#Kafka流式处理实战" class="headerlink" title="Kafka流式处理实战"></a><strong>Kafka流式处理实战</strong></h3><p>参见模块kafka-stream下</p>

        </div>
        <div id="post-footer">
            <div class="avatar">
                <img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jcpbkpo7j30u01407wj.jpg" alt="avatar">
                
                
                <a href="javascript:void(0)" class="donate fa">赠我一杯 &#128536;</a>
                
            </div>
            <ul class="author-profile-section">
                <li>
                  
                  Author:
                  
                    
                    <a href="/about.html">lill</a>
                </li>
                
                <li>Published Date: <span>2019-07-03  01:50:05</span></li>
                
                <li>Updated Date: <span>2020-03-26  00:12:24</span></li>
                
                <li class="post-category">
                    Categories:
                    
                    <a href="/categories/消息中间件/">消息中间件</a>
                    
                    <a href="/categories/消息中间件/Kafka/">Kafka</a>
                    
                </li>
                <li class="post-tags">
                    Tags:
                    
                    <a href="/tags/Kafka/">Kafka</a>
                    
                </li>
                
                <li> License: <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/" target="_blank">
知识共享署名-非商业性使用-禁止演绎 3.0 未本地化版本许可协议（CC BY-NC-ND 3.0）
</a></li>
                
            </ul>
            <div id="donate-wrap">
                
                
                
                <img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4j3v2hrrjj30a00fk750.jpg" alt="支付宝付款" class="donate-img">
                
                <img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jc3z12itj30h90no0tp.jpg" alt="微信付款" class="donate-img">
                
                
            </div>
        </div>
    </article>
    <div class="article-nav">
        
        <a href="/2019/07/03/kafka-4/" class="pre-post fa fa-caret-left">消息队列常见问题</a>
        
        
        <a href="/2019/07/03/kafka-2/" class="next-post fa">Kafka应用</a>
        
    </div>
    
    <div id="comments">
        

<script>
  gitment.render(document.getElementById("comments"));
</script>



    </div>
    
</div>


    </div>
    <footer id="footer">
    
    <div class="social">
        
        <a href="https://github.com/EllenJack/ellenjack.github.io.git" class="fa fa-free-code-camp" target="_blank" title="freecodecamp"></a>
        
        <a href="https://github.com/EllenJack/ellenjack.github.io.git" class="fa fa-github" target="_blank" title="Follow me~"></a>
        
    </div>
    
    <div>
        
        <a href="/" class="copyright-links">lill</a>&copy;2015 - 2020.All Rights
        Reserved.
    </div>
    <p>Powered by <a href="https://hexo.io" class="copyright-links" target="_blank">Hexo</a> | Theme by <a href="https://github.com/GeekaholicLin" class="copyright-links" target="_blank">GeekaholicLin</a>
    </p>
    
</footer>

</div>
    <ul id="tools">
    <li class="totop-btn fa fa-angle-up"></li>
    <li class="exchange-btn fa fa-exchange"></li>
  
    <li class="toc-btn fa fa-list-ul"></li>
    
    

    
</ul>
<p id="process"></p>
<div id="search-overlay">
    <div class="search-area-wrap">
        <div id="search-area">
            <div class="input-wrap focus">
                <i class="fa fa-search" aria-hidden="true"></i>
                <input id="search-input" autofocus autocomplete="off" type="text" placeholder="search this website...">
            </div>
            <ul id="search-result">
                <li class="load-first"><i class="fa fa-spinner fa-pulse"></i></li>
            </ul>
        </div>
    </div>
</div>

    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#深入理解Kafka"><span class="toc-number">1.</span> <span class="toc-text">深入理解Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#集群的成员关系"><span class="toc-number">1.1.</span> <span class="toc-text">集群的成员关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是控制器"><span class="toc-number">1.2.</span> <span class="toc-text">什么是控制器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#复制-Kafka的核心"><span class="toc-number">1.3.</span> <span class="toc-text">复制-Kafka的核心</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#副本类型。"><span class="toc-number">1.3.1.</span> <span class="toc-text">副本类型。</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#首领副本"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">首领副本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#跟随者副本"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">跟随者副本</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#工作机制"><span class="toc-number">1.3.2.</span> <span class="toc-text">工作机制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#处理请求的内部机制"><span class="toc-number">1.4.</span> <span class="toc-text">处理请求的内部机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#生产请求"><span class="toc-number">1.4.0.1.</span> <span class="toc-text">生产请求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#获取请求"><span class="toc-number">1.4.0.2.</span> <span class="toc-text">获取请求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ISR"><span class="toc-number">1.4.0.3.</span> <span class="toc-text">ISR</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#示例"><span class="toc-number">1.4.0.3.1.</span> <span class="toc-text">示例</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#使用ISR方案的原因"><span class="toc-number">1.4.0.3.2.</span> <span class="toc-text">使用ISR方案的原因</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ISR相关配置说明"><span class="toc-number">1.4.0.3.3.</span> <span class="toc-text">ISR相关配置说明</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#物理存储机制"><span class="toc-number">1.5.</span> <span class="toc-text">物理存储机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#分区分配"><span class="toc-number">1.5.1.</span> <span class="toc-text">分区分配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文件管理"><span class="toc-number">1.5.2.</span> <span class="toc-text">文件管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文件格式"><span class="toc-number">1.5.3.</span> <span class="toc-text">文件格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#索引"><span class="toc-number">1.5.4.</span> <span class="toc-text">索引</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#超时数据的清理机制"><span class="toc-number">1.5.5.</span> <span class="toc-text">超时数据的清理机制</span></a></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#可靠的数据传递"><span class="toc-number">2.</span> <span class="toc-text">可靠的数据传递</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka提供的可靠性保证和架构上的权衡"><span class="toc-number">2.1.</span> <span class="toc-text">Kafka提供的可靠性保证和架构上的权衡</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#复制"><span class="toc-number">2.2.</span> <span class="toc-text">复制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker配置对可靠性的影响"><span class="toc-number">2.3.</span> <span class="toc-text">Broker配置对可靠性的影响</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#复制系数"><span class="toc-number">2.3.1.</span> <span class="toc-text">复制系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#不完全的首领选举"><span class="toc-number">2.3.2.</span> <span class="toc-text">不完全的首领选举</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#最少同步副本"><span class="toc-number">2.3.3.</span> <span class="toc-text">最少同步副本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#可靠系统里的生产者"><span class="toc-number">2.4.</span> <span class="toc-text">可靠系统里的生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#发送确认"><span class="toc-number">2.4.1.</span> <span class="toc-text">发送确认</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置生产者的重试参数"><span class="toc-number">2.4.2.</span> <span class="toc-text">配置生产者的重试参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#额外的错误处理"><span class="toc-number">2.4.3.</span> <span class="toc-text">额外的错误处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#可靠系统里的消费者"><span class="toc-number">2.5.</span> <span class="toc-text">可靠系统里的消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#消费者的可靠性配置"><span class="toc-number">2.5.1.</span> <span class="toc-text">消费者的可靠性配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#显式提交偏移量"><span class="toc-number">2.5.2.</span> <span class="toc-text">显式提交偏移量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-总是在处理完事件后再提交偏移量"><span class="toc-number">2.5.2.1.</span> <span class="toc-text">1 . 总是在处理完事件后再提交偏移量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-提交频度是性能和重复消息数量之间的权衡"><span class="toc-number">2.5.2.2.</span> <span class="toc-text">2. 提交频度是性能和重复消息数量之间的权衡</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-确保对提交的偏移量心里有数"><span class="toc-number">2.5.2.3.</span> <span class="toc-text">3. 确保对提交的偏移量心里有数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-再均衡"><span class="toc-number">2.5.2.4.</span> <span class="toc-text">4 . 再均衡</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-消费者可能需要重试"><span class="toc-number">2.5.2.5.</span> <span class="toc-text">5 . 消费者可能需要重试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-消费者可能需要维护状态"><span class="toc-number">2.5.2.6.</span> <span class="toc-text">6 . 消费者可能需要维护状态</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-长时间处理"><span class="toc-number">2.5.2.7.</span> <span class="toc-text">7. 长时间处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-仅一次传递"><span class="toc-number">2.5.2.8.</span> <span class="toc-text">8. 仅一次传递</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#数据管道和流式处理（了解即可）"><span class="toc-number">3.</span> <span class="toc-text">数据管道和流式处理（了解即可）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据管道基本概念"><span class="toc-number">3.1.</span> <span class="toc-text">数据管道基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据管道需要考虑的问题"><span class="toc-number">3.1.1.</span> <span class="toc-text">数据管道需要考虑的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#及时性"><span class="toc-number">3.1.1.1.</span> <span class="toc-text">及时性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#可靠性"><span class="toc-number">3.1.1.2.</span> <span class="toc-text">可靠性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#高吞吐量和动态吞吐量"><span class="toc-number">3.1.1.3.</span> <span class="toc-text">高吞吐量和动态吞吐量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据格式"><span class="toc-number">3.1.1.4.</span> <span class="toc-text">数据格式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#流式处理基本概念"><span class="toc-number">3.2.</span> <span class="toc-text">流式处理基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据流"><span class="toc-number">3.2.1.</span> <span class="toc-text">数据流</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#事件流是有序的"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">事件流是有序的</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#不可变的数据记录"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">不可变的数据记录</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#事件流是可重播的"><span class="toc-number">3.2.1.3.</span> <span class="toc-text">事件流是可重播的</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是流式处理"><span class="toc-number">3.2.2.</span> <span class="toc-text">什么是流式处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#请求与响应"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">请求与响应</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#批处理"><span class="toc-number">3.2.2.2.</span> <span class="toc-text">批处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#流式处理"><span class="toc-number">3.2.2.3.</span> <span class="toc-text">流式处理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#流式处理中的基本概念"><span class="toc-number">3.2.3.</span> <span class="toc-text">流式处理中的基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#时间"><span class="toc-number">3.2.3.1.</span> <span class="toc-text">时间</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#事件时间"><span class="toc-number">3.2.3.1.1.</span> <span class="toc-text">事件时间</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#日志追加时间"><span class="toc-number">3.2.3.1.2.</span> <span class="toc-text">日志追加时间</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#处理时间"><span class="toc-number">3.2.3.1.3.</span> <span class="toc-text">处理时间</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#状态"><span class="toc-number">3.2.3.2.</span> <span class="toc-text">状态</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#本地状态或内部状态"><span class="toc-number">3.2.3.2.1.</span> <span class="toc-text">本地状态或内部状态</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#外部状态"><span class="toc-number">3.2.3.2.2.</span> <span class="toc-text">外部状态</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#流和表区别"><span class="toc-number">3.2.3.3.</span> <span class="toc-text">流和表区别</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#流式处理的常见场景"><span class="toc-number">3.2.4.</span> <span class="toc-text">流式处理的常见场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka流式处理实战"><span class="toc-number">3.2.5.</span> <span class="toc-text">Kafka流式处理实战</span></a></li></ol></li></ol></li>




<script src="/js/search.js"></script>
<script type="text/javascript">
    //theme config datas
    var copyrightObj = {};
    copyrightObj.enable = 'true';
    copyrightObj.triggerCopyLength = '200';
    copyrightObj.appendText = '商业转载请联系作者获得授权,非商业转载请注明出处 © example';
    var leancloudObj = {};
    leancloudObj.enable = 'false';
    leancloudObj.className = 'BlogCounter';
    leancloudObj.limits = '10';
</script>
<script type="text/javascript">
    var search = {};
    var search_path = "search.xml";
    if (!search_path) {
        search_path = "search.xml";
    }
    search.path = "/" + search_path;
    search.func =  _ajax.init();
</script>
<script src="/js/app.js"></script>


</body>
</html>