<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小小杰博客</title>
  
  <subtitle>锦绣前程</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ellenjack.github.io/"/>
  <updated>2020-04-10T14:23:21.156Z</updated>
  <id>https://ellenjack.github.io/</id>
  
  <author>
    <name>lill</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>排序算法的原理、实现和比较</title>
    <link href="https://ellenjack.github.io/2020/04/10/informal-5/"/>
    <id>https://ellenjack.github.io/2020/04/10/informal-5/</id>
    <published>2020-04-10T13:41:50.000Z</published>
    <updated>2020-04-10T14:23:21.156Z</updated>
    
    <content type="html"><![CDATA[<h1 id="排序算法概述"><a href="#排序算法概述" class="headerlink" title="排序算法概述"></a>排序算法概述</h1><p>排序就是将一组对象按照某种逻辑顺序重新排列的过程。比如，订单按照日期排序的——这种排序很可能使用了某种排序算法。在计算时代早期，大家普遍认为30% 的计算周期都用在了排序上。如果今天这个比例降低了，可能的原因之一是如今的排序算法更加高效，而并非排序的重要性降低了。现在计算机的广泛使用使得数据无处不在，而整理数据的第一步通常就是进行排序。几乎所有的计算机系统都实现了各种排序算法以供系统和用户使用。</p><p>即使你只是使用标准库中的排序函数，学习排序算法仍然有三大实际意义：</p><ul><li><p> IT从业人员必备技能，也是互联网公司面试的必考点；</p></li><li><p> 类似的技术也能有效解决其他类型的问题；</p></li><li><p> 排序算法常常是我们解决其他问题的第一步。</p></li></ul><p>排序在商业数据处理和现代科学计算中有着重要的地位，它能够应用于事物处理、组合优化、天体物理学、分子动力学、语言学、基因组学、天气预报和很多其他领域。其中一种排序算法（快速排序）甚至被誉为20 世纪科学和工程领域的十大算法之一。</p><p>数据结构和算法中，关于排序有十大算法，包括冒泡排序，简单选择排序，简单插入排序，归并排序，堆排序，快速排序、希尔排序、计数排序，基数排序，桶排序。</p><p>一般在面试中最常考的是快速排序和归并排序，并且经常有面试官要求现场写出这两种排序的代码。对这两种排序的代码一定要信手拈来才行。对于其他排序可能会要求比较各自的优劣、各种算法的思想及其使用场景，还有要知道算法的时间和空间复杂度。</p><p>通常查找和排序算法的考察是面试的开始，如果这些问题回答不好，估计面试官都没有继续面试下去的兴趣都没了。所以想开个好头就要把常见的排序算法思想及其特点要熟练掌握，有必要时要熟练写出代码。我们将由易到难学习这十种算法。</p><h1 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h1><p>冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为相关的元素会经由交换慢慢“浮”到数列的顶端。 </p><p>基本思路：</p><p>1、比较相邻的元素。如果第一个比第二个大(小)，就交换它们两个；</p><p>2、对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大(小)的数；</p><p>3、针对所有的元素重复以上的步骤，除了最后一个；</p><p>重复步骤1~2，直到排序完成。</p><h2 id="冒泡降序示例："><a href="#冒泡降序示例：" class="headerlink" title="冒泡降序示例："></a>冒泡降序示例：</h2><p>原始数组：   <img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0cbivgrj308o02omx5.jpg" alt>                         </p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp1c176enj30n204gmxn.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0ddorucj30n2030gm3.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0djlpmbj30n202u3yy.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0drs9urj30n203yt96.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0dykmz6j30n203w0t2.jpg" alt></p><h1 id="简单选择排序"><a href="#简单选择排序" class="headerlink" title="简单选择排序"></a>简单选择排序</h1><p>选择排序的思想其实和冒泡排序有点类似，都是在一次排序后把最小的元素放到最前面。但是过程不同，冒泡排序是通过相邻的比较和交换。而选择排序是通过对整体的选择。</p><p>举个例子，对5,3,8,6,4这个无序序列进行简单选择排序，首先要选择5以外的最小数来和5交换，也就是选择3和5交换，一次排序后就变成了3,5,8,6,4.对剩下的序列继续进行选择和交换，最终就会得到一个有序序列。其实选择排序可以看成冒泡排序的优化，因为其目的相同，只是选择排序只有在确定了最小数的前提下才进行交换，大大减少了交换的次数。</p><p><strong>具体步骤：</strong></p><p>首先，找到数组中最大（小）的那个元素；</p><p>其次，将它和数组的第一个元素交换位置（如果第一个元素就是最大（小）元素那么它就和自己交换）；</p><p>再次，在剩下的元素中找到最大（小）的元素，将它与数组的第二个元素交换位置。如此往复，直到将整个数组排序。</p><h2 id="简单选择排序（降序）示例"><a href="#简单选择排序（降序）示例" class="headerlink" title="简单选择排序（降序）示例"></a>简单选择排序（降序）示例</h2><p>原始数组：   <img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0eezrn2j309w02gdfr.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0figcbqj309m03kq2z.jpg" alt>，Y是数组中最大的元素</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0fzm2bkj309i03gaa3.jpg" alt>，Y和数组的第一个元素E交换位置</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0g46bkgj309m03gaa3.jpg" alt>，在剩下的数组中继续寻找最大的元素，找到了O</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0gjzthoj309g03edfv.jpg" alt>O和数组的第二个元素N交换位置</p><p>如此重复，最后形成降序后数组： <img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0gothagj309e022747.jpg" alt></p><h1 id="简单插入排序"><a href="#简单插入排序" class="headerlink" title="简单插入排序"></a>简单插入排序</h1><p>插入排序不是通过交换位置而是通过比较找到合适的位置插入元素来达到排序的目的的。相信大家都有过打扑克牌的经历，特别是牌数较大的。在分牌时可能要整理自己的牌，牌多的时候怎么整理呢？就是拿到一张牌，找到一个合适的位置插入。这个原理其实和插入排序是一样的。</p><p>举个例子，我们将要收到5,3,4,,8,6这几张牌，我们先收到5这张牌，毫无疑问，这张牌的位置是正确的，没必要整理。接着收到了牌3，然后3要插到5前面，把5后移一位，变成3,5。接着又收到了牌4，现在我们会怎么做？把4插入到5前面，把5后移一位。</p><p><strong>具体步骤：</strong></p><p>l 对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p><p>l 为了给要插入的元素腾出空间，我们需要将插入位置之后的已排序元素在都向右移动一位。</p><p>插入排序所需的时间取决于输入中元素的初始顺序。例如，对一个很大且其中的元素已经有序（或接近有序）的数组进行排序将会比对随机顺序的数组或是逆序数组进行排序要快得多。</p><p>总的来说，插入排序对于部分有序的数组十分高效，也很适合小规模数组。</p><h2 id="简单插入排序（降序）示例"><a href="#简单插入排序（降序）示例" class="headerlink" title="简单插入排序（降序）示例"></a>简单插入排序（降序）示例</h2><p>原始数组： <img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0h7fgkuj309w02gdfr.jpg" alt>  我们总是认为原始数组的第一个元素已经是有序的了，于是从第二个元素开始进行排序。</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0hgeu4gj309i05aglr.jpg" alt> 第二个元素是N，比E大，所以将E后移一位，N插入E原来的位置</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0i1q5qsj309u056mxb.jpg" alt>第三个元素是J，在已经排序的序列N、E中，J比N小，N不动，继续比较，J比E大，所以将E后移一位，J插入E原来的位置</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0ijqpwpj30b805gt8v.jpg" alt> 第四个元素是O，在已经排序的序列N、J、E中，O比N大，O应该插在N的前面，所以将N、J、E全部后移一位，O插入N原来的位置。</p><p>如此重复，最后形成降序后数组： <img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0iwx614j309e022747.jpg" alt></p><h1 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h1><p>一种基于插入排序的快速的排序算法(请大家先学习插入排序，了解基本的插入排序的思想。对于大规模乱序数组插入排序很慢，因为元素只能一点一点地从数组的一端移动到另一端。例如，如果主键最小的元素正好在数组的尽头，要将它挪到正确的位置就需要N-1 次移动。</p><p>希尔排序为了加快速度简单地改进了插入排序，也称为缩小增量排序，同时该算法是冲破O(n^2）的第一批算法之一。</p><p>希尔排序是把待排序数组按一定增量的分组，对每组使用直接插入排序算法排序；然后缩小增量继续分组排序，随着增量逐渐减少，每组包含的元素越来越多，当增量减至 1 时，整个数组恰被分成一组，排序便完成了。这个不断缩小的增量，就构成了一个增量序列。</p><h2 id="希尔排序（降序）示例"><a href="#希尔排序（降序）示例" class="headerlink" title="希尔排序（降序）示例"></a>希尔排序（降序）示例</h2><p>我们选择增量的计算方式为：gap=数组的长度/2，缩小增量继续以gap = gap/2的方式，于是形成的增量序列为{7,3,1}。</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0k1z0ykj30n201imxe.jpg" alt></p><p>1、第一个增量为7，则原始数组被分为7组，比如{35,72}为一组，{63,1}为一组，组内的每个元素之间数组下标之差为7，这7组分别进行插入排序</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0k8wq1zj30n2038jrp.jpg" alt></p><p>组内插入排序之后：</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0kk6dmqj30n201m3yp.jpg" alt></p><p>2、第二个增量为3，则第一次排序后数组被分为3组，比如{72,43,53,48,18}为一组，组内的每个元素之间数组下标之差为3，这3组分别进行插入排序</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0ksdw43j30n203ujru.jpg" alt></p><p>组内插入排序之后：</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0l0n8djj30n201oaa9.jpg" alt></p><p>3、</p><p>第三个增量为1，则第二次排序后数组被分为1组，进行插入排序，形成最后的排序数组</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0l94mo8j30n201mdg1.jpg" alt></p><h2 id="希尔排序中的增量序列"><a href="#希尔排序中的增量序列" class="headerlink" title="希尔排序中的增量序列"></a>希尔排序中的增量序列</h2><p>在先前较大的增量下每个子序列的规模都不大,用直接插入排序效率都较高，尽管在随后的增量递减分组中子序列越来越大,由于整个序列的有序性也越来越明显,则排序效率依然较高。</p><p>从理论上说，只要一个数组是递减的，并且最后一个值是1，都可以作为增量序列使用。有没有一个步长序列,使得排序过程中所需的比较和移动次数相对较少,并且无论待排序列记录数有多少,算法的时间复杂度都能渐近最佳呢？但是目前从数学上来说，无法证明某个序列是“最好的”。</p><p><strong>常用的增量序列有：</strong></p><p>希尔增量序列 ：{N/2, (N / 2)/2, …, 1}，其中N为原始数组的长度，这是最常用的序列，但却不是最好的</p><p>Hibbard序列：{2^k-1, …, 3,1}</p><p>Sedgewick序列：{… , 109 , 41 , 19 , 5，1} 表达式为</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0lf6kpsj30bm018wed.jpg" alt> </p><h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h1><p>归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。</p><p>若将两个有序表合并成一个有序表，称为2-路归并，与之对应的还有多路归并。</p><p>对于给定的一组数据，利用递归与分治技术将数据序列划分成为越来越小的半子表，在对半子表排序后，再用递归方法将排好序的半子表合并成为越来越大的有序序列。</p><p>为了提升性能，有时我们在半子表的个数小于某个数（比如15）的情况下，对半子表的排序采用其他排序算法，比如插入排序。</p><h2 id="归并排序（降序）示例"><a href="#归并排序（降序）示例" class="headerlink" title="归并排序（降序）示例"></a>归并排序（降序）示例</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0lr2u3cj30h601w0su.jpg" alt></p><p>先讲数组划分为左右两个子表：</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0lw4sb3j309y01swee.jpg" alt>，<img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0m2yv42j30aa01q0sn.jpg" alt> </p><p>然后继续左右两个子表拆分：</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0mawdwaj30n201qdfv.jpg" alt></p><p>对最后的拆分的子表，两两进行排序</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0mlsje6j30n201wgln.jpg" alt></p><p>对有序的子表进行排序和比较合并</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0muoim9j30n2042dg6.jpg" alt></p><p>对合并后的子表继续比较合并</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0mzx9urj30fg05mt9c.jpg" alt></p><h1 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h1><p>快速排序被誉为20 世纪科学和工程领域的十大算法之一。快速排序（Quicksort）是对冒泡排序的一种改进，也是采用分治法的一个典型的应用。</p><p>首先任意选取一个数据（比如数组的第一个数）作为关键数据，我们称为基准数，然后将所有比它小的数都放到它前面，所有比它大的数都放到它后面，这个过程称为一趟快速排序，也称为分区（partition）操作。在实际实现时，一般会在原数组上直接操作。 </p><p>通过一趟快速排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。</p><p>为了提升性能，有时我们在分割后独立的两部分的个数小于某个数（比如15）的情况下，会采用其他排序算法，比如插入排序。</p><h2 id="快速排序原理"><a href="#快速排序原理" class="headerlink" title="快速排序原理"></a>快速排序原理</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp18pl5fqj30ha01wwel.jpg" alt> </p><p>1、选择数组的第一个数35为基准，切分数组，将所有比35大的都放到35前面，所有比35小的，放到35后面，进行快速排序<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0ncqnfwj30ia03wt93.jpg" alt></p><p>于是数组变成了：<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0nqalm3j30f401uaa4.jpg" alt></p><p>2、对35左边的子数组，我们以63为基准数，进行快速排序，于是左边数组变为：<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0nwjolaj309s01sglj.jpg" alt></p><p>对35右边的子数组，我们以9为基准数，进行快速排序，于是左边数组变为：<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0o71cp8j305001sq2s.jpg" alt></p><p>3、继续快速排序下去，最终形成有序数组<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0og8isdj30dq01qt8r.jpg" alt></p><p>以上是快速排序的一个基本原理，看起来仿佛需要额外的数组进行辅助，但其实在实现的时候，并不需要，只要借助一个分割指示器就可以了。</p><h2 id="快速排序（升序）实现图示"><a href="#快速排序（升序）实现图示" class="headerlink" title="快速排序（升序）实现图示"></a>快速排序（升序）实现图示</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0p1azzij30lg02ct8z.jpg" alt></p><p>随机选择数组的一个数，比如48为基准，切分数组 同时引入一个分割指示器，这个分割指示器初始值是数组头元素下标减一，这里就是-1。同时交换基准数和数组尾元素 。<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0pcs30mj30ji044t9b.jpg" alt></p><p>进行数组的遍历，将数组中的元素和基准数进行比较，为了满足所有比基准数小的数都放到基准数前面，所有比基准数大的数都放到基准数后面，我们需要遵循着这样的规则：</p><p>当前元素小于等于基准数时，分割指示器右移一位 ，当前元素下标小于等于分割指示器时当前元素保持不动，当前元素下标大于分割指示器时，当前元素和分割指示器所指元素交换；</p><p>当前元素大于等于基准数，分割指示器保持不变 ，元素也无需交换。</p><p>所以接下来随着数组的遍历，其中元素的变动情况是：</p><p>1、</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0pvpd2cj30ey04m74u.jpg" alt></p><p>2、</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0q21wm7j30eq04s3yy.jpg" alt></p><p>3、</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0q97bvpj30fa04uq3j.jpg" alt>，交换63和11</p><p>4、</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0qfhjinj30fa058q3k.jpg" alt></p><p>5、</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0qlquptj30f004qgm8.jpg" alt>，交换63和9</p><p>6、</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0qu39cnj30ds04ot96.jpg" alt> </p><p>7、</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0r20z6rj30gg068wfb.jpg" alt>分割指示器指向了63，当前元素是24，于是交换63和24</p><p>8、</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0ra28dxj30g404e74p.jpg" alt></p><p>9、</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0rii4vfj30h6062js5.jpg" alt>，分割指示器指向了86，当前元素是48，于是交换86和48</p><p>10、</p><p>完成了本次分区操作<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0rvv22nj30h402gq34.jpg" alt></p><p>11、所有比基准数48小的数都已到它左边，所有比基准数48大的数都已到它右边。将左边和右边再按快速排序继续排序下去，就可完成最终的排序。</p><h2 id="快速排序中的基准数"><a href="#快速排序中的基准数" class="headerlink" title="快速排序中的基准数"></a>快速排序中的基准数</h2><p>基准的选取：最优的情况是基准值刚好取在无序区的中间，这样能够最大效率地让两边排序，同时最大地减少递归划分的次数，但是一般很难做到最优。基准的选取一般有三种方式，选取数组的第一个元素，选取数组的最后一个元素，以及选取第一个、最后一个以及中间的元素的中位数（如4 5 6 7, 第一个4, 最后一个7, 中间的为5, 这三个数的中位数为５, 所以选择5作为基准）。</p><p>Dual-Pivot快排：两个基准数的快速排序算法，其实就是用两个基准数, 把整个数组分成三份来进行快速排序，在这种新的算法下面，比经典快排从实验来看节省了10%的时间。</p><h1 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h1><p>许多应用程序都需要处理有序的元素，但不一定要求他们全部有序，或者不一定要一次就将他们排序，很多时候，我们每次只需要操作数据中的最大元素（最小元素），那么有一种基于二叉堆的数据结构可以提供支持。</p><p>所谓二叉堆，是一个完全二叉树的结构，同时满足堆的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。在一个二叉堆中，根节点总是最大（或者最小）节点。</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0sbkv4kj30e2074wep.jpg" alt>，这就是一个典型的二叉堆。</p><p>堆排序算法就是抓住了这一特点，每次都取堆顶的元素，然后将剩余的元素重新调整为最大（最小）堆，依次类推，最终得到排序的序列。</p><h2 id="补充知识：完全二叉树"><a href="#补充知识：完全二叉树" class="headerlink" title="补充知识：完全二叉树"></a>补充知识：完全二叉树</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0skgdurj30n205k74n.jpg" alt></p><p><strong>二叉树：</strong>是每个结点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）</p><p><strong>满二叉树：</strong>除最后一层无任何子<a href="https://baike.baidu.com/item/节点/865052" target="_blank" rel="noopener">节点</a>外，每一层上的所有结点都有两个子结点二叉树。</p><p><strong>完全二叉树：</strong>是由<a href="https://baike.baidu.com/item/满二叉树" target="_blank" rel="noopener">满二叉树</a>而引出来的，如果我们将一棵满二叉树由上到下，由左至右，每个结点都用数字编号，另外一个二叉树也同样由上到下，由左至右，每个结点都用数字编号，二叉树中的每个结点都可以在满二叉树中一一对应，我们称这个二叉树为完全二叉树。所以一棵满二叉树一定是个完全二叉树，而完全二叉树不是满二叉树。</p><p>完全二叉树的数组表示法 </p><table><thead><tr><th><strong>A</strong></th><th><strong>B</strong></th><th><strong>C</strong></th><th><strong>D</strong></th><th><strong>E</strong></th><th><strong>F</strong></th></tr></thead><tbody><tr><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr></tbody></table><p>A:0 B:1 C:2 B=2<em>0+1 C=2</em>(0+1)</p><p>B:1 D:3 E:4 D=2<em>1+1 E = 2</em>(1+1)</p><p>由此可以退出两个重要的推论：</p><p><strong>推论</strong> <strong>1</strong>：对于位置为K的结点  左子结点=2<em>k+1 右子结点=2</em>(k+1)</p><p>验证：C:2 2<em>2+1=5 2</em>(k+1)=6 </p><p><strong>推论</strong> <strong>2</strong>：最后一个非叶节点的位置为 (N/2)-1，N为数组长度。 </p><h2 id="堆排序（降序）示例"><a href="#堆排序（降序）示例" class="headerlink" title="堆排序（降序）示例"></a>堆排序（降序）示例</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0u30hc8j30h601qwek.jpg" alt></p><p>将该数组视为一个完全二叉树 ，则是：<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0u8ufk1j30bu08i3yq.jpg" alt></p><h3 id="堆的初始化"><a href="#堆的初始化" class="headerlink" title="堆的初始化"></a>堆的初始化</h3><p>很明显，这个二叉树不符合最大堆的定义，需要初始化为最大堆，从<strong>最后一个非叶节点</strong>开始，从下到上，从右到左调整 </p><p>最后一个非叶节点在8/2-1=3的位置，也就是值为9的元素，将它和自己的叶节点进行比较并交换 </p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0uvqlzoj30k406aq3j.jpg" alt></p><p>48和63调整到位后，进而调整根节点35，</p><p>  <img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0vc2g6hj309s06a3yo.jpg" alt>将35和它的子结点86交换，此时86变成根结点，35则变成子结点。很明显35和11、63组成的树不符合二叉堆的定义，此时需要再次调整35的位置：</p><p>  <img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0vib5inj30a406edfz.jpg" alt>此时就完成了堆的初始化，最大的数已经成为了根节点 。</p><h3 id="正式开始堆排序的过程"><a href="#正式开始堆排序的过程" class="headerlink" title="正式开始堆排序的过程"></a>正式开始堆排序的过程</h3><p>此时将堆顶的86和尾元素9交换</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0ujor32j30de08uwes.jpg" alt> ，86现在处于数组下标为7的位置，不再将86视为二叉树的一部分。9处于根结点，很明显，此时需要调整元素的位置 使之重新变成二叉堆 </p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0w4jl4fj30ka05yaao.jpg" alt></p><p>继续将堆顶63和尾元素48交换，63现在处于数组下标为6的位置，不再将63视为二叉树的一部分。48处于根结点，很明显，此时需要调整元素的位置 使之重新变成二叉堆</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0wqnxvzj30jk06qmxw.jpg" alt></p><p>经过反复将堆顶元素和尾元素交换，并调整二叉堆的过程，最后数据变为</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0xzonxyj30by01gmx5.jpg" alt> </p><p><strong>如果需要进行降序，改用最小堆即可。</strong></p><h1 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序</h1><p>计数排序是一个排序时不比较元素大小的排序算法。</p><p>计数排序对一定范围内的整数排序时候的速度非常快，一般快于其他排序算法。但计数排序局限性比较大，只限于对整数进行排序，而且待排序元素值分布较连续、跨度小的情况。</p><p>如果一个数组里所有元素都是整数，而且都在0-K以内。那对于数组里每个元素来说，如果能知道数组里有多少项小于或等于该元素，就能准确地给出该元素在排序后的数组的位置。</p><p>比如有个数组 <img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0y8kx6rj30h402st8u.jpg" alt></p><p>对于这个数组来说，元素5之前有8个元素小于等于5（含5本身），因此排序后5所在的位置肯定是7.只要构造一个（5+1）大小的数组，里面存下所有对应A中每个元素之前的元素个数，就能在线性时间内完成排序。</p><h2 id="计数排序（升序）示例"><a href="#计数排序（升序）示例" class="headerlink" title="计数排序（升序）示例"></a>计数排序（升序）示例</h2><p>1、初始化一个大小为（5+1）的计数数组（所有元素初始值为0），遍历整个原始数组，将原始数组中每个元素值对应计数数组下标中的元素大小+1 </p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0ykp5kij30e005uwew.jpg" alt></p><p>比如遍历数组的时候，发现原始数组有2个0，则在计数数组的下标为0的元素改为2，原始数组有3个3，则在计数数组的下标为3的元素改为3，</p><p>2、遍历计数数组，先访问第0个元素。第0个元素，下标为0，值为2，那么就应该将原始数组中第0个位置改写为0。<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0yu1p5uj30ey04yaad.jpg" alt></p><p>3、计数数组第0个元素，值为由2变为1，但是还没有归零，因此，计数数组访问索引不进行移动，而原始数组的访问索引应该向前移动一位，到了第1个位置，于是我们将原始数组第1个位置也改写为0。<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0z0rmv1j30e004qaaf.jpg" alt></p><p>4、计数数组第0个元素，值已经归零，所以，计数数组访问索引向前移动一位，到了第1个位置，但是这个位置的元素值为0，无需处理，所以访问索引继续向前移动，到了第2个位置。这个位置上，值为2，此时原始数组的访问索引又向前移动了一位，到了第2个位置上，于是我们将原始数组的第二个位置改写为2。<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0za662dj30du04ijrq.jpg" alt></p><p>5、计数数组第2个元素，值为由2变为1，但是还没有归零，因此，计数数组访问索引不进行移动，而原始数组的访问索引应该向前移动一位，到了第3个位置，于是我们将原始数组第3个位置也改写为2。<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp0zl8bi0j30eo04waaf.jpg" alt></p><p>6、计数数组第2个元素，值已经归零，所以，计数数组访问索引向前移动一位，到了第3个位置，。这个位置上，值为3，按照我们前面所说的方法，原始数组的第4,5,6个元素都应该改写为3，同时计数数组中的第3个元素，值变为3.<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp10d5zkij30ee04qgly.jpg" alt><br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp10kna7hj30dw04mq3a.jpg" alt><br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp10qmrjtj30e604k0t3.jpg" alt></p><p>7、计数数组到了第4个位置，元素值为0，无需处理，所以访问索引继续向前移动，到了第5个位置。这个位置上，值为1，此时原始数组的访问索引已经来到了第7个位置，这个位置的元素值改写为5。至此完成了排序。<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp10y31hoj30dw04i3yu.jpg" alt></p><h2 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h2><p>实际应用中我们会同时找出数组中的max和min，主要是为了尽量节省空间。试想[1003, 1001, 1030, 1050]这样的数据要排序，真的需要建立长度为1050 + 1的数组吗？我们只需要长度为1050 - 1003 + 1= 48的数组（先不考虑额外+1的长度），就能囊括从最小到最大元素之间的所有元素了。</p><p>如果待排序数组的元素值跨度很大，比如[99999, 1, 2]，为三个元素排序要使用99999 - 1 + 1的空间，实在是浪费。所以计数排序适用于待排序元素值分布较连续、跨度小的情况。</p><h1 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h1><p>桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，利用某种函数的映射关系将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序）。</p><p>基本步骤是：</p><p>l 根据输入建立适当个数的桶，每个桶可以存放某个范围内的元素；</p><p>l 将落在特定范围内的所有元素放入对应的桶中；</p><p>l 对每个非空的桶中元素进行排序，可以选择通用的排序方法，比如插入、快排；</p><p>l 按照划分的范围顺序，将桶中的元素依次取出。排序完成。 </p><p>桶排序利用函数的映射关系，减少了几乎所有的比较工作。实际上，桶排序的f(k)值的计算，其作用就相当于快排中划分，已经把大量数据分割成了基本有序的数据块(桶)。然后只需要对桶中的少量数据做先进的比较排序即可。</p><h2 id="桶排序（降序）示例"><a href="#桶排序（降序）示例" class="headerlink" title="桶排序（降序）示例"></a>桶排序（降序）示例</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp114zgg2j30kw01wjrj.jpg" alt></p><p>我们可以建立5个桶，每个桶按范围顺序依次是[0, 10)、[10, 20)……[40, 49)，注意是左闭右开区间，对于待排序数组，5,9会被放到[0, 10)这个桶中，…….，48会被放到[40, 49)这个桶中</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp11ditiwj30eg07adgf.jpg" alt></p><p>对这5个桶中的元素分别排序。 依次取出5个桶中元素，得到排序后的序列。 </p><h1 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h1><p>常见的数据元素一般是由若干位组成的，比如字符串由若干字符组成，整数由若干位0~9数字组成。基数排序按照从右往左的顺序，依次将每一位都当做一次关键字，然后按照该关键字对数组排序，同时每一轮排序都基于上轮排序后的结果；当我们将所有的位排序后，整个数组就达到有序状态。比如对于数字2985，从右往左就是先以个位为关键字进行排序，然后是十位、百位、千位，总共需要四轮。基数排序不是基于比较的算法。</p><p>基数是什么意思？对于十进制整数，每一位都只可能是0~9中的某一个，总共10种可能。那10就是它的基，同理二进制数字的基为2；对于字符串，如果它使用的是8位的扩展ASCII字符集，那么它的基就是256。</p><h2 id="基数排序（降序）示例"><a href="#基数排序（降序）示例" class="headerlink" title="基数排序（降序）示例"></a>基数排序（降序）示例</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp11p217jj30n201o74i.jpg" alt></p><p>首先按个位排序<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp11ubmx6j30n204ogmf.jpg" alt></p><p>然后再按十位进行排序<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp11zv1ivj30n205mjs9.jpg" alt></p><h2 id="基数排序-vs-计数排序-vs-桶排序"><a href="#基数排序-vs-计数排序-vs-桶排序" class="headerlink" title="基数排序 vs 计数排序 vs 桶排序"></a>基数排序 vs 计数排序 vs 桶排序</h2><p>基数排序有两种方法：</p><p>l MSD 从高位开始进行排序</p><p>l LSD 从低位开始进行排序</p><p>这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异：</p><p>l 基数排序：根据键值的每位数字来分配桶</p><p>l 计数排序：每个桶只存储单一键值</p><p>l 桶排序：每个桶存储一定范围的数值</p><h1 id="外部排序"><a href="#外部排序" class="headerlink" title="外部排序"></a>外部排序</h1><p>有时，待排序的文件很大，计算机内存不能容纳整个文件，这时候对文件就不能使用内部排序了（我们一般的排序都是在内存中做的，所以称之为内部排序，而外部排序是指待排序的内容不能在内存中一下子完成，它需要做内外存的内容交换），外部排序常采用的排序方法也是归并排序，这种归并方法由两个不同的阶段组成：</p><p>1、采用适当的内部排序方法对输入文件的每个片段进行排序，将排好序的片段（成为归并段）写到外部存储器中（通常由一个可用的磁盘作为临时缓冲区），这样临时缓冲区中的每个归并段的内容是有序的。</p><p>2、利用归并算法，归并第一阶段生成的归并段，直到只剩下一个归并段为止。</p><p>例如要对外存中4500个记录进行归并，而内存大小只能容纳750个记录，在第一阶段，我们可以每次读取750个记录进行排序，这样可以分六次读取，进行排序，可以得到六个有序的归并段</p><p>每个归并段的大小是750个记录，记住，这些归并段已经全部写到临时缓冲区（由一个可用的磁盘充当）内了，这是第一步的排序结果。</p><p>完成第二步该怎么做呢？这时候归并算法就有用处了，算法描述如下：</p><p>1、将内存空间划分为三份，每份大小250个记录，其中两个用作输入缓冲区，另外一个用作输出缓冲区。首先对Segment_1和Segment_2进行归并，先从每个归并段中读取250个记录到输入缓冲区，对其归并，归并结果放到输出缓冲区，当输出缓冲区满后，将其写道临时缓冲区内，如果某个输入缓冲区空了，则从相应的归并段中再读取250个记录进行继续归并，反复以上步骤，直至Segment_1和Segment_2全都排好序，形成一个大小为1500的记录，然后对Segment_3和Segment_4、Segment_5和Segment_6进行同样的操作。</p><p>2、对归并好的大小为1500的记录进行如同步骤1一样的操作，进行继续排序，直至最后形成大小为4500的归并段，至此，排序结束。</p><h1 id="排序算法总结"><a href="#排序算法总结" class="headerlink" title="排序算法总结"></a>排序算法总结</h1><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdp12876c2j30n209u76t.jpg" alt></p><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><h3 id="算法的稳定性"><a href="#算法的稳定性" class="headerlink" title="算法的稳定性"></a>算法的稳定性</h3><p><strong>稳定：</strong>如果a原本在b前面，而a=b，排序之后a仍然在b的前面；</p><p><strong>不稳定：</strong>如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面；</p><p>排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，前一个键排序的结果可以为后一个键排序所用。</p><h3 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h3><p>人总是贪婪的，在做一件事的时候，我们总是期望着可以付出最少的时间、精力或者金钱来获得最大的回报，这个类比到算法上也同样适用，那就是花最少的时间和最少的存储做成最棒的解决办法，所以好的算法应该具备时效高和存储低的特点。这里的「时效」是指时间效率，也就是算法的执行时间，对于同一个问题的多种不同解决算法，执行时间越短的算法效率越高，越长的效率越低；「存储」是指算法在执行的时候需要的存储空间，主要是指算法程序运行的时候所占用的内存空间。</p><p>从我们日常的经验就可以得知，一般来说，如果处理一件事情，这件事情越大，那么我们处理所花费的时间和精力就越多，在算法中同样也如此，所以我们在讨论算法复杂度时，往往需要考虑这个待处理数据的大小，我们把待处理数据的大小称之为数据的规模大小。讨论一个算法的复杂度，往往也就是寻找程序的运行时间是如何随着问题规模的变化而变化。</p><p>而有的时候算法的运行时间还取决于数据本身分布性质而不仅仅是「问题的规模大小」。对于这样的算法，我们把它们的执行情况分为「最优情况」、「最坏情况」和「平均情况」来讨论。</p><p>某个特定的数据集能让算法的执行情况极好，这就是最「最好情况」，而另一个不同的数据会让算法的执行情况变得极差，这就是「最坏情况」。不过在大多数情况下，算法的执行情况都介于这两种极端情况之间，也就是「平均情况」。</p><p>对于「最优情况」，没有什么大的价值，因为它没有提供什么有用信息，反应的只是最乐观最理想的情况，没有参考价值。「平均情况」是对算法的一个全面评价，因为它完整全面的反映了这个算法的性质，但从另一方面来说，这种衡量并没有什么保证，并不是每个运算都能在这种情况内完成。而对于「最坏情况」，它提供了一种保证，这个保证运行时间将不会再坏了，所以一般我们所算的时间复杂度是最坏情况下的时间复杂度，这和我们平时做事要考虑到最坏的情况是一个道理</p><h4 id="时间复杂度："><a href="#时间复杂度：" class="headerlink" title="时间复杂度："></a>时间复杂度：</h4><p>一个算法执行所耗费的时间。</p><h4 id="空间复杂度："><a href="#空间复杂度：" class="headerlink" title="空间复杂度："></a>空间复杂度：</h4><p>对一个算法在运行过程中临时占用存储空间大小的量度。</p><h4 id="常见复杂度"><a href="#常见复杂度" class="headerlink" title="常见复杂度"></a>常见复杂度</h4><p>在各种不同算法中，若算法中语句执行次数(占用空间)为一个常数，则复杂度为O(1)； </p><p>当一个算法的复杂度与以2为底的n的对数成正比时，可表示为O(log n)；当一个算法的复杂度与n成线性比例关系时，可表示为O (n)，依次类推。</p><p><strong>由小到大：</strong>O(1) &lt; O(logn) &lt; O(n) &lt; O(nlogn) &lt; O(n^2) &lt; O(n^3) &lt; O(2^n) </p><h2 id="排序算法时间复杂度助记"><a href="#排序算法时间复杂度助记" class="headerlink" title="排序算法时间复杂度助记"></a>排序算法时间复杂度助记</h2><p>冒泡、选择、插入排序需要两个for循环，每次只关注一个元素，平均时间复杂度为O(  )（外循环找元素O(n)，内循环找位置O(n)）</p><p>快速、归并、希尔、堆基于分治思想，log以2为底，平均时间复杂度往往和O(nlogn)（外循环找元素O(n)，内循环找位置O(logn)）相关</p><p>基数排序时间复杂度为O（N*M），其中N为数据个数，M为数据位数 </p><h2 id="快速排序的优势"><a href="#快速排序的优势" class="headerlink" title="快速排序的优势"></a>快速排序的优势</h2><p>从平均时间来看，快速排序是效率最高的：</p><p>快速排序中平均时间复杂度O(nlog n)，这个公式中隐含的常数因子很小，比归并排序的O(nlog n)中的要小很多，所以大多数情况下，快速排序总是优于合并排序的。</p><p>而堆排序的平均时间复杂度也是O(nlog n)，但是堆排序存在着重建堆的过程，它把根节点移除后，把最后的叶子结点拿上来，是为了重建堆，但是，拿上的值是要比它的两个叶子结点要差很多的，它要比较很多次，才能回到合适的位置。堆排序就会有很多的时间耗在堆调整上。</p><p>虽然快速排序的最坏情况为排序规模（n）的平方关系，但是这种最坏情况取决于每次选择的基准， 对于这种情况，已经提出了很多优化的方法，比如三取样划分和Dual-Pivot快排。</p><p>同时，当排序规模较小时，划分的平衡性容易被打破，而且频繁的方法调用超过了O(nlog n)为O(  )省出的时间，所以一般排序规模较小时，会改用插入排序或者其他排序算法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;排序算法概述&quot;&gt;&lt;a href=&quot;#排序算法概述&quot; class=&quot;headerlink&quot; title=&quot;排序算法概述&quot;&gt;&lt;/a&gt;排序算法概述&lt;/h1&gt;&lt;p&gt;排序就是将一组对象按照某种逻辑顺序重新排列的过程。比如，订单按照日期排序的——这种排序很可能使用了某种排序算
      
    
    </summary>
    
      <category term="随笔" scheme="https://ellenjack.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="排序" scheme="https://ellenjack.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>JVM的内存布局和垃圾回收机制</title>
    <link href="https://ellenjack.github.io/2020/04/08/informal-4/"/>
    <id>https://ellenjack.github.io/2020/04/08/informal-4/</id>
    <published>2020-04-08T08:24:49.000Z</published>
    <updated>2020-04-08T08:50:02.122Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdmgb6g26ij30w80ojgvn.jpg" alt></p><p><strong>Java虚拟机栈：</strong><br>每个方法在被调用时就会创建一个栈帧，每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程</p><p><strong>Java堆：</strong><br>是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，对象实例在这里分配内存。是垃圾收集器（GC）管理的主要区域</p><p><strong>方法区：</strong><br>存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据，运行时常量池（Runtime Constant Pool）是方法区的一部分。</p><p><strong>直接内存：</strong><br>直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdmg05tihcj31r50u0e2r.jpg" alt></p><p><strong>标记-清除算法(Mark-Sweep)</strong><br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdmg2ns7elj31en0u0qn2.jpg" alt></p><p><strong>复制算法（Copying)</strong><br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdmg3vaqz5j31ca0u0k40.jpg" alt></p><p><strong>标记-整理算法（Mark-Compact）</strong><br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdmg5u0m7ij31as0u0b29.jpg" alt></p><p><strong>算法都用上</strong><br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdmg7n9yedj31l60tq1kx.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/00831rSTly1gdmgb6g26ij30w80ojgvn.jpg&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Java虚拟机栈：&lt;/strong&gt;&lt;br&gt;每个方法在被调用时就会创建一个栈帧
      
    
    </summary>
    
      <category term="随笔" scheme="https://ellenjack.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="jvm" scheme="https://ellenjack.github.io/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>B+树：MySql数据库索引是如何实现的</title>
    <link href="https://ellenjack.github.io/2020/04/08/informal-3/"/>
    <id>https://ellenjack.github.io/2020/04/08/informal-3/</id>
    <published>2020-04-08T08:01:55.000Z</published>
    <updated>2020-04-08T08:09:27.590Z</updated>
    
    <content type="html"><![CDATA[<h2 id="索引的用处"><a href="#索引的用处" class="headerlink" title="索引的用处"></a>索引的用处</h2><p>MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。</p><p>当表中有大量记录时，若要对表进行查询，第一种搜索信息方式是全表搜索，是将所有记录一一取出，和查询条件进行一一对比，然后返回满足条件的记录，这样做会消耗大量数据库系统时间，并造成大量磁盘I/O操作；第二种就是在表中建立索引，然后在索引中找到符合查询条件的索引值，最后通过保存在索引中的ROWID（相当于页码）快速找到表中对应的记录。</p><h2 id="用平衡二叉树？"><a href="#用平衡二叉树？" class="headerlink" title="用平衡二叉树？"></a>用平衡二叉树？</h2><p>数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。</p><p>最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如二分查找、平衡二叉树查找。</p><p>从理论上来说，似乎没有什么问题，但是如果仔细考虑我们对数据库的使用，会发现，</p><p>第一，我们一个表中的数据存储量会很大，数据量在万以内的我们都认为这是个小数据量表，一般的表数据量都以十万计，百万级别的表也不在少数，用二叉树来索引的话，这个树就会是个很高很瘦的树，层次很深，查找的次数会有几十次次之多。</p><p>第二，因为数据量很大，相应的索引也会很大，不可能全部存储在内存中，数据库是做数据持久化的地方，索引文件不可能永驻内存，因此索引往往以索引文件的形式存储的磁盘上，</p><p>这样。索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。</p><p>这样磁盘存取也成为我们在设计索引时必须要考虑的主要因素之一。</p><h2 id="磁盘存取原理"><a href="#磁盘存取原理" class="headerlink" title="磁盘存取原理"></a>磁盘存取原理</h2><p>盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。</p><p>当需要从磁盘读取数据时，为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。</p><p>由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：</p><p><strong>当一个数据被用到时，其附近的数据也通常会马上被使用。</strong></p><p>由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。预读的长度一般为4k的整数倍(这个4K大小的数据块，称为页)。</p><h2 id="B树-平衡多路查找树-B-树"><a href="#B树-平衡多路查找树-B-树" class="headerlink" title="B树(平衡多路查找树, B-树)"></a>B树(平衡多路查找树, B-树)</h2><p>综上所述，有没有一种既可以避免二叉树这种搜寻深度过深，又可以充分利用磁盘预读原理的数据结构呢。这个就是B树了。</p><p>B树中一个节点可以允许有多个子节点，在实际使用时，一个B树节点的实际大小一般设为一个4K大小的页，这样每个节点只需要一次I/O就可以完全载入。</p><p>同时，B树的每个节点有多个key，并且以升序排列。这样在查找时就很方便了。 </p><p>大家可以从图上看到，存储了27个数据，允许7个子节点的B树的层次比存储了20个数据的平衡二叉树要少，数据越多，层次相对于平衡二叉树就越少，而且B树的允许的子节点个数越多，这个B树也就层次越少。</p><p>在硬盘上实际存储B树时，一个B树节点的实际大小一般设为一个4K大小的页，所以B树的允许子节点都非常大（通常在100到1000之间），所以即使存储大量的数据，B树的高度仍然比较小。</p><p>每个结点中存储了关键字（key）和关键字对应的数据（data），以及孩子结点的指针。<strong>我们将一个**</strong>key<strong><strong>和其对应的</strong></strong>data<strong>**称为一个记录</strong>。<strong>但为了方便描述，除非特别说明，后续文中就用**</strong>key<strong><strong>来代替（</strong></strong>key, value<strong>**）键值对这个整体</strong>。在数据库中我们将B树（和B+树）作为索引结构，可以加快查询速速，此时B树中的key就表示键，而data表示了这个键对应的条目在硬盘上的逻辑地址。</p><h2 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h2><p>Mysql等数据库系统实际使用的则是B+树，B+树是B-树的变体，其定义基本与B-树相同，主要的不同点在于：</p><p>1、关键字（key）的个数比指向子结点的指针的个数要少1个。</p><p>2、所有的非叶子节点上不包含数据信息，因此在内存页中能够存放更多的key，所有数据（或者说记录）都保存在叶子结点中。</p><p>3、叶子结点都是相链的，因此对整棵树的遍历只需要一次线性遍历叶子结点即可</p><h2 id="Mysql索引的实现"><a href="#Mysql索引的实现" class="headerlink" title="Mysql索引的实现"></a>Mysql索引的实现</h2><h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址，这里设表一共有三列，假设我们以Col1为主键，可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。MyISAM的索引方式也叫做“非聚集”的。</p><h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。</p><p>第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。</p><p>叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。</p><p>第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域</p><p>聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;索引的用处&quot;&gt;&lt;a href=&quot;#索引的用处&quot; class=&quot;headerlink&quot; title=&quot;索引的用处&quot;&gt;&lt;/a&gt;索引的用处&lt;/h2&gt;&lt;p&gt;MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引
      
    
    </summary>
    
      <category term="随笔" scheme="https://ellenjack.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="索引" scheme="https://ellenjack.github.io/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>类加载机制和双亲委派模型</title>
    <link href="https://ellenjack.github.io/2020/04/08/informal-2/"/>
    <id>https://ellenjack.github.io/2020/04/08/informal-2/</id>
    <published>2020-04-08T07:29:15.000Z</published>
    <updated>2020-04-08T07:40:55.319Z</updated>
    
    <content type="html"><![CDATA[<h2 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdmedewb6ij31hc0jw4nt.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdmedei3xoj31k20u07o6.jpg" alt></p><h2 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdmedeogskj30vt0l0aif.jpg" alt></p><p><strong>双亲委派模型过程</strong><br>某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。</p><p><strong>双亲委派模型好处</strong><br>Java类随着它的类加载器一起具备了带有优先级的层次关系，保证java程序稳定运行</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;类加载机制&quot;&gt;&lt;a href=&quot;#类加载机制&quot; class=&quot;headerlink&quot; title=&quot;类加载机制&quot;&gt;&lt;/a&gt;类加载机制&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/00831rSTly1gdmedew
      
    
    </summary>
    
      <category term="随笔" scheme="https://ellenjack.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="类加载" scheme="https://ellenjack.github.io/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>阐述事务的隔离级别和传播属性</title>
    <link href="https://ellenjack.github.io/2020/04/06/informal-1/"/>
    <id>https://ellenjack.github.io/2020/04/06/informal-1/</id>
    <published>2020-04-06T10:43:18.000Z</published>
    <updated>2020-04-08T07:32:08.152Z</updated>
    
    <content type="html"><![CDATA[<h2 id="七个事务传播属性"><a href="#七个事务传播属性" class="headerlink" title="七个事务传播属性"></a>七个事务传播属性</h2><p> <strong>PROPAGATION_REQUIRED</strong> – 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。<br> <strong>PROPAGATION_SUPPORTS</strong> – 支持当前事务，如果当前没有事务，就以非事务方式执行。<br> <strong>PROPAGATION_MANDATORY</strong> – 支持当前事务，如果当前没有事务，就抛出异常。<br> <strong>PROPAGATION_REQUIRES_NEW</strong> – 新建事务，如果当前存在事务，把当前事务挂起。<br> <strong>PROPAGATION_NOT_SUPPORTED</strong> – 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。<br> <strong>PROPAGATION_NEVER</strong> – 以非事务方式执行，如果当前存在事务，则抛出异常。<br> <strong>PROPAGATION_NESTED</strong>–如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。</p><h2 id="五种隔离级别"><a href="#五种隔离级别" class="headerlink" title="五种隔离级别"></a>五种隔离级别</h2><p>隔离级别是指若干个并发的事务之间的隔离程度。</p><p><strong>ISOLATION_DEFAULT</strong>–这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别.另外四个与JDBC的隔离级别相对应；</p><p><strong>ISOLATION_READ_UNCOMMITTED</strong>–这是事务最低的隔离级别，它充许别外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻像读。</p><p><strong>ISOLATION_READ_COMMITTED</strong>–保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。这种事务隔离级别可以避免脏读出现，但是可能会出现不可重复读和幻像读。</p><p><strong>ISOLATION_REPEATABLE_READ</strong>–这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读。它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免下面的情况产生(不可重复读)。</p><p><strong>ISOLATION_SERIALIZABLE</strong>–这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻像读。</p><p>mysql默认的事务隔离级别为repeatable-read</p><p>show variables like ‘%tx_isolation%’;</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gdk87skkgfj306703m3yi.jpg" alt="img"></p><h3 id="1-1-1-未提交读（READ-UNCOMMITED）脏读"><a href="#1-1-1-未提交读（READ-UNCOMMITED）脏读" class="headerlink" title="1.1.1.  未提交读（READ UNCOMMITED）脏读"></a>1.1.1.  未提交读（READ UNCOMMITED）脏读</h3><p>set SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;</p><p><strong>测试：</strong></p><p>启动两个session</p><p>一个session中</p><p> start TRANSACTION</p><p> update account set balance = balance -50 where id = 1</p><p>另外一个session中查询</p><p>select * from account</p><p>回到第一个session中 回滚事务</p><p>ROLLBACK</p><p>在第二个session种</p><p>update account set balance = balance -50 where id = 1</p><p>查询结果还是 400</p><p>第二个session以为结果是350，但前面的400数据为脏读数据，导致最后的结果和意料中的结果并不一致。</p><h3 id="1-1-2-已提交读-（READ-COMMITED）不可重复读"><a href="#1-1-2-已提交读-（READ-COMMITED）不可重复读" class="headerlink" title="1.1.2.  已提交读 （READ COMMITED）不可重复读"></a>1.1.2.  已提交读 （READ COMMITED）不可重复读</h3><p><strong>测试</strong></p><p>show variables like ‘%tx_isolation%’;</p><p>set SESSION TRANSACTION ISOLATION LEVEL read committed;</p><p>一个session中</p><p> start TRANSACTION</p><p> update account set balance = balance -50 where id = 1</p><p>另外一个session中查询 (数据并没改变)</p><p>select * from account</p><p>回到第一个session中 回滚事务</p><p>commit</p><p>在第二个session种</p><p>select * from account (数据已经改变)</p><h3 id="1-1-3-可重复读（REPEATABLE-READ）"><a href="#1-1-3-可重复读（REPEATABLE-READ）" class="headerlink" title="1.1.3.  可重复读（REPEATABLE READ）"></a>1.1.3.  可重复读（REPEATABLE READ）</h3><p><strong>测试</strong></p><p>show variables like ‘%tx_isolation%’;</p><p>set SESSION TRANSACTION ISOLATION LEVEL repeatable read;</p><p>一个session中</p><p> start TRANSACTION</p><p> update account set balance = balance -50 where id = 1</p><p>另外一个session中查询 (数据并没改变)</p><p>select * from account</p><p>回到第一个session中 回滚事务</p><p>commit</p><p>在第二个session种</p><p>select * from account (数据并未改变)</p><h3 id="1-1-4-可串行化（SERIALIZABLE）"><a href="#1-1-4-可串行化（SERIALIZABLE）" class="headerlink" title="1.1.4.  可串行化（SERIALIZABLE）"></a>1.1.4.  可串行化（SERIALIZABLE）</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;七个事务传播属性&quot;&gt;&lt;a href=&quot;#七个事务传播属性&quot; class=&quot;headerlink&quot; title=&quot;七个事务传播属性&quot;&gt;&lt;/a&gt;七个事务传播属性&lt;/h2&gt;&lt;p&gt; &lt;strong&gt;PROPAGATION_REQUIRED&lt;/strong&gt; – 支持当前事
      
    
    </summary>
    
      <category term="随笔" scheme="https://ellenjack.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="事务" scheme="https://ellenjack.github.io/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>消息队列常见问题</title>
    <link href="https://ellenjack.github.io/2019/07/03/kafka-4/"/>
    <id>https://ellenjack.github.io/2019/07/03/kafka-4/</id>
    <published>2019-07-02T17:54:27.000Z</published>
    <updated>2020-03-25T16:12:24.798Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么使用消息队列？"><a href="#为什么使用消息队列？" class="headerlink" title="为什么使用消息队列？"></a><strong>为什么使用消息队列？</strong></h2><p>其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么？</p><p>面试官问你这个问题，期望的一个回答是说，你们公司有个什么业务场景，这个业务场景有个什么技术挑战，如果不用MQ可能会很麻烦，但是你现在用了MQ之后带给了你很多的好处。消息队列的常见使用场景，其实场景有很多，但是比较核心的有3个：解耦、异步、削峰。</p><h3 id="解耦："><a href="#解耦：" class="headerlink" title="解耦："></a><strong>解耦：</strong></h3><p>A系统发送个数据到BCD三个系统，接口调用发送，那如果E系统也要这个数据呢？那如果C系统现在不需要了呢？现在A系统又要发送第二种数据了呢？而且A系统要时时刻刻考虑BCDE四个系统如果挂了咋办？要不要重发？我要不要把消息存起来？</p><p>你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用MQ给他异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个MQ去进行系统的解耦。</p><h3 id="异步："><a href="#异步：" class="headerlink" title="异步："></a><strong>异步：</strong></h3><p>A系统接收一个请求，需要在自己本地写库，还需要在BCD三个系统写库，自己本地写库要30ms，BCD三个系统分别写库要300ms、450ms、200ms。最终请求总延时是30 + 300 + 450 + 200 = 980ms，接近1s，异步后，BCD三个系统分别写库的时间，A系统就不再考虑了。</p><h3 id="削峰："><a href="#削峰：" class="headerlink" title="削峰："></a><strong>削峰：</strong></h3><p>每天0点到16点，A系统风平浪静，每秒并发请求数量就100个。结果每次一到16点~23点，每秒并发请求数量突然会暴增到1万条。但是系统最大的处理能力就只能是每秒钟处理1000个请求啊。怎么办？需要我们进行流量的削峰，让系统可以平缓的处理突增的请求。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4m15c3usvj30um0f2aek.jpg" alt="img"> </p><h2 id="消息队列有什么优点和缺点"><a href="#消息队列有什么优点和缺点" class="headerlink" title="消息队列有什么优点和缺点?"></a><strong>消息队列有什么优点和缺点?</strong></h2><p>优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。</p><p>缺点呢？ </p><h3 id="系统可用性降低"><a href="#系统可用性降低" class="headerlink" title="系统可用性降低"></a><strong>系统可用性降低</strong></h3><p>系统引入的外部依赖越多，越容易挂掉，本来你就是A系统调用BCD三个系统的接口就好了，ABCD四个系统好好的，没啥问题，你偏加个MQ进来，万一MQ挂了怎么办？MQ挂了，整套系统崩溃了，业务也就停顿了。</p><h3 id="系统复杂性提高"><a href="#系统复杂性提高" class="headerlink" title="系统复杂性提高"></a><strong>系统复杂性提高</strong></h3><p>硬生生加个MQ进来，怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？ </p><h3 id="一致性问题"><a href="#一致性问题" class="headerlink" title="一致性问题"></a><strong>一致性问题</strong></h3><p>A系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是BCD三个系统那里，BD两个系统写库成功了，结果C系统写库失败了，你这数据就不一致了。</p><p>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉。 </p><h2 id="常见消息队列的比较"><a href="#常见消息队列的比较" class="headerlink" title="常见消息队列的比较"></a><strong>常见消息队列的比较</strong></h2><p>参见第一章中消息队列的比较章节。</p><h2 id="消息的重复"><a href="#消息的重复" class="headerlink" title="消息的重复"></a><strong>消息的重复</strong></h2><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a><strong>原因</strong></h3><h4 id="第一类原因"><a href="#第一类原因" class="headerlink" title="第一类原因"></a><strong>第一类原因</strong></h4><p>消息发送端应用的消息重复发送,有以下几种情况。</p><p>l 消息发送端发送消息给消息中间件,消息中间件收到消息并成功存储,而这时消息中间件出现了问题,导致应用端没有收到消息发送成功的返回因而进行重试产生了重复。</p><p>l 消息中间件因为负载高响应变慢,成功把消息存储到消息存储中后,返回“成功”这个结果时超时。</p><p>l 消息中间件将消息成功写入消息存储,在返回结果时网络出现问题,导致应用发送端重试,而重试时网络恢复,由此导致重复。</p><p>可以看到,通过消息发送端产生消息重复的主要原因是消息成功进入消息存储后,因为各种原因使得消息发送端没有收到“成功”的返回结果,并且又有重试机制,因而导致重复。</p><h4 id="第二类原因"><a href="#第二类原因" class="headerlink" title="第二类原因"></a><strong>第二类原因</strong></h4><p>消息到达了消息存储,由消息中间件进行向外的投递时产生重复，有以下几种情况。</p><p>l 消息被投递到消息接收者应用进行处理,处理完毕后应用出问题了,消息中间件不知道消息处理结果,会再次投递。</p><p>l 消息被投递到消息接收者应用进行处理,处理完毕后网络出现问题了,消息中间件没有收到消息处理结果,会再次投递。</p><p>l 消息被投递到消息接收者应用进行处理,处理时间比较长,消息中间件因为消息超时会再次投递。</p><p>l 消息被投递到消息接收者应用进行处理,处理完毕后消息中间件出问题了,没能收到消息结果并处理,会再次投递</p><p>l 消息被投递到消息接收者应用进行处理,处理完毕后消息中间件收到结果但是遇到消息存储故障,没能更新投递状态,会再次投递。</p><p>可以看到,在投递过程中产生的消息重复接收主要是因为消息接收者成功处理完消息后,消息中间件不能及时更新投递状态造成的。</p><h3 id="如何解决重复消费"><a href="#如何解决重复消费" class="headerlink" title="如何解决重复消费"></a><strong>如何解决重复消费</strong></h3><p>那么有什么办法可以解决呢?主要是要求消息接收者来处理这种重复的情况,也就是要求消息接收者的消息处理是幂等操作。</p><h4 id="什么是幂等性？"><a href="#什么是幂等性？" class="headerlink" title="什么是幂等性？"></a><strong>什么是幂等性？</strong></h4><p>对于消息接收端的情况,幂等的含义是采用同样的输入多次调用处理函数,得到同样的结果。例如，一个SQL操作</p><p>update stat_table set count= 10 where id =1</p><p>这个操作多次执行,id等于1的记录中的 count字段的值都为10,这个操作就是幂等的,我们不用担心这个操作被重复。</p><p>再来看另外一个SQL操作</p><p>update stat_table set count= count +1 where id= 1;</p><p>这样的SQL操作就不是幂等的,一旦重复,结果就会产生变化。</p><h4 id="常见办法"><a href="#常见办法" class="headerlink" title="常见办法"></a><strong>常见办法</strong></h4><p>因此应对消息重复的办法是,使消息接收端的处理是一个幂等操作。这样的做法降低了消息中间件的整体复杂性,不过也给使用消息中间件的消息接收端应用带来了一定的限制和门槛。</p><h5 id="1-MVCC："><a href="#1-MVCC：" class="headerlink" title="1. MVCC："></a>1. MVCC：</h5><p>多版本并发控制，乐观锁的一种实现，在生产者发送消息时进行数据更新时需要带上数据的版本号，消费者去更新时需要去比较持有数据的版本号，版本号不一致的操作无法成功。例如博客点赞次数自动+1的接口：</p><p>public boolean addCount(Long id, Long version);</p><p>update blogTable set count= count+1,version=version+1 where id=321 and version=123 </p><p>每一个version只有一次执行成功的机会，一旦失败了生产者必须重新获取数据的最新版本号再次发起更新。</p><h5 id="2-去重表："><a href="#2-去重表：" class="headerlink" title="2. 去重表："></a>2. 去重表：</h5><p>利用数据库表单的特性来实现幂等，常用的一个思路是在表上构建唯一性索引，保证某一类数据一旦执行完毕，后续同样的请求不再重复处理了（利用一张日志表来记录已经处理成功的消息的ID，如果新到的消息ID已经在日志表中，那么就不再处理这条消息。）</p><p>以电商平台为例子，电商平台上的订单id就是最适合的token。当用户下单时，会经历多个环节，比如生成订单，减库存，减优惠券等等。每一个环节执行时都先检测一下该订单id是否已经执行过这一步骤，对未执行的请求，执行操作并缓存结果，而对已经执行过的id，则直接返回之前的执行结果，不做任何操作。这样可以在最大程度上避免操作的重复执行问题，缓存起来的执行结果也能用于事务的控制等。</p><h2 id="消息的可靠性传输"><a href="#消息的可靠性传输" class="headerlink" title="消息的可靠性传输"></a><strong>消息的可靠性传输</strong></h2><h3 id="ActiveMQ"><a href="#ActiveMQ" class="headerlink" title="ActiveMQ"></a><strong>ActiveMQ</strong></h3><p>要保证消息的可靠性，除了消息的持久化，还包括两个方面，一是生产者发送的消息可以被ActiveMQ收到，二是消费者收到了ActiveMQ发送的消息。</p><h5 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h5><p>非持久化又不在事务中的消息，可能会有消息的丢失。为保证消息可以被ActiveMQ收到，我们应该采用事务消息或持久化消息。</p><h5 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h5><p>对消息的确认有4种机制</p><p>1、 AUTO_ACKNOWLEDGE = 1    自动确认</p><p>2、 CLIENT_ACKNOWLEDGE = 2    客户端手动确认   </p><p>3、 DUPS_OK_ACKNOWLEDGE = 3    自动批量确认</p><p>4、 SESSION_TRANSACTED = 0    事务提交并确认</p><p>ACK_MODE描述了Consumer与broker确认消息的方式(时机),比如当消息被Consumer接收之后,Consumer将在何时确认消息。所以ack_mode描述的不是producer于broker之间的关系，而是customer于broker之间的关系。</p><p>对于broker而言，只有接收到ACK指令,才会认为消息被正确的接收或者处理成功了,通过ACK，可以在consumer与Broker之间建立一种简单的“担保”机制.</p><h6 id="AUTO-ACKNOWLEDGE"><a href="#AUTO-ACKNOWLEDGE" class="headerlink" title="AUTO_ACKNOWLEDGE"></a><em>AUTO_ACKNOWLEDGE</em></h6><p>自动确认</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">“同步”(receive)方法返回message给消息时会立即确认。</span><br><span class="line"></span><br><span class="line"> 在&quot;异步&quot;(messageListener)方式中,将会首先调用listener.onMessage(message)，如果onMessage方法正常结束,消息将会正常确认。如果onMessage方法异常，将导致消费者要求ActiveMQ重发消息。</span><br></pre></td></tr></table></figure><h6 id="CLIENT-ACKNOWLEDGE"><a href="#CLIENT-ACKNOWLEDGE" class="headerlink" title="CLIENT_ACKNOWLEDGE :"></a><em>CLIENT_ACKNOWLEDGE :</em></h6><p>客户端手动确认，这就意味着AcitveMQ将不会“自作主张”的为你ACK任何消息，开发者需要自己择机确认。</p><p>我们可以在当前消息处理成功之后，立即调用message.acknowledge()方法来”逐个”确认消息，这样可以尽可能的减少因网络故障而导致消息重发的个数；当然也可以处理多条消息之后，间歇性的调用acknowledge方法来一次确认多条消息，减少ack的次数来提升consumer的效率，不过需要自行权衡。</p><h6 id="DUPS-OK-ACKNOWLEDGE"><a href="#DUPS-OK-ACKNOWLEDGE" class="headerlink" title="DUPS_OK_ACKNOWLEDGE"></a><em>DUPS_OK_ACKNOWLEDGE</em></h6><p>类似于AUTO_ACK确认机制，为自动批量确认而生，而且具有“延迟”确认的特点，ActiveMQ会根据内部算法，在收到一定数量的消息自动进行确认。在此模式下，可能会出现重复消息，什么时候？当consumer故障重启后，那些尚未ACK的消息会重新发送过来。</p><h6 id="SESSION-TRANSACTED"><a href="#SESSION-TRANSACTED" class="headerlink" title="SESSION_TRANSACTED"></a><em>SESSION_TRANSACTED</em></h6><p>当session使用事务时，就是使用此模式。当决定事务中的消息可以确认时，必须调用session.commit()方法，commit方法将会导致当前session的事务中所有消息立即被确认。在事务开始之后的任何时机调用rollback()，意味着当前事务的结束，事务中所有的消息都将被重发。当然在commit之前抛出异常，也会导致事务的rollback。</p><h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a><strong>RabbitMQ</strong></h3><h4 id="（1）生产者弄丢了数据"><a href="#（1）生产者弄丢了数据" class="headerlink" title="（1）生产者弄丢了数据"></a><strong>（1）生产者弄丢了数据</strong></h4><p>生产者将数据发送到RabbitMQ的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。此时可以选择用RabbitMQ提供的事务功能，就是生产者发送数据之前开启RabbitMQ事务（channel.txSelect），然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，RabbitMQ事务机制一搞，基本上吞吐量会下来，因为太耗性能。</p><p>所以一般来说，如果要确保RabbitMQ的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，告诉你说这个消息ok了。如果RabbitMQ没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p><p>事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你一个接口通知你这个消息接收到了。</p><p>所以一般在生产者这块避免数据丢失，都是用confirm机制的。</p><h4 id="（2）RabbitMQ弄丢了数据"><a href="#（2）RabbitMQ弄丢了数据" class="headerlink" title="（2）RabbitMQ弄丢了数据"></a><strong>（2）RabbitMQ弄丢了数据</strong></h4><p>就是RabbitMQ自己弄丢了数据，这个你必须开启RabbitMQ的持久化，就是消息写入之后会持久化到磁盘，哪怕是RabbitMQ自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。</p><p>设置持久化有两个步骤，第一个是创建queue和交换器的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化相关的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。</p><p>而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。</p><p>哪怕是你给RabbitMQ开启了持久化机制，也有一种可能，就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘上，结果不巧，此时RabbitMQ挂了，就会导致内存里的一点点数据会丢失。</p><h4 id="（3）消费端弄丢了数据"><a href="#（3）消费端弄丢了数据" class="headerlink" title="（3）消费端弄丢了数据"></a><strong>（3）消费端弄丢了数据</strong></h4><p>RabbitMQ如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ认为你都消费了，这数据就丢了。</p><p>这个时候得用RabbitMQ提供的ack机制，简单来说，就是你关闭RabbitMQ自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那RabbitMQ就认为你还没处理完，这个时候RabbitMQ会把这个消费分配给别的consumer去处理，消息是不会丢的。</p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a><strong>Kafka</strong></h3><h4 id="（1）消费端弄丢了数据"><a href="#（1）消费端弄丢了数据" class="headerlink" title="（1）消费端弄丢了数据"></a><strong>（1）消费端弄丢了数据</strong></h4><p>唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p><p>大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p><p>生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。</p><p>然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了</p><h4 id="（2）kafka弄丢了数据"><a href="#（2）kafka弄丢了数据" class="headerlink" title="（2）kafka弄丢了数据"></a><strong>（2）kafka弄丢了数据</strong></h4><p>这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。</p><p>所以此时一般是要求起码设置如下4个参数：</p><p>给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本。</p><p>在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧。</p><p>在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了。</p><p>在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。</p><h4 id="（3）生产者会不会弄丢数据"><a href="#（3）生产者会不会弄丢数据" class="headerlink" title="（3）生产者会不会弄丢数据"></a><strong>（3）生产者会不会弄丢数据</strong></h4><p>如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p><h2 id="消息的顺序性"><a href="#消息的顺序性" class="headerlink" title="消息的顺序性"></a><strong>消息的顺序性</strong></h2><p>从根本上说，异步消息是不应该有顺序依赖的。在MQ上估计是没法解决。要实现严格的顺序消息，简单且可行的办法就是：保证生产者 - MQServer - 消费者是一对一对一的关系。</p><h3 id="ActiveMQ-1"><a href="#ActiveMQ-1" class="headerlink" title="ActiveMQ"></a><strong>ActiveMQ</strong></h3><p>1、通过高级特性consumer独有消费者（exclusive consumer）</p><p>queue = new ActiveMQQueue(“TEST.QUEUE?consumer.exclusive=true”);</p><p>consumer = session.createConsumer(queue);</p><p>当在接收信息的时候，有多个独占消费者的时候，只有一个独占消费者可以接收到消息。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4m15d6qyyj30s50cjn0a.jpg" alt="img"> </p><p>独占消息就是在有多个消费者同时消费一个queue时，可以保证只有一个消费者可以消费消息，这样虽然保证了消息的顺序问题，不过也带来了一个问题，就是这个queue的所有消息将只会在这一个主消费者上消费，其他消费者将闲置，达不到负载均衡分配，而实际业务我们可能更多的是这样的场景，比如一个订单会发出一组顺序消息，我们只要求这一组消息是顺序消费的，而订单与订单之间又是可以并行消费的，不需要顺序，因为顺序也没有任何意义，有没有办法做到呢？可以利用activemq的另一个高级特性之messageGroup</p><p>2、利用Activemq的高级特性：messageGroups</p><p>Message Groups特性是一种负载均衡的机制。在一个消息被分发到consumer之前，broker首先检查消息JMSXGroupID属性。如果存在，那么broker会检查是否有某个consumer拥有这个message group。如果没有，那么broker会选择一个consumer，并将它关联到这个message group。此后，这个consumer会接收这个message group的所有消息，直到：Consumer被关闭。Message group被关闭，通过发送一个消息，并设置这个消息的JMSXGroupSeq为-1</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4m15cr33pj30rw0cqn05.jpg" alt="img"> </p><p><strong>bytesMessage</strong>.setStringProperty(“JMSXGroupID”, “constact-20100000002”);</p><p><strong>bytesMessage</strong>.setIntProperty(“JMSXGroupSeq”, -1);</p><p>如上图所示，同一个queue中，拥有相同JMSXGroupID的消息将发往同一个消费者，解决顺序问题，不同分组的消息又能被其他消费者并行消费，解决负载均衡的问题。</p><h3 id="RabbitMQ-1"><a href="#RabbitMQ-1" class="headerlink" title="RabbitMQ"></a><strong>RabbitMQ</strong></h3><p>如果有顺序依赖的消息，要保证消息有一个hashKey，类似于数据库表分区的的分区key列。保证对同一个key的消息发送到相同的队列。A用户产生的消息（包括创建消息和删除消息）都按A的hashKey分发到同一个队列。只需要把强相关的两条消息基于相同的路由就行了，也就是说经过m1和m2的在路由表里的路由是一样的，那自然m1会优先于m2去投递。而且一个queue只对应一个consumer。</p><h3 id="Kafka-1"><a href="#Kafka-1" class="headerlink" title="Kafka"></a><strong>Kafka</strong></h3><p>一个topic，一个partition，一个consumer，内部单线程消费</p><h2 id="如何解决消息队列的延时以及过期失效问题？"><a href="#如何解决消息队列的延时以及过期失效问题？" class="headerlink" title="如何解决消息队列的延时以及过期失效问题？"></a><strong>如何解决消息队列的延时以及过期失效问题？</strong></h2><p>rabbitmq，rabbitmq是可以设置过期时间的，就是TTL，如果消息在queue中积压超过一定的时间，而又没有设置死信队列机制，就会被rabbitmq给清理掉，这个数据就没了。</p><p>ActiveMQ则通过更改配置，支持消息的定时发送。</p><h2 id="有几百万消息持续积压几小时怎么解决？"><a href="#有几百万消息持续积压几小时怎么解决？" class="headerlink" title="有几百万消息持续积压几小时怎么解决？"></a><strong>有几百万消息持续积压几小时怎么解决？</strong></h2><p>发生了线上故障，几千万条数据在MQ里积压很久。是修复consumer的问题，让他恢复消费速度，然后等待几个小时消费完毕？这是个解决方案。不过有时候我们还会进行临时紧急扩容。</p><p>一个消费者一秒是1000条，一秒3个消费者是3000条，一分钟是18万条。1000多万条，所以如果积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来。</p><p>一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：</p><p>先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉。</p><p>新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量。然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue。</p><p>接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据。</p><p>这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据。</p><p>等快速消费完积压数据之后，再恢复原先部署架构，重新用原先的consumer机器来消费消息。</p><h2 id="Kafka是如何实现高性能的？"><a href="#Kafka是如何实现高性能的？" class="headerlink" title="Kafka是如何实现高性能的？"></a><strong>Kafka是如何实现高性能的？</strong></h2><h3 id="宏观架构层面利用Partition实现并行处理"><a href="#宏观架构层面利用Partition实现并行处理" class="headerlink" title="宏观架构层面利用Partition实现并行处理"></a><strong>宏观架构层面利用Partition实现并行处理</strong></h3><p>Kafka中每个Topic都包含一个或多个Partition，不同Partition可位于不同节点。同时Partition在物理上对应一个本地文件夹，每个Partition包含一个或多个Segment，每个Segment包含一个数据文件和一个与之对应的索引文件。在逻辑上，可以把一个Partition当作一个非常长的数组，可通过这个“数组”的索引（offset）去访问其数据。</p><p>一方面，由于不同Partition可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于Partition在物理上对应一个文件夹，即使多个Partition位于同一个节点，也可通过配置让同一节点上的不同Partition置于不同的disk drive上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</p><p>利用多磁盘的具体方法是，将不同磁盘mount到不同目录，然后在server.properties中，将log.dirs设置为多目录（用逗号分隔）。Kafka会自动将所有Partition尽可能均匀分配到不同目录也即不同目录（也即不同disk）上。</p><p>Partition是最小并发粒度，Partition个数决定了可能的最大并行度。。</p><h3 id="ISR实现可用性与数据一致性的动态平衡"><a href="#ISR实现可用性与数据一致性的动态平衡" class="headerlink" title="ISR实现可用性与数据一致性的动态平衡"></a><strong>ISR实现可用性与数据一致性的动态平衡</strong></h3><h4 id="常用数据复制及一致性方案"><a href="#常用数据复制及一致性方案" class="headerlink" title="常用数据复制及一致性方案"></a><strong>常用数据复制及一致性方案</strong></h4><h5 id="Master-Slave"><a href="#Master-Slave" class="headerlink" title="Master-Slave"></a>Master-Slave</h5><p>- RDBMS的读写分离即为典型的Master-Slave方案</p><p>- 同步复制可保证强一致性但会影响可用性</p><p>- 异步复制可提供高可用性但会降低一致性</p><h5 id="WNR"><a href="#WNR" class="headerlink" title="WNR"></a>WNR</h5><p>- 主要用于去中心化的分布式系统中。</p><p>- N代表总副本数，W代表每次写操作要保证的最少写成功的副本数，R代表每次读至少要读取的副本数</p><p>- 当W+R&gt;N时，可保证每次读取的数据至少有一个副本拥有最新的数据</p><p>- 多个写操作的顺序难以保证，可能导致多副本间的写操作顺序不一致。Dynamo通过向量时钟保证最终一致性</p><h5 id="Paxos及其变种"><a href="#Paxos及其变种" class="headerlink" title="Paxos及其变种"></a>Paxos及其变种</h5><p>- Google的Chubby，Zookeeper的原子广播协议（Zab），RAFT等</p><h4 id="基于ISR的数据复制方案"><a href="#基于ISR的数据复制方案" class="headerlink" title="基于ISR的数据复制方案"></a><strong>基于ISR的数据复制方案</strong></h4><p>Kafka的数据复制是以Partition为单位的。而多个备份间的数据复制，通过Follower向Leader拉取数据完成。从一这点来讲，Kafka的数据复制方案接近于上文所讲的Master-Slave方案。不同的是，Kafka既不是完全的同步复制，也不是完全的异步复制，而是基于ISR的动态复制方案。</p><p>ISR，也即In-sync Replica。每个Partition的Leader都会维护这样一个列表，该列表中，包含了所有与之同步的Replica（包含Leader自己）。每次数据写入时，只有ISR中的所有Replica都复制完，Leader才会将其置为Commit，它才能被Consumer所消费。</p><p>这种方案，与同步复制非常接近。但不同的是，这个ISR是由Leader动态维护的。如果Follower不能紧“跟上”Leader，它将被Leader从ISR中移除，待它又重新“跟上”Leader后，会被Leader再次加加ISR中。每次改变ISR后，Leader都会将最新的ISR持久化到Zookeeper中。</p><p>由于Leader可移除不能及时与之同步的Follower，故与同步复制相比可避免最慢的Follower拖慢整体速度，也即ISR提高了系统可用性。</p><p>ISR中的所有Follower都包含了所有Commit过的消息，而只有Commit过的消息才会被Consumer消费，故从Consumer的角度而言，ISR中的所有Replica都始终处于同步状态，从而与异步复制方案相比提高了数据一致性。</p><p>ISR可动态调整，极限情况下，可以只包含Leader，极大提高了可容忍的宕机的Follower的数量。与Majority Quorum方案相比，容忍相同个数的节点失败，所要求的总节点数少了近一半。</p><h3 id="具体实现层面高效使用磁盘特性和操作系统特性"><a href="#具体实现层面高效使用磁盘特性和操作系统特性" class="headerlink" title="具体实现层面高效使用磁盘特性和操作系统特性"></a><strong>具体实现层面高效使用磁盘特性和操作系统特性</strong></h3><h4 id="将写磁盘的过程变为顺序写"><a href="#将写磁盘的过程变为顺序写" class="headerlink" title="将写磁盘的过程变为顺序写"></a><strong>将写磁盘的过程变为顺序写</strong></h4><p>Kafka的整个设计中，Partition相当于一个非常长的数组，而Broker接收到的所有消息顺序写入这个大数组中。同时Consumer通过Offset顺序消费这些数据，并且不删除已经消费的数据，从而避免了随机写磁盘的过程。</p><p>由于磁盘有限，不可能保存所有数据，实际上作为消息系统Kafka也没必要保存所有数据，需要删除旧的数据。而这个删除过程，并非通过使用“读-写”模式去修改文件，而是将Partition分为多个Segment，每个Segment对应一个物理文件，通过删除整个文件的方式去删除Partition内的数据。这种方式清除旧数据的方式，也避免了对文件的随机写操作。</p><p>在存储机制上，使用了Log Structured Merge Trees(LSM) 。</p><p>注：Log Structured Merge Trees(LSM)，谷歌 “BigTable” 的论文，中提出，LSM是当前被用在许多产品的文件结构策略：HBase, Cassandra, LevelDB, SQLite,Kafka。LSM被设计来提供比传统的B+树或者ISAM更好的写操作吞吐量，通过消去随机的本地更新操作来达到这个目标。这个问题的本质还是磁盘随机操作慢，顺序读写快。这二种操作存在巨大的差距，无论是磁盘还是SSD，而且快至少三个数量级。 </p><h4 id="充分利用Page-Cache"><a href="#充分利用Page-Cache" class="headerlink" title="充分利用Page Cache"></a><strong>充分利用Page Cache</strong></h4><p>使用Page Cache的好处如下</p><p>- I/O Scheduler会将连续的小块写组装成大块的物理写从而提高性能</p><p>- I/O Scheduler会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</p><p>- 充分利用所有空闲内存（非JVM内存）。如果使用应用层Cache（即JVM堆内存），会增加GC负担</p><p>- 读操作可直接在Page Cache内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过Page Cache）交换数据</p><p>- 如果进程重启，JVM内的Cache会失效，但Page Cache仍然可用</p><p>Broker收到数据后，写磁盘时只是将数据写入Page Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page Cache内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由Kafka层面的Replication机制去解决。如果为了保证这种情况下数据不丢失而强制将Page Cache中的数据Flush到磁盘，反而会降低性能。也正因如此，Kafka虽然提供了flush.messages和flush.ms两个参数将Page Cache中的数据强制Flush到磁盘，但是Kafka并不建议使用。</p><p>如果数据消费速度与生产速度相当，甚至不需要通过物理磁盘交换数据，而是直接通过Page Cache交换数据。同时，Follower从Leader Fetch数据时，也可通过Page Cache完成。</p><p>注：Page Cache，又称pcache，其中文名称为页高速缓冲存储器，简称页高缓。page cache的大小为一页，通常为4K。在linux读写文件时，它用于缓存文件的逻辑内容，从而加快对磁盘上映像和数据的访问。 是Linux操作系统的一个特色。</p><h4 id="支持多Disk-Drive"><a href="#支持多Disk-Drive" class="headerlink" title="支持多Disk Drive"></a><strong>支持多Disk Drive</strong></h4><p>Broker的log.dirs配置项，允许配置多个文件夹。如果机器上有多个Disk Drive，可将不同的Disk挂载到不同的目录，然后将这些目录都配置到log.dirs里。Kafka会尽可能将不同的Partition分配到不同的目录，也即不同的Disk上，从而充分利用了多Disk的优势。</p><h4 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a><strong>零拷贝</strong></h4><p>Kafka中存在大量的网络数据持久化到磁盘（Producer到Broker）和磁盘文件通过网络发送（Broker到Consumer）的过程。这一过程的性能直接影响Kafka的整体吞吐量。</p><p>传统模式下的四次拷贝与四次上下文切换</p><p>以将磁盘文件通过网络发送为例。传统模式下，一般使用如下伪代码所示的方法先将文件数据读入内存，然后通过Socket将内存中的数据发送出去。</p><p>buffer = File.readSocket.send(buffer)</p><p>这一过程实际上发生了四次数据拷贝。首先通过系统调用将文件数据读入到内核态Buffer（DMA拷贝），然后应用程序将内存态Buffer数据读入到用户态Buffer（CPU拷贝），接着用户程序通过Socket发送数据时将用户态Buffer数据拷贝到内核态Buffer（CPU拷贝），最后通过DMA拷贝将数据拷贝到NIC Buffer。同时，还伴随着四次上下文切换。</p><p>而Linux 2.4+内核通过sendfile系统调用，提供了零拷贝。数据通过DMA拷贝到内核态Buffer后，直接通过DMA拷贝到NIC Buffer，无需CPU拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件-网络发送由一个sendfile调用完成，整个过程只有两次上下文切换，因此大大提高了性能。</p><p>从具体实现来看，Kafka的数据传输通过Java NIO的FileChannel的transferTo和transferFrom方法实现零拷贝。</p><p>注： transferTo和transferFrom并不保证一定能使用零拷贝。实际上是否能使用零拷贝与操作系统相关，如果操作系统提供sendfile这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，否则并不能通过这两个方法本身实现零拷贝。</p><h4 id="减少网络开销批处理"><a href="#减少网络开销批处理" class="headerlink" title="减少网络开销批处理"></a><strong>减少网络开销批处理</strong></h4><p>批处理是一种常用的用于提高I/O性能的方式。对Kafka而言，批处理既减少了网络传输的Overhead，又提高了写磁盘的效率。</p><p>Kafka 的send方法并非立即将消息发送出去，而是通过batch.size和linger.ms控制实际发送频率，从而实现批量发送。</p><p>由于每次网络传输，除了传输消息本身以外，还要传输非常多的网络协议本身的一些内容（称为Overhead），所以将多条消息合并到一起传输，可有效减少网络传输的Overhead，进而提高了传输效率。</p><h4 id="数据压缩降低网络负载"><a href="#数据压缩降低网络负载" class="headerlink" title="数据压缩降低网络负载"></a><strong>数据压缩降低网络负载</strong></h4><p>Kafka从0.7开始，即支持将数据压缩后再传输给Broker。除了可以将每条消息单独压缩然后传输外，Kafka还支持在批量发送时，将整个Batch的消息一起压缩后传输。数据压缩的一个基本原理是，重复数据越多压缩效果越好。因此将整个Batch的数据一起压缩能更大幅度减小数据量，从而更大程度提高网络传输效率。</p><p>Broker接收消息后，并不直接解压缩，而是直接将消息以压缩后的形式持久化到磁盘。Consumer Fetch到数据后再解压缩。因此Kafka的压缩不仅减少了Producer到Broker的网络传输负载，同时也降低了Broker磁盘操作的负载，也降低了Consumer与Broker间的网络传输量，从而极大得提高了传输效率，提高了吞吐量。</p><h4 id="高效的序列化方式"><a href="#高效的序列化方式" class="headerlink" title="高效的序列化方式"></a><strong>高效的序列化方式</strong></h4><p>Kafka消息的Key和Payload（或者说Value）的类型可自定义，只需同时提供相应的序列化器和反序列化器即可。因此用户可以通过使用快速且紧凑的序列化-反序列化方式（如Avro，Protocal Buffer）来减少实际网络传输和磁盘存储的数据规模，从而提高吞吐率。这里要注意，如果使用的序列化方法太慢，即使压缩比非常高，最终的效率也不一定高。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;为什么使用消息队列？&quot;&gt;&lt;a href=&quot;#为什么使用消息队列？&quot; class=&quot;headerlink&quot; title=&quot;为什么使用消息队列？&quot;&gt;&lt;/a&gt;&lt;strong&gt;为什么使用消息队列？&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;其实就是问问你消息队列都有哪些使用场景，然
      
    
    </summary>
    
      <category term="消息中间件" scheme="https://ellenjack.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
      <category term="Kafka" scheme="https://ellenjack.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/"/>
    
    
      <category term="Kafka" scheme="https://ellenjack.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>深入理解Kafka</title>
    <link href="https://ellenjack.github.io/2019/07/03/kafka-3/"/>
    <id>https://ellenjack.github.io/2019/07/03/kafka-3/</id>
    <published>2019-07-02T17:50:05.000Z</published>
    <updated>2020-03-25T16:12:24.797Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深入理解Kafka"><a href="#深入理解Kafka" class="headerlink" title="深入理解Kafka"></a><strong>深入理解Kafka</strong></h1><h2 id="集群的成员关系"><a href="#集群的成员关系" class="headerlink" title="集群的成员关系"></a><strong>集群的成员关系</strong></h2><p>Kafka使用 zookeeper来维护集群成员的信息。每个 broker都有个唯一标识符, 这个标识符可以在配置文件里指定, 也可以自动生成。 在 broker启动的时候, 它通过创建临时节点把自己的 ID注册到 zoo-keeper。 Kafka组件订阅 Zookeeper的/brokers/ids路径(broker在 zookeeper上的注册路径) , 当有 broker加入集群或退出集群时, 这些组件就可以获得通知 。</p><p>如果你要启动另一个具有相同 ID的 broker, 会得到一个错误。新 broker会试着进行注册,但不会成功, 因为 zookeeper里已经有一个具有相同 ID的 broker。</p><p>在 broker停机、 出现网络分区或长时间垃圾回收停顿时, broker会从 Zookeeper上断开连接, 此时 broker在启动时创建的临时节点会自动从 Zookeeper上移除。 监听 broker列表的Kafka 组件会被告知该 broker已移除。</p><p>在关闭 broker时, 它对应的节点也会消失, 不过它的 ID会继续存在于其他数据结构中 。 例如,主题的副本列表里就可能包含这些ID。在完全关闭一个broker之后, 如果使用相同的ID启动另一个全新的 broker, 它会立刻加入集群, 并拥有与旧 broker 相同的分区和主题。</p><h2 id="什么是控制器"><a href="#什么是控制器" class="headerlink" title="什么是控制器"></a><strong>什么是控制器</strong></h2><p>控制器其实就是一个 broker, 只不过它除了具有一般 broker的功能之外, 还负责分区首领的选举。 集群里第一个启动的 broker通过在Zookeeper里创建一个临时节点/controuer让自己成为控制器。 其他 broker在启动时也会尝试创建这个节点,不过它们会收到一个“节点已存在”的异常,然后“意识”到控制器节点已存在, 也就是说集群里已经有一个控制器了 。 其他 broker在控制器节点上创建Zookeeperwatch对象,这样它们就可以收到这个节点的变更通知。这种方式可以确保集群里一次只有一个控制器存在。</p><p>如果控制器被关闭或者与 Zookeeper断开连接, zookeeper上的临时节点就会消失。 集群里的其他 broker通过 watch对象得到控制器节点消失的通知, 它们会尝试让自己成为新的控制器。 第一个在 Zookeeper里成功创建控制器节点的 broker就会成为新的控制器, 其他节点会收到“节点已存在”的异常,然后在新的控制器节点上再次创建watch对象。</p><p>当控制器发现一个 broker已经离开集群,它就知道,那些失去首领的分区需要一个新首领 (这些分区的首领刚好是在这个 broker上)。 控制器遍历这些分区, 并确定谁应该成为新首领 (简单来说就是分区副本列表里的下一个副本) , 然后向所有包含新首领或现有跟随者的 broker发送请求。该请求消息包含了谁是新首领以及谁是分区跟随者的信息。随后,新首领开始处理来自生产者和消费者的情求,而跟随者开始从新首领那里复制消息。</p><p>当控制器发现一个 broker加入集群时, 它会使用 broker ID来检査新加入的 broker是否包含现有分区的副本。 如果有, 控制器就把变更通知发送给新加入的 broker和其他 broker, 新 broker上的副本开始从首领那里复制消息。</p><p>简而言之, Kafka使用 Zookeeper的临时节点来选举控制器,并在节点加入集群或退出集群时通知控制器。 控制器负责在节点加入或离开集群时进行分区首领选举。 </p><h2 id="复制-Kafka的核心"><a href="#复制-Kafka的核心" class="headerlink" title="复制-Kafka的核心"></a><strong>复制-Kafka的核心</strong></h2><p>复制功能是 Kafka架构的核心。在 Kafka的文档里, Kafka把自己描述成“一个分布式的、可分区的、可复制的提交日志服务”。复制之所以这么关键,是因为它可以在个别节点失效时仍能保证 Kafka的可用性和持久性。</p><p>Kafka使用主题来组织数据, 每个主题被分为若干个分区,每个分区有多个副本。那些副本被保存在 broker上, 每个 broker可以保存成百上千个属于不同主题和分区的副本。</p><h3 id="副本类型。"><a href="#副本类型。" class="headerlink" title="副本类型。"></a><strong>副本类型。</strong></h3><h4 id="首领副本"><a href="#首领副本" class="headerlink" title="首领副本"></a><strong>首领副本</strong></h4><p>每个分区都有一个首领副本。为了保证一致性,所有生产者请求和消费者请求都会经过这个副本 。</p><h4 id="跟随者副本"><a href="#跟随者副本" class="headerlink" title="跟随者副本"></a><strong>跟随者副本</strong></h4><p>首领以外的副本都是跟随者副本。跟随者副本不处理来自客户端的请求,它们唯一一的任务就是从首领那里复制消息, 保持与首领一致的状态 。 如果首领发生崩溃, 其中的一个跟随者会被提升为新首领 。</p><h3 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a><strong>工作机制</strong></h3><p>首领的另一个任务是搞清楚哪个跟随者的状态与自己是一致的。 跟随者为了保持与首领的状态一致，在有新消息到达时尝试从首领那里复制消息, 不过有各种原因会导致同步失败。例如,网络拥塞导致复制变慢, broker发生崩演导致复制滞后,直到重启broker后复制才会继续。</p><p>为了与首领保持同步, 跟随者向首领发送获取数据的请求, 这种请求与消费者为了读取消息而发送的请求是一样的。首领将响应消息发给跟随者。请求消息里包含了跟随者想要获取消息的偏移量, 而且这些偏移量总是有序的 。</p><p>一个跟随者副本先请求消息1,接着请求消息2,然后请求消息3,在收到这3个请求的响应之前,它是不会发送第4个请求消息的。如果跟随者发送了请求消息4,那么首领就知道它已经收到了前面3个请求的响应。 通过査看每个跟随者请求的最新偏移量, 首领就会知道每个跟随者复制的进度。如果跟随者在10s内没有请求任何消息,或者虽然在请求消息,但在10s内没有请求最新的数据,那么它就会被认为是不同步的。如果一个副本无法与首领保持一致,在首领发生失效时,它就不可能成为新首领，因为它没有包含全部的消息。</p><p>相反,持续请求得到的最新消息副本被称为同步副本。在首领发生失效时,只有同步副本才有可能被选为新首领。</p><p>跟随者的正常不活跃时间或在成为不同步副本之前的时间可以通过replica.lag.time.max.ms参数来配置的。 这个时间间隔直接影响着首领选举期间的客户端行为和数据保留机制 。</p><p>除了当前首领之外, 每个分区都有一个优先副本（首选首领），创建主题时选定的首领分区就是分区的优先副本。 之所以把它叫作优先副本, 是因为在创建分区时, 需要在 broker之间均衡首领副本。 因此, 我们希望首选首领在成为真正的首领时, broker间的负载最终会得到均衡。 默认情况下, Kafka的 auto.leader.rebalance.enable被设为 true,它会检査优先副本是不是当前首领,如果不是,并且该副本是同步的, 那么就会触发首领选举, 让优先副本成为当前首领。</p><h2 id="处理请求的内部机制"><a href="#处理请求的内部机制" class="headerlink" title="处理请求的内部机制"></a><strong>处理请求的内部机制</strong></h2><p>broker的大部分工作是处理客户端、分区副本和控制器发送给分区首领的请求。 Kafka提供了一个二进制协议(基于TCP),指定了请求消息的格式以及 broker如何对请求作出响应——包括成功处理请求或在处理请求过程中遇到错误。</p><p>客户端发起连接并发送请求,broker处理请求并作出响应。 broker按照请求到达的顺序来处理它们这种顺序保证让Kaka具有了消息队列的特性,同时保证保存的消息也是有序的。</p><p>所有的请求消息都包含一个标准消息头:</p><p>Request type(也就是 API key)</p><p>Request version( broker可以处理不同版本的客户端请求,并根据客户端版本作出不同的响应)</p><p>Correlation id-一个具有唯一性的数字,用于标识请求消息,同时也会出现在响应消息和错误日志里(用于诊断问题)</p><p>Client Id用于标识发送请求的客户端</p><p>broker会在它所监听的每一个端口上运行一个 Acceptor线程,这个线程会创建一个连接并把它交给 Processor线程去处理。 Processor线程(也被叫作“网络线程”)的数量是可配置的。网络线程负责从客户端获取请求消息,把它们放进请求队列,然后从响应队列获取响应消息,把它们发送给客户端。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4m17ddbn9j30bg0akq4e.jpg" alt="img"> </p><p>请求消息被放到请求队列后,IO线程会负责处理它们。比较常见的请求类型有：</p><p>生产请求：生产者发送的请求,它包含客户端要写入 broker的消息。</p><p>获取请求：在消费者和跟随者副本需要从 broker读取消息时发送的请求。</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4m17cjhafj30iy0hbadk.jpg" alt="img"> </p><p>生产请求和获取请求都必须发送给分区的首领副本。如果broker 收到一个针对特定分区的请求，而该分区的首领在另一个broker 上，那么发送请求的客户端会收到一个“非分区首领”的错误响应。当针对特定分区的获取请求被发送到一个不含有该分区首领的broker上，也会出现同样的错误。Kafka 客户端要自己负责把生产请求和获取请求发送到正确的broker 上。</p><p>那么客户端怎么知道该往哪里发送请求呢？客户端使用了另一种请求类型，也就是元数据请求。这种请求包含了客户端感兴趣的主题列表。服务器端的响应消息里指明了这些主题所包含的分区、每个分区都有哪些副本， 以及哪个副本是首领。元数据请求可以发送给任意一个broker ，因为所有broker 都缓存了这些信息。</p><p>一般情况下，客户端会把这些信息缓存起来，并直接往目标broker 上发送生产请求和获取请求。它们需要时不时地通过发送元数据请求来刷新这些信息（刷新的时间间隔通过meta.max.age.ms参数来配置），从而知道元数据是否发生了变更, 比如，在新broker 加入集群时，部分副本会被移动到新的broker 上。另外，如果客户端收到“非首领”错误，它会在尝试重发请求之前先刷新元数据，因为这个错误说明了客户端正在使用过期的元数据信息，之前的请求被发到了错误的broker 上。</p><h4 id="生产请求"><a href="#生产请求" class="headerlink" title="生产请求"></a><strong>生产请求</strong></h4><p>我们曾经说过， acks这个配置参数，该参数指定了需要多少个 broker确认才可以认为一个消息写入是成功的。不同的配置对“写入成功”的界定是不一样的,如果acks=1,那么只要首领收到消息就认为写入成功;如果acks=all,那么需要所有同步副本收到消息才算写入成功; 如果 acks=0, 那么生产者在把消息发出去之后, 完全不需要等待 broker的响应。</p><p>包含首领副本的 broker在收到生产请求时, 会对请求做一些验证。</p><p>•  发送数据的用户是否有主题写入权限?</p><p>  请求里包含的acks值是否有效(只允许出现0、1或all) ?</p><p>  如果 acks=all, 是否有足够多的同步副本保证消息已经被安全写入? </p><p>之后,消息被写入本地磁盘。在Linux系统上,消息会被写到文件系统缓存里,并不保证它们何时会被刷新到磁盘上。Kafka不会一直等待数据被写到磁盘上，它依赖复制功能来保证消息的持久性。</p><p>在消息被写入分区的首领之后, broker开始检査 acks配置参数一如果 acks被设为 0或1, 那么 broker立即返回响应;如果 acks被设为 all,那么请求会被保存在一个叫作炼狱的缓冲区里, 直到首领发现所有跟随者副本都复制了消息, 响应才会被返回给客户端。</p><h4 id="获取请求"><a href="#获取请求" class="headerlink" title="获取请求"></a><strong>获取请求</strong></h4><p>broker处理获取请求的方式与处理生产请求的方式很相似。客户端发送请求,向 broker请求主题分区里具有特定偏移量的消息, 好像在说: “请把主题 Test分区 0偏移量从53开始的消息以及主题 Test分区3偏移量从64开始的消息发给我。”客户端还可以指定 broker最多可以从一个分区里返回多少数据。 这个限制是非常重要的, 因为客户端需要为 broker返回的数据分配足够的内存。 如果没有这个限制, broker返回的大量数据有可能耗尽客户端的内存。</p><p>我们之前讨论过,请求需要先到达指定的分区首领上,然后客户端通过査询元数据来确保请求的路由是正确的。首领在收到请求时,它会先检査请求是否有效，比如,指定的偏移量在分区上是否存在?如果客户端请求的是已经被删除的数据,或者请求的偏移量不存在, 那么 broker将返回一个错误。</p><p>如果请求的偏移量存在, broker将按照客户端指定的数量上限从分区里读取消息, 再把消息返回给客户端。 Kafka使用零复制技术向客户端发送消息一一也就是说, Kafka直接把消息从文件(或者更确切地说是 Linux文件系统缓存)里发送到网络通道,而不需要经过任何中间缓冲区。 这是 Kafka与其他大部分数据库系统不一样的地方, 其他数据库在将数据发送给客户端之前会先把它们保存在本地缓存里。 这项技术避免了字节复制, 也不需要管理内存缓冲区, 从而获得更好的性能。</p><p>客户端除了可以设置 broker返回数据的上限, 也可以设置下限。 例如, 如果把下限设置为10KB,就好像是在告诉broker:“等到有10KB数据的时候再把它们发送给我。”在主题消息流量不是很大的情况下,这样可以减少 CPU和网络开销。 客户端发送一个请求, broker 等到有足够的数据时才把它们返回给客户端, 然后客户端再发出情求, 而不是让客户端每隔几毫秒就发送一次请求,每次只能得到很少的数据甚至没有数据。对比这两种情况, 它们最终读取的数据总量是一样的, 但前者的来回传送次数更少, 因此开销也更小。</p><p> <img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4m179vhrhj30jm07x0u9.jpg" alt="img"></p><p>当然,我们不会让客户端一直等待broker累积数据。在等待了一段时间之后,就可以把可用的数据拿回处理,而不是一直等待下去。所以,客户端可以定义一个超时时间,告诉 broker: “如果你无法在 K毫秒内累积满足要求的数据量, 那么就把当前这些数据返回给我。”</p><h4 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a><strong>ISR</strong></h4><p>并不是所有保存在分区首领上的数据都可以被客户端读取。大部分客户端只能读取已经被写入所有同步副本的消息。 分区首领知道每个消息会被复制到哪个副本上, 在消息还没有被写入所有同步副本之前, 是不会发送给消费者的，尝试获取这些消息的请求会得到空的响应而不是错误。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4m17edgrlj30py08uwhb.jpg" alt="img"> </p><p>因为还没有被足够多副本复制的消息被认为是“不安全”的，如果首领发生崩横,另一 个副本成为新首领,那么这些消息就丢失了。如果我们允许消费者读取这些消息,可能就会破坏一致性。试想, 一个消费者读取并处理了这样的一个消息,而另一个消费者发现这个消息其实并不存在。所以,我们会等到所有同步副本复制了这些消息,才允许消费者读取它们。这也意味着,如果broker间的消息复制因为某些原因变慢,那么消息到达消费者的时间也会随之变长 (因为我们会先等待消息复制完毕) 。延迟时间可以通过参数replica. lag. time. max. ms来配置, 它指定了副本在复制消息时可被允许的最大延迟时间。</p><p>Kafka的数据复制是以Partition为单位的。而多个备份间的数据复制，通过Follower向Leader拉取数据完成。从一这点来讲，有点像Master-Slave方案。不同的是，Kafka既不是完全的同步复制，也不是完全的异步复制，而是基于ISR的动态复制方案。</p><p>ISR，也即In-Sync Replica。每个Partition的Leader都会维护这样一个列表，该列表中，包含了所有与之同步的Replica（包含Leader自己）。每次数据写入时，只有ISR中的所有Replica都复制完，Leader才会将其置为Commit，它才能被Consumer所消费。</p><p>这种方案，与同步复制非常接近。但不同的是，这个ISR是由Leader动态维护的。如果Follower不能紧“跟上”Leader，它将被Leader从ISR中移除，待它又重新“跟上”Leader后，会被Leader再次加加ISR中。每次改变ISR后，Leader都会将最新的ISR持久化到Zookeeper中。</p><p>至于如何判断某个Follower是否“跟上”Leader，不同版本的Kafka的策略稍微有些区别。</p><p>从0.9.0.0版本开始，replica.lag.max.messages被移除，故Leader不再考虑Follower落后的消息条数。另外，Leader不仅会判断Follower是否在replica.lag.time.max.ms时间内向其发送Fetch请求，同时还会考虑Follower是否在该时间内与之保持同步。</p><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4m17dt7b0j30lr0b0acm.jpg" alt="img"> </p><p>在第一步中，Leader A总共收到3条消息，但由于ISR中的Follower只同步了第1条消息（m1），故只有m1被Commit，也即只有m1可被Consumer消费。此时Follower B与Leader A的差距是1，而Follower C与Leader A的差距是2，虽然有消息的差距，但是满足同步副本的要求保留在ISR中。同步副本概念参见<a href="#_复制">《复制》</a></p><p>在第二步中，由于旧的Leader A宕机，新的Leader B在replica.lag.time.max.ms时间内未收到来自A的Fetch请求，故将A从ISR中移除，此时ISR={B，C}。同时，由于此时新的Leader B中只有2条消息，并未包含m3（m3从未被任何Leader所Commit），所以m3无法被Consumer消费。</p><h5 id="使用ISR方案的原因"><a href="#使用ISR方案的原因" class="headerlink" title="使用ISR方案的原因"></a>使用ISR方案的原因</h5><p>由于Leader可移除不能及时与之同步的Follower，故与同步复制相比可避免最慢的Follower拖慢整体速度，也即ISR提高了系统可用性。</p><p>ISR中的所有Follower都包含了所有Commit过的消息，而只有Commit过的消息才会被Consumer消费，故从Consumer的角度而言，ISR中的所有Replica都始终处于同步状态，从而与异步复制方案相比提高了数据一致性。</p><h5 id="ISR相关配置说明"><a href="#ISR相关配置说明" class="headerlink" title="ISR相关配置说明"></a>ISR相关配置说明</h5><p>Broker的min.insync.replicas参数指定了Broker所要求的ISR最小长度，默认值为1。也即极限情况下ISR可以只包含Leader。但此时如果Leader宕机，则该Partition不可用，可用性得不到保证。</p><p>只有被ISR中所有Replica同步的消息才被Commit，但Producer发布数据时，Leader并不需要ISR中的所有Replica同步该数据才确认收到数据。Producer可以通过acks参数指定最少需要多少个Replica确认收到该消息才视为该消息发送成功。acks的默认值是1，即Leader收到该消息后立即告诉Producer收到该消息，此时如果在ISR中的消息复制完该消息前Leader宕机，那该条消息会丢失。而如果将该值设置为0，则Producer发送完数据后，立即认为该数据发送成功，不作任何等待，而实际上该数据可能发送失败，并且Producer的Retry机制将不生效。更推荐的做法是，将acks设置为all或者-1，此时只有ISR中的所有Replica都收到该数据（也即该消息被Commit），Leader才会告诉Producer该消息发送成功，从而保证不会有未知的数据丢失。</p><h2 id="物理存储机制"><a href="#物理存储机制" class="headerlink" title="物理存储机制"></a><strong>物理存储机制</strong></h2><p>Kafka的基本存储单元是分区。分区无法在多个broker间进行再细分,也无法在同一个broker的多个磁盘上进行再细分。</p><p>在配置 Kafka的时候, 管理员指定了一个用于存储分区的目录清单——也就是log.dirs参数的值 (不要把它与存放错误日志的目录混淆了, 日志目录是配置在1og4j.properties文件里的)。 该参数一般会包含每个挂载点的目录。</p><h3 id="分区分配"><a href="#分区分配" class="headerlink" title="分区分配"></a><strong>分区分配</strong></h3><p>在创建主题时, Kafka首先会决定如何在 broker间分配分区。假设你有6个 broker, 打算创建一个包含10个分区的主题,并且复制系数为3。那么 Kafka就会有30个分区副本, 它们可以被分配给6个 broker。 在进行分区分配时, 我们要达到如下的目标。</p><p>•  在 broker间平均地分布分区副本。对于我们的例子来说, 就是要保证每个 broker可以分到5个副本。</p><p>•  确保每个分区的每个副本分布在不同的 broker上。假设分区 0的首领副本在 broker2上,,那么可以把跟随者副本放在 broker3和 broker4上, 但不能放在 broker2上,也不能两个都放在 broker3上。</p><p>•  如果为 broker指定了机架信息,那么尽可能把每个分区的副本分配到不同机架的 broker上 。 这样做是为了保证一个机架的不可用不会导致整体的分区不可用 。</p><p>为了实现这个目标, 我们先随机选择一个 broker(假设是4) , 然后使用轮询的方式给每个 broker分配分区来确定首领分区的位置。于是,首领分区 0会在 broker4上,首领分区l会在 broker5上, 首领分区2会在 broker 0上(只有6个 broker), 并以此类推。然后, 我们从分区首领开始,依次分配跟随者副本。如果分区 0的首领在broker4上,那么它的第一个跟随者副本会在 broker5上,第二个跟随者副本会在 broker 0上。分区1的首领在broker5上,那么它的第一个跟随者副本在 broker0上,第二个跟随者副本在 broker1上。</p><p>为分区和副本选好合适的 broker之后, 接下来要决定这些分区应该使用哪个目录。 我们单独为每个分区分配目录, 规则很简单: 计算每个目录里的分区数量, 新的分区总是被添加到数量最小的那个目录里。 也就是说, 如果添加了一个新磁量, 所有新的分区都会被创建到这个磁盘上。因为在完成分配工作之前,新磁盘的分区数量总是最少的。</p><h3 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a><strong>文件管理</strong></h3><p>保留数据是 Kafka的一个基本特性, Kafka不会一直保留数据, 也不会等到所有消费者都读取了消息之后才删除消息。 相反, Kafka管理员为每个主题配置了数据保留期限, 规定数据被删除之前可以保留多长时间, 或者清理数据之前可以保留的数据量大小 。</p><p>因为在一个大文件里査找和删除消息是很费时的, 也很容易出错, 所以分区分成若干个片段。默认情况下,每个片段包含1GB或一周的数据,以较小的那个为准。在broker 往分区写入数据时,如果达到片段上限,就关闭当前文件,并打开一个新文件。</p><p>当前正在写入数据的片段叫作活跃片段。 活动片段永远不会被删除, 所以如果你要保留数据1天,但片段里包含了5天的数据,那么这些数据会被保留5天,因为在片段被关闭之前这些数据无法被删除。如果你要保留数据一周,而且每天使用一个新片段,那么你就会看到,每天在使用一个新片段的同时会删除一个最老的片段一所以大部分时间该分区会有7个片段存在。</p><h3 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a><strong>文件格式</strong></h3><p>Kafka的消息和偏移量保存在文件里。保存在磁盘上的数据格式与从生产者发送过来或者发送给消费者的消息格式是一样的 。 因为使用了相同的消息格式进行磁盘存储和网络传输, Kafka可以使用零复制技术给消费者发送消息, 同时避免了对生产者已经压缩过的消息进行解压和再圧缩。</p><p>除了键、值和偏移量外,消息里还包含了消息大小、校验和、消息格式版本号、压缩算法(snappy、 Gzip或Lz4)和时间戳(在0.10.0版本里引入的)。时间戳可以是生产者发送消息的时间, 也可以是消息到达 broker的时间, 这个是可配置的。</p><p>如果生产者发送的是圧缩过的消息, 那么同一个批次的消息会被压缩在一起, 被当作 “包装消息”进行发送。于是, broker就会收到一个这样的消息,然后再把它发送给消费者。 消费者在解压这个消息之后, 会看到整个批次的消息, 它们都有自己的时间戳和偏移量。</p><p>如果在生产者端使用了压缩功能(极力推荐),那么发送的批次越大,就意味着在网络传输和磁盘存储方面会获得越好的压缩性能, 同时意味着如果修改了消费者使用的消息格式 (例如, 在消息里增加了时间戳) , 那么网络传输和磁盘存储的格式也要随之修改, 而且 broker要知道如何处理包含了两种消息格式的文件。</p><p>Kafka附带了一个叫 DumpLogSegment的工具, 可以用它査看片段的内容。 它可以显示每个消息的偏移量、校验和、魔术数字节、消息大小和压缩算法。</p><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a><strong>索引</strong></h3><p>消费者可以从Kafka的任意可用偏移量位置开始读取消息。假设消费者要读取从偏移量100开始的1MB消息,那么 broker必须立即定位到偏移量100(可能是在分区的任意一个片段里), 然后开始从这个位置读取消息。为了帮助 broker更快地定位到指定的偏移量, Kafka 为每个分区维护了一个索引。索引把偏移量映射到片段文件和偏移量在文件里的位置。</p><p>索引也被分成片段, 所以在删除消息时, 也可以删除相应的索引 。 Kafka不维护索引的校验和。 如果索引出现损坏, Kafka会通过重新读取消息并录制偏移量和位置来重新生成索引。 如果有必要, 管理员可以删除索引, 这样做是绝对安全的, Kafka会自动重新生成这些索引 。</p><h3 id="超时数据的清理机制"><a href="#超时数据的清理机制" class="headerlink" title="超时数据的清理机制"></a><strong>超时数据的清理机制</strong></h3><p>一般情况下, Kafka会根据设置的时间保留数据,把超过时效的旧数据删除掉。不过,试想一下这样的场景,如果你使用 Kafka保存客户的收货地址,那么保存客户的最新地址比保存客户上周甚至去年的地址要有意义得多,这样你就不用担心会用错旧地址,而且短时间内客户也不会修改新地址。另外一个场景, 一个应用程序使用 Kafka保存它的状态,每次状态发生变化,它就把状态写入 Kafka。在应用程序从崩演中恢复时,它从Kafka读取消息来恢复最近的状态。在这种情况下,应用程序只关心它在崩粉前的那个状态,而不关心运行过程中的那些状态。</p><p>Kafka通过改变主题的保留策略来满足这些使用场景 。 早于保留时间的事件会被删除, 为每个键保留最新的值, 从而达到清理的效果</p><p>每个日志片段可以分为以下两个部分 。</p><p><strong>干净的部分</strong>，这些消息之前被清理过, 每个键只有一个对应的值, 这个值是上一次清理时保留下来的。 <strong>污浊的部分</strong>，这些消息是在上一次清理之后写入的。</p><p>为了清理分区, 清理线程会读取分区的污独部分, 并在内存里创建一个 map。 map里的每个元素包含了消息键的散列值和消息的偏移量,键的散列值是16B,加上偏移量总共是24B。如果要清理一个1GB的日志片段,并假设每个消息大小为1KB,那么这个片段就包含_一百万个消息,而我们只需要用24MB的 map就可以清理这个片段。 (如果有重复的键, 可以重用散列项, 从而使用更少的内存。) </p><p>清理线程在创建好偏移量map后,开始从干净的片段处读取消息,从最旧的消息开始,把它们的内容与 map里的内容进行比对。它会检査消息的键是否存在于 map中, 如果不存在, 那么说明消息的值是最新的,就把消息复制到替換片段上。如果键已存在,消息会被忽略, 因为在分区的后部已经有一个具有相同键的消息存在。在复制完所有的消息之后,我们就将替換片段与原始片段进行交换,然后开始清理下一个片段。完成整个清理过程之后,每个键对应一个不同的消息一这些消息的值都是最新的。 清理前后的分区片段如图所示。</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4m17c08awj30j30b61kx.jpg" alt="img"> </p><h1 id="可靠的数据传递"><a href="#可靠的数据传递" class="headerlink" title="可靠的数据传递"></a><strong>可靠的数据传递</strong></h1><h2 id="Kafka提供的可靠性保证和架构上的权衡"><a href="#Kafka提供的可靠性保证和架构上的权衡" class="headerlink" title="Kafka提供的可靠性保证和架构上的权衡"></a><strong>Kafka提供的可靠性保证和架构上的权衡</strong></h2><p>可靠性时，我们一般会使用保证这个词，它是指确保系统在各种不同的环境下能够发生一致的行为。</p><p>ACID 大概是大家最熟悉的一个例子，它是关系型数据库普遍支持的标准可靠性保证。ACID 指的是原子性、一致性、隔离性和持久性。如果一个供应商说他们的数据库遵循ACID 规范，其实就是在说他们的数据库支持与事务相关的行为。</p><p>有了这些保证，我们才能相信关系型数据库的事务特性可以确保应用程序的安全。我们知道系统承诺可以做到些什么，也知道在不同条件下它们会发生怎样的行为。我们了解这些保证机制，井基于这些保证机制开发安全的应用程序。</p><p>所以，了解系统的保证机制对于构建可靠的应用程序来说至关重要，这也是能够在不同条件下解释系统行为的前提。那么Kafka 可以在哪些方面作出保证呢？</p><p>• Kafka 可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且消息B 在消息A 之后写入，那么Kafka 可以保证消息B 的偏移量比消息A 的偏移量大，而且消费者会先读取消息A 再读取消息B 。</p><p>• 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“ 已提交”的。生产者可以选择接收不同类型的确认，比如在消息被完全提交时的确认，或者在消息被写入首领副本时的确认，或者在消息被发送到网络时的确认。</p><p>• 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失。消费者只能读取已经提交的消息。</p><p>这些基本的保证机制可以用来构建可靠的系统，但仅仅依赖它们是无法保证系统完全可靠的。构建一个可靠的系统需要作出一些权衡， Kafka 管理员和开发者可以在配置参数上作出权衡，从而得到他们想要达到的可靠性。这种权衡一般是指消息存储的可靠性和一致性的重要程度与可用性、高吞吐量、低延迟和硬件成本的重要程度之间的权衡。</p><h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a><strong>复制</strong></h2><p>Kafka 的复制机制和分区的多副本架构是Kafka 可靠性保证的核心。把消息写入多个副本可以使Kafka 在发生崩愤时仍能保证消息的持久性。</p><p>回顾一下主要内容：</p><p>Kafka 的主题被分为多个分区，分区是基本的数据块。分区存储在单个磁盘上， Kafka 可以保证分区里的事件是有序的，分区可以在线（可用），也可以离线（不可用） 。每个分区可以有多个副本，其中一个副本是首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其他副本只需要与首领保持同步，并及时复制最新的事件。当首领副本不可用时，其中一个同步副本将成为新首领。</p><p>分区首领是同步副本，而对于跟随者副本来说，它需要满足以下条件才能被认为是同步的。</p><p>•与Zoo keeper 之间有一个活跃的会话，也就是说，它在过去的6秒（可配置）内向Zoo keeper 发送过心跳。</p><p>• 在过去的10s 内（可配置）从首领那里获取过消息。</p><p>• 在过去的10s 内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，它还必须是儿乎零延迟的。</p><p>如果跟随者副本不能满足以上任何一点，比如与Zookeep er 断开连接，或者不再获取新消息，或者获取消息滞后了10s 以上，那么它就被认为是不同步的。一个不同步的副本通过与Zookeeper 重新建立连接，井从首领那里获取最新消息，可以重新变成同步的。这个过程在网络出现临时问题井很快得到修复的情况下会很快完成，但如果broker 发生崩愤就需要较长的时间。</p><p><strong>注意</strong>：如果一个或多个副本在同步和非同步状态之间快速切换，说明集群内部出现了问题，通常是Java 不恰当的垃圾回收配置导致的。不恰当的垃圾回收配置会造成几秒钟的停顿，从而让broker 与Zoo keeper 之间断开连接，最后变成不同步的，进而发生状态切换。</p><h2 id="Broker配置对可靠性的影响"><a href="#Broker配置对可靠性的影响" class="headerlink" title="Broker配置对可靠性的影响"></a><strong>Broker配置对可靠性的影响</strong></h2><h3 id="复制系数"><a href="#复制系数" class="headerlink" title="复制系数"></a><strong>复制系数</strong></h3><p>主题级别的配置参数是replication.factor，而在b roker 级别则可以通过default. replication.factor来配置自动创建的主题。</p><p>Kafka 的默认复制系数就是3，不过用户可以修改它。</p><p>如果复制系数为N，那么在凡l 个broker 失效的情况下，仍然能够从主题读取数据或向主题写入数据。所以，更高的复制系数会带来更高的可用性、可靠性和更少的故障。另一方面，复制系数N 需要至少N 个broker ，而且会有N 个数据副本，也就是说它们会占用N倍的磁盘空间。我们一般会在可用性和存储硬件之间作出权衡。</p><p>那么该如何确定一个主题需要几个副本呢？这要看主题的重要程度，以及你愿意付出多少成本来换取可用性。。</p><p>如果因broker 重启导致的主题不可用是可接受的（这在集群里是很正常的行为），那么把复制系数设为1就可以了。在作出这个权衡的时候，要确保这样不会对你的组织和用户造成影响，因为你在节省了硬件成本的同时也降低了可用性。复制系数为2 意味着可以容忍1 个broker 发生失效，看起来已经足够了。不过要记住，有时候1 个broker 发生失效会导致集群不稳定（通常是旧版的Kafka ），迫使你重启另一个broker－一集群控制器。也就是说，如果将复制系数设为2 ，就有可能因为重启等问题导致集群不可用。</p><p>基于以上几点原因，在要求可用性的场景里把复制系数设为3 。在大多数情况下，这已经足够安全了，不过要求更可靠时，可以设为更高，比如我5 个副本，以防不测。</p><p>副本的分布也很重要。默认情况下， Kafka 会确保分区的每个副本被放在不同的broker 上。不过，有时候这样仍然不够安全。如果这些broker 处于同一个机架上， 一旦机架的交换机发生故障，分区就会不可用，这时候把复制系数设为多少都不管用。为了避免机架级别的故障，我们建议把broker 分布在多个不同的机架上。</p><h3 id="不完全的首领选举"><a href="#不完全的首领选举" class="headerlink" title="不完全的首领选举"></a><strong>不完全的首领选举</strong></h3><p>unclean.leader.election 只能在broker 级别（实际上是在集群范围内）进行配置， 它的默认值是true。</p><p>当分区首领不可用时， 一个同步副本会被选为新首领。如果在选举过程中没有丢失数据，也就是说提交的数据同时存在于所有的同步副本上，那么这个选举就是“完全”的。</p><p>但如果在首领不可用时其他副本都是不同步的，我们该怎么办呢？</p><p>这种情况会在以下两种场景里出现。</p><p>• 分区有3 个副本，其中的两个跟随者副本不可用（比如有两个broker 发生崩愤）。这个时候，如果生产者继续往首领写入数据，所有消息都会得到确认井被提交（因为此时首领是唯一的同步副本）。现在我们假设首领也不可用了（又一个broker 发生崩愤），这个时候，如果之前的一个跟随者重新启动，它就成为了分区的唯一不同步副本。</p><p>• 分区有3 个副本，因为网络问题导致两个跟随者副本复制消息滞后，所以尽管它们还在复制消息，但已经不同步了。首领作为唯一的同步副本继续接收消息。这个时候，如果首领变为不可用，另外两个副本就再也无法变成同步的了。</p><p>对于这两种场景，我们要作出一个两难的选择。</p><p>如果不同步的副本不能被提升为新首领，那么分区在旧首领（最后一个同步副本）恢复之前是不可用的。有时候这种状态会持续数小时（比如更换内存芯片）。</p><p>·如果不同步的副本可以被提升为新首领，那么在这个副本变为不同步之后写入旧首领的消息、会全部丢失，导致数据不一致。为什么会这样呢？假设在副本0 和副本1不可用时，偏移量100-200 的消息被写入副本2 （首领）。现在副本2 变为不可用的，而副本0 变为可用的。副本0 只包含偏移量0～ 100 的消息，不包含偏移量100～ 200 的悄息。如果我们允许副本0 成为新首领，生产者就可以继续写人数据，消费者可以继续读取数据。于是，新首领就有了偏移量100 ～200 的新消息。这样，部分消费者会读取到偏移量100 ～200 的旧消息，部分消费者会读取到偏移量100～200 的新消息，还有部分消费者读取的是二者的混合。这样会导致非常不好的结果，比如生成不准确的报表。另外，副本2 可能会重新变为可用，并成为新首领的跟随者。这个时候，它会把比当前首领旧的消息全部删除，而这些消息对于所有消费者来说都是不可用的。</p><p>简而言之，如果我们允许不同步的副本成为首领，那么就要承担丢失数据和出现数据不一致的风险。如果不允许它们成为首领，那么就要接受较低的可用性，因为我们必须等待原先的首领恢复到可用状态。</p><p>如果把unclean.leader.election设为true ，就是允许不同步的副本成为首领（也就是“ 不完全的选举”），那么我们将面临丢失消息的风险。如果把这个参数设为false ,就要等待原先的首领重新上线，从而降低了可用性。</p><p>我们经常看到一些对数据质量和数据一致性要求较高的系统会禁用这种不完全的首领选举（ 把这个参数设为false ） 。比如银行系统，大部分银行系统宁愿选择在几分钟甚至几个小时内不处理信用卡支付事务，也不会冒险处理错误的消息。不过在对可用性要求较高的系统里，比如实时点击流分析系统， 一般会启用不完全的首领选举。</p><h3 id="最少同步副本"><a href="#最少同步副本" class="headerlink" title="最少同步副本"></a><strong>最少同步副本</strong></h3><p>在主题级别和broker 级别上，这个参数都叫min.insync.replicas。</p><p>我们知道，尽管为一个主题配置了3 个副本，还是会出现只有一个同步副本的情况。如果这个同步副本变为不可用，我们必须在可用性和一致性之间作出选择—这又是一个两难的选择。根据Kafka 对可靠性保证的定义，消息只有在被写入到所有同步副本之后才被认为是已提交的。但如果这里的“所有副本”只包含一个同步副本，那么在这个副本变为不可用时，数据就会丢失。</p><p>如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大一点的值。对于一个包含3 个副本的主题，如果min.insync.replicas被设为2 ，那么至少要存在两个同步副本才能向分区写入数据。</p><p>如果3 个副本都是同步的，或者其中一个副本变为不可用，都不会有什么问题。不过，如果有两个副本变为不可用，那么broker 就会停止接受生产者的请求。尝试发送数据的生产者会收到N otEnoughReplicasException 异常。消费者仍然可以继续读取已有的数据。实际上，如果使用这样的配置，那么当只剩下一个同步副本时，它就变成只读了，这是为了避免在发生不完全选举时数据的写入和读取出现非预期的行为。为了从只读状态中恢复，必须让两个不可用分区中的一个重新变为可用的（比如重启broker ），并等待它变为同步的。</p><h2 id="可靠系统里的生产者"><a href="#可靠系统里的生产者" class="headerlink" title="可靠系统里的生产者"></a><strong>可靠系统里的生产者</strong></h2><p>即使我们尽可能把broker 配置得很可靠，但如果没有对生产者进行可靠性方面的配置， 整个系统仍然有可能出现突发性的数据丢失。</p><p>请看以下两个例子。</p><p> 为broker 配置了3 个副本，井且禁用了不完全首领选举，这样应该可以保证万无一失。我们把生产者发送消息的acks 设为1 （只要首领接收到消息就可以认为消息写入成功）。生产者发送一个消息给首领，首领成功写入，但跟随者副本还没有接收到这个消息。首领向生产者发送了一个响应，告诉它“消息写入成功”，然后它崩溃了，而此时消息还没有被其他副本复制过去。另外两个副本此时仍然被认为是同步的（毕竟判断一个副本不同步需要一小段时间），而且其中的一个副本成了新的首领。因为消息还没有被写入这个副本，所以就丢失了，但发送消息的客户端却认为消息已成功写入。因为消费者看不到丢失的消息，所以此时的系统仍然是一致的（因为副本没有收到这个消息，所以消息不算已提交），但从生产者角度来看，它丢失了一个消息。</p><p>• 为broker 配置了3 个副本，并且禁用了不完全首领选举。我们接受了之前的教训， 把生产者的acks 设为all 。假设现在往Kafka 发送消息，分区的首领刚好崩愤，新的首领正在选举当中， Kafka 会向生产者返回“首领不可用”的响应。在这个时候，如果生产者没能正确处理这个错误，也没有重试发送消息直到发送成功，那么消息也有可能丢失。这算不上是broker 的可靠性问题，因为broker 并没有收到这个消息。这也不是一致性问题，因为消费者并没有读到这个消息。问题在于如果生产者没能正确处理这些错误，弄丢消息的是它们自己。</p><p>那么，我们该如何避免这些悲剧性的后果呢？从上面两个例子可以看出，每个使用Kafk a的开发人员都要注意两件事情。</p><p>\1. 根据可靠性需求配置恰当的acks 值。</p><p>\2. 在参数配置和代码里正确处理错误。</p><h3 id="发送确认"><a href="#发送确认" class="headerlink" title="发送确认"></a><strong>发送确认</strong></h3><p>复习一下，生产者可以选择以下3 种不同的确认模式。</p><p>acks=0 意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入Kafka 。在这种情况下还是有可能发生错误，比如发送的对象无法被序列化或者网卡发生故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。即使是在发生完全首领选举的情况下，这种模式仍然会丢失消息，因为在新首领选举过程中它并不知道首领已经不可用了。在acks=0 模式下的运行速度是非常快的（这就是为什么很多基准测试都是基于这个模式），你可以得到惊人的吞吐量和带宽利用率，不过如果选择了这种模式， 一定会丢失一些消息。</p><p>acks=1 意味若首领在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。在这个模式下，如果发生正常的首领选举，生产者会在选举时收到一个LeadeNotAvailableExcepti.on 异常，如果生产者能恰当地处理这个错误，它会重试发送消息，最终消息会安全到达新的首领那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩溃。</p><p>acks=all 意味着首领在返回确认或错误响应之前，会等待所有同步副本都收到悄息。如果和min.insync.replicas参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到消息。这是最保险的做法——生产者会一直重试直到消息被成功提交。不过这也是最慢的做法，生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。可以通过使用异步模式和更大的批次来加快速度，但这样做通常会降低吞吐量。</p><h3 id="配置生产者的重试参数"><a href="#配置生产者的重试参数" class="headerlink" title="配置生产者的重试参数"></a><strong>配置生产者的重试参数</strong></h3><p>生产者需要处理的错误包括两部分： 一部分是生产者可以自动处理的错误，还有一部分是需要开发者手动处理的错民。</p><p>如果broker 返回的错误可以通过重试来解决，那么生产者会自动处理这些错误。生产者向broker 发送消息时， broker 可以返回一个成功响应码或者一个错误响应码。错民响应码可以分为两种， 一种是在重试之后可以解决的，还有一种是无法通过重试解决的。例如，如果broker 返回的是LEADER_NOT_AVAILABLE 错误，生产者可以尝试重新发送消息。也许在这个时候一个新的首领被选举出来了，那么这次发送就会成功。也就是说， LEADER_NOT_AVAILABLE是一个可重试错误。</p><p>另一方面，如果broker 返回的是INVALID_CONFIG 错误，即使通过重试也无能改变配置选项，所以这样的重试是没有意义的。这种错误是不可重试错误。</p><p>一般情况下，如果你的目标是不丢失任何消息，那么最好让生产者在遇到可重试错误时能够保持重试。为什么要这样？因为像首领选举或网络连接这类问题都可以在几秒钟之内得到解决，如果让生产者保持重试，就不需要额外去处理这些问题了。</p><p>那么为生产者配置多少重试次数比较好？这个要看在生产者放弃重试并抛出异常之后想做些什么。如果你想抓住异常并再多重试几次，那么就可以把重试次数设置得多一点， 让生产者继续重试；如果你想直接丢弃消息，多次重试造成的延迟已经失去发送消息的意义；如果你想把消息保存到某个地方然后回过头来再继续处理，那就可以停止重试。</p><p>Kafka 的跨数据中心复制工具（ MirrorMaker）默认会进行无限制的重试。作为一个具有高可靠性的复制工具，它决不会丢失消息。</p><p>要注意，重试发送一个已经失败的消息会带来一些风险，如果两个消息都写入成功，会导致消息重复。例如，生产者因为网络问题没有收到broker的确认，但实际上消息已经写入成功，生产者会认为网络出现了临时故障，就重试发送该消息（因为它不知道消息已经写入成功）。在这种情况下，broker 会收到两个相同的消息。重试和恰当的错误处理可以保证每个消息“至少被保存一次”，但无法保证每个消息“只被保存一次”。现实中的很多应用程序在消息里加入唯一标识符，用于检测重复消息，消费者在读取消息时可以对它们进行清理。还要一些应用程序可以做到消息的“幕等”，也就是说，即使出现了重复消息，也不会对处理结果的正确性造成负面影响。</p><h3 id="额外的错误处理"><a href="#额外的错误处理" class="headerlink" title="额外的错误处理"></a><strong>额外的错误处理</strong></h3><p>使用生产者内置的重试机制可以在不造成消息丢失的情况下轻松地处理大部分错误，不过对于开发人员来说，仍然需要处理其他类型的错误，包括：</p><p>• 不可重试的broker 错误，例如消息大小错误、认证错误等 . 在消息发送之前发生的错误，例如序列化错误：</p><p>• 在生产者达到重试次数上限时或者在消息占用的内存达到上限时发生的错误。</p><p>错误处理器的代码逻辑与具体的应用程序及其目标有关。丢弃“不合理的消息”？把错误记录下来？把这些消息保存在本地磁盘上？具体使用哪一种逻辑要根据具体的架构来决定。如果错误处理只是为了重试发送消息，那么最好还是使用生产者内置的重试机制。</p><h2 id="可靠系统里的消费者"><a href="#可靠系统里的消费者" class="headerlink" title="可靠系统里的消费者"></a><strong>可靠系统里的消费者</strong></h2><p>可以看到，只有那些被提交到Kafka 的数据，也就是那些已经被写入所有同步副本的数据，对消费者是可用的，这意味着消费者得到的消息已经具备了一致性。</p><p>消费者唯一要做的是跟踪哪些消息是已经读取过的，哪些是还没有读取过的。这是在读取消息时不丢失消息的关键。</p><p>在从分区读取数据时，消费者会获取一批事件，检查这批事件里最大的偏移量，然后从这个偏移量开始读取另外一批事件。这样可以保证消费者总能以正确的顺序获取新数据， 不会错过任何事件。</p><p>如果一个消费者退出，另一个消费者需要知道从什么地方开始继续处理，它需要知道前一个消费者在退出前处理的最后一个偏移量是多少。所谓的“另一个”消费者，也可能就是它自己重启之后重新回来工作。这也就是为什么消费者要“提交”它们的偏移量。它们把当前读取的偏移量保存起来，在退出之后，同一个群组里的其他消费者就可以接手它们的工作。如果消费者提交了偏移量却未能处理完消息，那么就有可能造成消息丢失，这也是消费者丢失消息的主要原因。在这种情况下，如果其他消费者接手了工作，那些没有被处理完的消息就会被忽略，永远得不到处理。所以我们要重视偏移量提交的时间点和提交的方式。</p><h3 id="消费者的可靠性配置"><a href="#消费者的可靠性配置" class="headerlink" title="消费者的可靠性配置"></a><strong>消费者的可靠性配置</strong></h3><p>为了保证消费者行为的可靠性，需要注意以下4 个非常重要的配置参数。</p><p>第1个是group.id 。如果两个消费者具有相同的group.id ， 并且订阅了同一个主题，那么每个消费者会分到主题分区的一个子集， 也就是说它们只能读到所有消息的一个子集（不过群组会读取主题所有的消息）。如果你希望消费者可以看到主题的所有消息，那么需要为它们设置唯一的group.id 。</p><p>第2 个是auto.offset.reset 。这个参数指定了在没有偏移量可提交时（比如消费者第1次启动时）或者请求的偏移量在broker 上不存在时，消费者会做些什么。这个参数有两种配置。一种是earliest ，如果选择了这种配置，消费者会从分区的开始位置读取数据，不管偏移量是否有效，这样会导致消费者读取大量的重复数据，但可以保证最少的数据丢失。一种是latest，如果选择了这种配置， 消费者会从分区的末尾开始读取数据，这样可以减少重复处理消息，但很有可能会错过一些消息。</p><p>第3 个是enable.auto.commit 。这是一个非常重要的配置参数，你可以让消费者基于任务调度自动提交偏移量，也可以在代码里手动提交偏移量。自动提交的一个最大好处是，在实现消费者逻辑时可以少考虑一些问题。如果你在消费者轮询操作里处理所有的数据，那么自动提交可以保证只提交已经处理过的偏移量。自动提交的主要缺点是，无法控制重复处理消息（比如消费者在自动提交偏移量之前停止处理消息），而且如果把消息交给另外一个后台线程去处理，自动提交机制可能会在消息还没有处理完毕就提交偏移量。</p><p>第4 个配置参数auto.commit.interval.ms与第3 个参数有直接的联系。如果选择了自动提交偏移盘，可以通过该参数配置提交的频度， 默认值是每5 秒钟提交一次。一般来说，频繁提交会增加额外的开销，但也会降低重复处理消息的概率。</p><h3 id="显式提交偏移量"><a href="#显式提交偏移量" class="headerlink" title="显式提交偏移量"></a><strong>显式提交偏移量</strong></h3><p>如果选择了自动提交偏移量，就不需要关心显式提交的问题。不过如果希望能够更多地控制偏移量提交的时间点，那么就要仔细想想该如何提交偏移量了一一要么是为了减少重复处理消息，要么是因为把消息处理逻辑放在了轮询之外。</p><p>在开发具有可靠性的消费者应用程序时需要注意的事项。我们先从简单的开始，再逐步深入。</p><h4 id="1-总是在处理完事件后再提交偏移量"><a href="#1-总是在处理完事件后再提交偏移量" class="headerlink" title="1 . 总是在处理完事件后再提交偏移量"></a><strong>1 .</strong> <strong>总是在处理完事件后再提交偏移量</strong></h4><p>如果所有的处理都是在轮询里完成，而且消息处理总是幂等的，或者少量消息丢失无关紧要， 那么可以使用自动提交，或者在轮询结束时进行手动提交。</p><h4 id="2-提交频度是性能和重复消息数量之间的权衡"><a href="#2-提交频度是性能和重复消息数量之间的权衡" class="headerlink" title="2. 提交频度是性能和重复消息数量之间的权衡"></a><strong>2.</strong> <strong>提交频度是性能和重复消息数量之间的权衡</strong></h4><p>即使是在最简单的场景里，比如所有的处理都在轮询里完成，并且不需要在轮询之间维护状态，你仍然可以在一个循环里多次提交偏移量（甚至可以在每处理完一个事件之后），或者多个循环里只提交一次，这完全取决于你在性能和重复处理消息之间作出的权衡。</p><h4 id="3-确保对提交的偏移量心里有数"><a href="#3-确保对提交的偏移量心里有数" class="headerlink" title="3. 确保对提交的偏移量心里有数"></a><strong>3.</strong> <strong>确保对提交的偏移量心里有数</strong></h4><p>在轮询过程中提交偏移量有一个不好的地方，就是提交的偏移量有可能是读取到的最新偏移量，而不是处理过的最新偏移量。要记住，在处理完消息后再提交偏移量是非常关键的，否则会导致消费者错过消息。</p><h4 id="4-再均衡"><a href="#4-再均衡" class="headerlink" title="4 . 再均衡"></a><strong>4 .</strong> <strong>再均衡</strong></h4><p>在设计应用程序时要注意处理消费者的再均衡问题。一般要在分区被撤销之前提交偏移量，井在分配到新分区时清理之前的状态。</p><h4 id="5-消费者可能需要重试"><a href="#5-消费者可能需要重试" class="headerlink" title="5 . 消费者可能需要重试"></a><strong>5 .</strong> <strong>消费者可能需要重试</strong></h4><p>有时候，在进行轮询之后，有些消息不会被完全处理，可能稍后再来处理。例如，假设要把Kafka 的数据写到数据库里，不过那个时候数据库不可用，于是你想稍后重试。要注意，你提交的是偏移量，而不是对消息的“确认”，这个与传统的发布和订阅消息系统不太一样。如果记录的#30 处理失败，但记录的#31处理成功，那么你不应该提交#31， 否则会导致的#31以内的偏移量都被提交，包括的#30在内。不过可以采用下面这种模式来解决这个问题。</p><p>在遇到可重试错误时，把错误写入一个独立的主题，然后继续。一个独立的消费者群组负责从该主题上读取错误消息，并进行重试，或者使用其中的一个消费者同时从该主题上读取错误消息并进行重试，不过在重试时需要暂停该主题。这种模式有点像其他消息系统里的死信队列 。</p><h4 id="6-消费者可能需要维护状态"><a href="#6-消费者可能需要维护状态" class="headerlink" title="6 . 消费者可能需要维护状态"></a><strong>6 .</strong> <strong>消费者可能需要维护状态</strong></h4><p>有时候你希望在多个轮询之间维护状态，例如，你想计算消息的移动平均数，希望在首次轮询之后计算平均数，然后在后续的轮询中更新这个结果。如果进程重启，你不仅需要从上一个偏移量开始处理数据，还要恢复移动平均数。有一种办法是在提交偏移量的同时把最近计算的平均数写到一个“结果”主题上。消费者线程在重新启动之后，它就可以拿到最近的平均数并接着计算。不过这并不能完全地解决问题，因为Kafka 并没有提供事务支持。消费者有可能在写入平均数之后来不及提交偏移量就崩溃了，或者反过来也一样。这是一个很复杂的问题，你不应该尝试自己去解决这个问题，建议尝试一下Kafka流计算，它为聚合、连接、时间窗和其他复杂的分析提供了高级的API 。</p><h4 id="7-长时间处理"><a href="#7-长时间处理" class="headerlink" title="7. 长时间处理"></a><strong>7.</strong> <strong>长时间处理</strong></h4><p>有时候处理数据需要很长时间：你可能会从发生阻塞的外部系统获取信息，或者把数据写到外部系统，或者进行一个非常复杂的计算，但是我们要尽量保持轮询。在这种情况下， 一种常见的做法是使用一个线程地来处理数据，因为使用多个线程可以进行并行处理，从而加快处理速度。在把数据移交给线程地去处理之后，你就可以暂停消费者，然后保持轮询，但不获取新数据，直到工作线程处理完成。在工作线程处理完成之后，可以让消费者继续获取新数据。</p><h4 id="8-仅一次传递"><a href="#8-仅一次传递" class="headerlink" title="8. 仅一次传递"></a><strong>8.</strong> <strong>仅一次传递</strong></h4><p>有些应用程序不仅仅需要“至少一次”（意味着没有数据丢失），还需要“仅一次”语义。Kafka 现在还不能完全支持仅一次语义，消费者还是有一些办法可以保证Kafka 里的每个消息只被写到外部系统一次（但不会处理向Kafka 写入数据时可能出现的重复数据） 。</p><p>实现仅一次处理最简单且最常用的办能是把结果写到一个支持唯一键的系统里，比如键值存储引擎、关系型数据库、ElasticSearch 或其他数据存储引擎。在这种情况下，要么消息本身包含一个唯一键（通常都是这样），要么使用主题、分区和偏移量的组合来创建唯一键一一－它们的组合可以唯一标识一个Kafka 记录。如果你把消息和一个唯一键写入系统，然后碰巧又读到一个相同的消息，只要把原先的键值覆盖掉即可。数据存储引擎会覆盖已经存在的键值对，就像没有出现过重复数据一样。这个模式被叫作幂等性写入，它是一种很常见也很有用的模式。</p><p>如果写入消息的系统支持事务， 那么就可以使用另一种方法。最简单的是使用关系型数据库。我们把消息和偏移量放在同一个事务里，这样它们就能保持同步。在消费者启动时，它会获取最近处理过的消息偏移量，然后调用seek （）方也从该偏移量位置继续读取数据。</p><h1 id="数据管道和流式处理（了解即可）"><a href="#数据管道和流式处理（了解即可）" class="headerlink" title="数据管道和流式处理（了解即可）"></a><strong>数据管道和流式处理（了解即可）</strong></h1><h2 id="数据管道基本概念"><a href="#数据管道基本概念" class="headerlink" title="数据管道基本概念"></a><strong>数据管道基本概念</strong></h2><p>在使用Kafka 构建数据管道时，通常有两种使用场景： 第一种，把Kafka 作为数据管道的两个端点之一，例如，把Kafka 里的数据移动到云上，或者把Mongo DB 里的数据移动到Kafka 里；第二种，把Kafka 作为数据管道两个端点的中间媒介，例如，为了把DB的数据移动到ElasticSearch 上，需要先把它们移动到Kafka 里，再将它们从Kafka 移动到Elastic Search 上。</p><p>Kafka 为数据管道带来的主要价值在于，它可以作为数据管道各个数据段之间的大型缓冲区， 有效地解耦管道数据的生产者和消费者。数据管道的重要作用之一是解耦数据源和数据池，Kafka在这方面的能力以及在安全和效率方面的可靠性，使它成为构建数据管道的最佳选择。</p><h3 id="数据管道需要考虑的问题"><a href="#数据管道需要考虑的问题" class="headerlink" title="数据管道需要考虑的问题"></a><strong>数据管道需要考虑的问题</strong></h3><h4 id="及时性"><a href="#及时性" class="headerlink" title="及时性"></a><strong>及时性</strong></h4><p>有些系统希望每天一次性地接收大量数据，而有些则希望在数据生成几毫秒之内就能拿到它们。大部分数据管道介于这两者之间。一个好的数据集成系统能够很好地支持数据管道的各种及时性需求，而且在业务需求发生变更时，具有不同及时性需求的数据表之间可以方便地进行迁移。</p><p>Kafka 作为一个基于流的数据平台，提供了可靠且可伸缩的数据存储，可以支持几近实时的数据管道和基于小时的批处理。生产者可以频繁地向Kafka 写入数据，也可以按需写入：消费者可以在数据到达的第一时间读取它们，也可以每隔一段时间读取一次积压的数据。</p><p>Kafka 在这里扮演了一个大型缓冲区的角色，降低了生产者和消费者之间的时间敏感度。实时的生产者和基于批处理的消费者可以同时存在，也可以任意组合。实现回压策略也因此变得更加容易， Kafka 本身就使用了回压策略（必要时可以延后向生产者发送确认），消费速率完全取决于消费者自己。</p><h4 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a><strong>可靠性</strong></h4><p>我们要避免单点故障，并能够自动从各种故障中快速恢复。数据通过数据管道到达业务系统，哪怕出现几秒钟的故障，也会造成灾难性的影响，对于那些要求毫秒级的及时性系统来说尤为如此。数据传递保证是可靠性的另一个重要因素。有些系统允许数据丢失，不过在大多数情况下，它们要求至少一次传递。也就是说，源系统的每一个事件都必须到达目的地，不过有时候需要进行重试，而重试可能造成重复传递。有些系统甚至要求仅一次传递一一源系统的每一个事件都必须到达目的地，不允许丢失，也不允许重复。</p><h4 id="高吞吐量和动态吞吐量"><a href="#高吞吐量和动态吞吐量" class="headerlink" title="高吞吐量和动态吞吐量"></a><strong>高吞吐量和动态吞吐量</strong></h4><p>为了满足现代数据系统的要求，数据管道需要支持非常高的吞吐量。更重要的是，在某些情况下，数据管道还需要能够应对突发的吞吐量增长。</p><p>由于我们将Kafka 作为生产者和消费者之间的缓冲区，消费者的吞吐量和生产者的吞吐量就不会耦合在一起了。如果生产者的吞吐量超过了消费者的吞吐量，可以把数据积压在Kafka 里，等待消费者追赶上来。通过增加额外的消费者或生产者可以实现Kafka 的伸缩，因此我们可以在数据管道的任何一边进行动态的伸缩，以便满足持续变化的需求。</p><p>因为Kafka 是一个高吞吐量的分布式系统， 一个适当规模的集群每秒钟可以处理数百兆的数据，所以根本无需担心数据管道无住满足伸缩性需求。另外， Connect API 不仅支持伸缩，而且擅长并行处理任务。</p><h4 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a><strong>数据格式</strong></h4><p>数据管道需要协调各种数据格式和数据类型，这是数据管道的一个非常重要的因素。数据类型取决于不同的数据库和数据存储系统。你可能会通过Avro 将XML 或关系型数据加载到Kafka 里，然后将它们转成JSON 写入ElasticSearch ，或者写入HDFS 等等。 </p><p>Kafka 和与数据格式无关。生产者和消费者可以使用各种序列化器来表示任意格式的数据。</p><h2 id="流式处理基本概念"><a href="#流式处理基本概念" class="headerlink" title="流式处理基本概念"></a><strong>流式处理基本概念</strong></h2><p>Kafka 早期版本一般被认为是一个强大的消息总线，可以传递事件流，但没有处理和转换事件的能力。Kafka 可靠的传递能力让它成为流式处理系统完美的数据来源。很多基于Kafka 构建的流式处理系统都将Kafka 作为唯一可靠的数据来隙，如Apache Storm 、Apache SparkStreaming 、Apache Flink 、Apache Samza 等。</p><p>从0 . 10 . 0 版本开始， Kafka 不仅为每一个流行的流式处理框架提供了可靠的数据来橱， 还提供了一个强大的流式处理类库，并将其作为客户端类库的一部分。这样，开发人员就可以在应用程序里读取、处理和生成事件，而不需要再依赖外部的处理框架。</p><h3 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a><strong>数据流</strong></h3><p>先来看看什么是数据流（也被称为“事件流”或“流数据”）。首先，数据流是无边界数据集的抽象表示。无边界意味着无限和持续增长。无边界数据集之所以是无限的，是因为随着时间的推移，新的记录会不断加入进来。</p><p>这个简单的模型（事件流）可以表示很多业务活动，比如信用卡交易、股票交易、包裹递送、流经交换机的网络事件、制造商设备传感器发出的事件、发送出去的邮件、游戏里物体的移动，等等。这个清单是无穷无尽的，因为几乎每一件事情都可以被看成事件的序列。</p><p>除了没有边界外，事件流模型还有其他一些属性。</p><h4 id="事件流是有序的"><a href="#事件流是有序的" class="headerlink" title="事件流是有序的"></a><strong>事件流是有序的</strong></h4><p>事件的发生总是有个先后顺序。以金融活动事件为例，先将钱存进账户后再花钱，这与先花钱再还钱的次序是完全不一样的。后者会出现透支，而前者不会。</p><h4 id="不可变的数据记录"><a href="#不可变的数据记录" class="headerlink" title="不可变的数据记录"></a><strong>不可变的数据记录</strong></h4><p>事件一旦发生，就不能被改变。一个金融交易被取消，并不是说它就消失了，相反，这需要往事件流里添加一个额外的事件，表示前一个交易的取消操作。顾客的一次退货并不意味着之前的销售记录被删除，相反，退货行为被当成一个额外的事件记录下来。这是数据流与数据表之间的另一个不同点一一可以删除和修改数据表里的记录，但这些操作只不过是发生在数据库里的事务，这些事务可以被看成事件流。假设你对数据库的二进制日志（ bin log ）、预写式日志（ WAL ）和重做日志（ redo log ）的概念都很熟悉，那么就会知道，如果往数据库表插入一条记录，然后将其删除，表里就不会再有这条记录。但重做日志里包含了两个事务：插入事务和删除事务。</p><h4 id="事件流是可重播的"><a href="#事件流是可重播的" class="headerlink" title="事件流是可重播的"></a><strong>事件流是可重播的</strong></h4><p>这是事件流非常有价值的一个属性。但对于大多数业务来说，重播发生在几个月前（甚至几年前）的原始事件流是一个很重要的需求。可能是为了尝试使用新的分析方法纠正过去的错误，或是为了进行审计。</p><h3 id="什么是流式处理"><a href="#什么是流式处理" class="headerlink" title="什么是流式处理"></a><strong>什么是流式处理</strong></h3><p>流式处理是指实时地处理一个或多个事件流。流式处理是一种编程范式，就像请求与响应范式和批处理范式那样。</p><h4 id="请求与响应"><a href="#请求与响应" class="headerlink" title="请求与响应"></a><strong>请求与响应</strong></h4><p>这是延迟最小的一种范式，响应时间处于亚毫秒到毫秒之间，而且响应时间一般非常稳定。这种处理模式一般是阻塞的，应用程序向处理系统发出请求，然后等待响应。在数据库领域。</p><h4 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a><strong>批处理</strong></h4><p>这种范式具有高延迟和高吞吐量的特点。处理系统按照设定的时间启动处理进程，比如每天的下午两点开始启动，每小时启动一次等。它读取所有的输入数据（从上－ 次执行之后的所有可用数据，或者从月初开始的所有数据等）．输出结果，然后等待下一次启动。处理时间从几分钟到几小时不等，并且用户从结果里读到的都是旧数据。它们每天加载巨大批次的数据，并生成报表，用户在下一次加载数据之前看到的都是相同的报表。从规模上来说，这种范式既高效又经挤。但在近几年，为了能够更及时、高效地作出决策，业务要求在更短的时间内能提供可用的数据，这就给那些为探索规模经济而开发却无法提供低延迟报表的系统带来了巨大的压力。</p><h4 id="流式处理"><a href="#流式处理" class="headerlink" title="流式处理"></a><strong>流式处理</strong></h4><p>这种范式介于上述两者之间。大部分的业务不要求亚毫秒级的响应，不过也接受不了要等到第二天才知道结果。大部分业务流程都是持续进行的，只要业务报告保持更新，业务产品线能够持续响应，那么业务流程就可以进行下去，而无需等待特定的响应，也不要求在几毫秒内得到响应。一些业务流程具有持续性和非阻塞的特点，比如针对可疑信用卡交易的警告、网络警告、根据供应关系实时调整价格、跟踪包衷。</p><p>流的定义不依赖任何一个特定的框架、API 或特性。只要持续地从一个无边界的数据集读取数据，然后对它们进行处理并生成结果，那就是在进行流式处理。重点是，整个处理过程必须是持续的。一个在每天凌晨两点启动的流程，从流里读取500 条记录，生成结果，然后结束，这样的流程不是流式处理。</p><h3 id="流式处理中的基本概念"><a href="#流式处理中的基本概念" class="headerlink" title="流式处理中的基本概念"></a><strong>流式处理中的基本概念</strong></h3><p>流式处理的很多方面与普通的数据处理是很相似的：写一些代码来接收数据，对数据进行处理，可能做一些转换、聚合和增强的操作，然后把生成的结果输出到某个地方。不过流式处理有一些特有的概念，我们可以适当了解一下。</p><h4 id="时间"><a href="#时间" class="headerlink" title="时间"></a><strong>时间</strong></h4><p>在流式处理里，时间是一个非常重要的概念，因为大部分流式应用的操作都是基于时间窗口的。</p><p>例如，流式应用可能会计算股价的5 分钟移动平均数。如果生产者因为网络问题离线了2小时，然后带着2 小时的数据重新连线，我们需要知道该如何处理这些数据。这些数据大部分都已经超过了5 分钟，而且没有参与之前的计算。</p><p>流式处理系统一般包含如下几个时间概念。</p><h5 id="事件时间"><a href="#事件时间" class="headerlink" title="事件时间"></a>事件时间</h5><p>事件时间是指所追踪事件的发生时间和记录的创建时间。例如，度量的获取时间、商店里商品的出售时间、网站用户访问网页的时间，等等。在处理数据流肘，事件时间是很重要的。</p><h5 id="日志追加时间"><a href="#日志追加时间" class="headerlink" title="日志追加时间"></a>日志追加时间</h5><p>日志追加时间是指事件保存到broker 的时间。这个时间戳一般与流式处理没有太大关系，因为用户一般只对事件的发生时间感兴趣。例如，如果要计算每天生产了多少台设备，就需要计算在那一天实际生产的设备数量，尽管这些事件有可能因为网络问题到了第二天才进入Kafka 。不过，如果真实的事件时间没有被记录下来，那么就可以使用日志追加时间，在记录创建之后，这个时间就不会发生改变。</p><h5 id="处理时间"><a href="#处理时间" class="headerlink" title="处理时间"></a>处理时间</h5><p>处理时间是指应用程序在收到事件之后要对其进行处理的时间。这个时间可以是在事件发生之后的几毫秒、几小时或几天。同一个事件可能会被分配不同的时间戳，这取决于应用程序何时读取这个事件。如果应用程序使用了两个线程来读取同一个事件，这个时间戳也会不一样。所以这个时间戳非常不可靠，应该避免使用它。</p><h4 id="状态"><a href="#状态" class="headerlink" title="状态"></a><strong>状态</strong></h4><p>如果只是单独处理每一个事件，那么流式处理就很简单。例如，如果想从Kafka 读取电商购物交易事件流，找出金额超过10 000元的交易，并将结果通过邮件发送给销售人员，那么可以使用Kafka 消费者客户端，几行代码就可以搞定。</p><p>如果操作里包含了多个事件，流式处理就会变得很有意思，比如根据类型计算事件的数量、移动平均数、合并两个流以便生成更丰富的信息流。在这些情况下，光处理单个事件是不够的，需要跟踪更多的信息，比如这个小时内看到的每种类型事件的个数、需要合并的事件、将每种类型的事件值相加等等。事件与事件之间的信息被称为状态。</p><p>这些状态一般被保存在应用程序的本地变量里。流式处理包含以下几种类型的状态。</p><h5 id="本地状态或内部状态"><a href="#本地状态或内部状态" class="headerlink" title="本地状态或内部状态"></a>本地状态或内部状态</h5><p>这种状态只能被单个应用程序实例访问，它们一般使用内嵌在应用程序里的数据库进行维护和管理。本地状态的优势在于它的速度，不足之处在于它受到内存大小的限制。所以，流式处理的很多设计模式都将数据拆分到多个子流，这样就可以使用有限的本地状态来处理它们。</p><h5 id="外部状态"><a href="#外部状态" class="headerlink" title="外部状态"></a>外部状态</h5><p>这种状态使用外部的数据存储来维护， 一般使用NoSQL 系统，比如HDFS 。使用外部存储的优势在于，它没有大小的限制，而且可以被应用程序的多个实例访问，甚至被不同的应用程序访问。不足之处在于，引人额外的系统会造成更大的延迟和复杂性。大部分流式处理应用尽量避免使用外部存储，或者将信息缓存在本地，减少与外部存储发生交互，以此来降低延迟。</p><h4 id="流和表区别"><a href="#流和表区别" class="headerlink" title="流和表区别"></a><strong>流和表区别</strong></h4><p>大家都熟悉数据库表，表就是记录的集合，每个表都有一个主键，并包含了一系列由schema 定义的属性。表的记录是可变的（可以在表上面执行更新和删除操作）。我们可以通过查询表数据获知某一时刻的数据状态。例如，通过查询客户信息这个表，就可以获取所有客户的联系信息。如果表被设计成不包含历史信息，那么就找不到客户过去的联系信息了。</p><p>在将表与流进行对比时，可以这么想：流包含了变更一一流是一系列事件，每个事件就是一个变更。表包含了当前的状态，是多个变更所产生的结果。</p><p>为了将表转化成流，需要捕捉到在表上所发生的变更，将“ insert ”、“ update ”和“ delete ”事件保存到流里。大部分数据库提供了用于捕捉变更的“ Change Data Capture” (CDC ）解决方案， Kafka 连接器将这些变更发送到Kafka ，用于后续的流式处理。</p><p>假设有一个商店，某零售活动可以使用一个事件流来表示：</p><p>“红色、蓝色和绿色鞋子到货”</p><p>“蓝色鞋子卖出”</p><p>“红色鞋子卖出”</p><p>“蓝色鞋子退货”</p><p>“绿色鞋子卖出”</p><p>如果想知道现在仓库里还有哪些库存，或者到目前为止赚了多少钱，可以用表。如果想知道鞋店的繁忙程度，可以查看整个事件流，会发现总共发生了5 个交易，还可以查出为什么蓝色鞋子被退货。</p><h3 id="流式处理的常见场景"><a href="#流式处理的常见场景" class="headerlink" title="流式处理的常见场景"></a><strong>流式处理的常见场景</strong></h3><p>现在很多公司每天都会产生数以TB级的大数据，如何对这些数据进行挖掘，分析成了很重要的课题。比如：</p><p><strong>电子商务</strong>：需要处理并且挖掘用户行为产生的数据，产生推荐，从而带来更多的流量和收益。最理想的推荐就是根据兴趣推荐给用户本来不需要的东西！而每天处理海量的用户数据，需要一个低延时高可靠的实时流式分布式计算系统。</p><p><strong>在线订购</strong>：假设客户向一个大型的连锁酒店预订了一个房间，连锁酒店的每一个系统在预订结束之后的几秒钟或者几分钟之内都能发出通知，包括客服中心、酒店、发送确认邮件的系统、网站等。有的酒店可能还希望客服中心能够立即获知用户在这家连锁酒店的历史入住数据，前台能够知道他是一个忠实的客户，从而提供更高级别的服务。如果使用流式处理应用来构建这些系统，就可以实现几近实时的接收和处理这些事件，从而带来更好的用户体验。</p><p><strong>新闻聚合</strong>：新闻时效性非常重要，如果在一个重大事情发生后能够实时的推荐给用户，那么肯定能增大用户粘性，带来可观的流量。</p><p><strong>社交网站</strong>：大家每天都会去社交网站是为了看看现在发生了什么，周围人在做什么。流式计算可以把用户关注的热点聚合，实时反馈给用户，从而达到一个圈子的聚合效果。</p><p><strong>交通监管</strong>：每个城市的交通监管部门每天都要产生海量的视频数据，这些视频数据也是以流的形式源源不断的输系统中。实时流式计算系统需要以最快的速度来处理这些数据。</p><p><strong>数据挖掘和机器学习</strong>：它们实际上是互联网公司内部使用的系统，主要为线上服务提供数据支撑。它们可以说是互联网公司的最核心的平台之一。系统的效率是挖掘的关键，理想条件下就是每天产生的海量数据都能得到有效处理，对于原来的数据进行全量更新。</p><p><strong>大型集群的监控</strong>：自动化运维很重要，集群监控的实时预警机制也非常重要，而流式系统对于日志的实时处理，往往是监控系统的关键。</p><p><strong>物联网</strong>：物联网包含很多东西。流式处理在传感器和设备上应用，最为常见的是用于预测何时该进行设备维护。这个与应用监控有点相似，不过这次是应用在硬件上，而且应用在很多不同的行业一一制造业、通信（识别故障基站）、有线电视（在用户投诉之前识别出故障机顶盒）等。每一种场景都有自己的特点，不过目标是一样的处理大量来自设备的事件，并识别出一些模式，这些模式预示着某些设备需要进行维护，比如交换机数据包的下降、生产过程中需要更大的力气来拧紧螺丝， 或者用户频繁重启有线电视的机顶盒。</p><h3 id="Kafka流式处理实战"><a href="#Kafka流式处理实战" class="headerlink" title="Kafka流式处理实战"></a><strong>Kafka流式处理实战</strong></h3><p>参见模块kafka-stream下</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;深入理解Kafka&quot;&gt;&lt;a href=&quot;#深入理解Kafka&quot; class=&quot;headerlink&quot; title=&quot;深入理解Kafka&quot;&gt;&lt;/a&gt;&lt;strong&gt;深入理解Kafka&lt;/strong&gt;&lt;/h1&gt;&lt;h2 id=&quot;集群的成员关系&quot;&gt;&lt;a href=&quot;#集
      
    
    </summary>
    
      <category term="消息中间件" scheme="https://ellenjack.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
      <category term="Kafka" scheme="https://ellenjack.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/"/>
    
    
      <category term="Kafka" scheme="https://ellenjack.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka应用</title>
    <link href="https://ellenjack.github.io/2019/07/03/kafka-2/"/>
    <id>https://ellenjack.github.io/2019/07/03/kafka-2/</id>
    <published>2019-07-02T17:43:25.000Z</published>
    <updated>2020-03-25T16:12:24.796Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第一个Kafka程序"><a href="#第一个Kafka程序" class="headerlink" title="第一个Kafka程序"></a><strong>第一个Kafka程序</strong></h1><h2 id="创建我们的主题"><a href="#创建我们的主题" class="headerlink" title="创建我们的主题"></a><strong>创建我们的主题</strong></h2><p>kafka-topics.bat –zookeeper localhost:2181/kafka –create –topic hello-kafka –replication-factor 1 –partitions 4</p><h2 id="生产者发送消息"><a href="#生产者发送消息" class="headerlink" title="生产者发送消息"></a><strong>生产者发送消息</strong></h2><h4 id="必选属性"><a href="#必选属性" class="headerlink" title="必选属性"></a><strong>必选属性</strong></h4><p>创建生产者对象时有三个属性必须指定。</p><h5 id="bootstrap-servers"><a href="#bootstrap-servers" class="headerlink" title="bootstrap.servers"></a>bootstrap.servers</h5><p>该属性指定broker的地址清单，地址的格式为host：port。清单里不需要包含所有的broker地址，生产者会从给定的broker里查询其他broker的信息。不过最少提供2个broker的信息，一旦其中一个宕机，生产者仍能连接到集群上。</p><h5 id="key-serializer"><a href="#key-serializer" class="headerlink" title="key.serializer"></a>key.serializer</h5><p>生产者接口允许使用参数化类型，可以把Java对象作为键和值传broker，但是broker希望收到的消息的键和值都是字节数组，所以，必须提供将对象序列化成字节数组的序列化器。key.serializer必须设置为实现org.apache.kafka.common.serialization.Serializer的接口类，Kafka的客户端默认提供了ByteArraySerializer,IntegerSerializer, StringSerializer，也可以实现自定义的序列化器。</p><h5 id="value-serializer"><a href="#value-serializer" class="headerlink" title="value.serializer"></a>value.serializer</h5><p>同 key.serializer。</p><p>参见代码，模块kafka-no-spring下包hellokafka中</p><h2 id="消费者接受消息"><a href="#消费者接受消息" class="headerlink" title="消费者接受消息"></a><strong>消费者接受消息</strong></h2><h4 id="必选参数"><a href="#必选参数" class="headerlink" title="必选参数"></a><strong>必选参数</strong></h4><p>bootstrap.servers、key.serializer、value.serializer含义同生产者</p><h5 id="group-id"><a href="#group-id" class="headerlink" title="group.id"></a>group.id</h5><p>并非完全必需，它指定了消费者属于哪一个群组，但是创建不属于任何一个群组的消费者并没有问题。</p><p>参见代码，模块kafka-no-spring下包hellokafka中</p><h1 id="Kafka的生产者"><a href="#Kafka的生产者" class="headerlink" title="Kafka的生产者"></a><strong>Kafka的生产者</strong></h1><h2 id="生产者发送消息的基本流程"><a href="#生产者发送消息的基本流程" class="headerlink" title="生产者发送消息的基本流程"></a><strong>生产者发送消息的基本流程</strong></h2><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4m0qk6nsyj30j70ligok.jpg" alt="img"> </p><p>从创建一个ProducerRecord 对象开始， Producer Record 对象需要包含目标主题和要发送的内容。我们还可以指定键或分区。在发送ProducerReco rd 对象时，生产者要先把键和值对象序列化成字节数组，这样它们才能够在网络上传输。</p><p>接下来，数据被传给分区器。如果之前在Producer Record 对象里指定了分区，那么分区器就不会再做任何事情，直接把指定的分区返回。如果没有指定分区，那么分区器会根据Producer Record对象的键来选择一个分区。选好分区以后，生产者就知道该往哪个主题和分区发送这条记录了。紧接着，这条记录被添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上。有一个独立的线程负责把这些记录批次发送到相应的broker 上。</p><p>服务器在收到这些消息时会返回一个响应。如果消息成功写入Kafka ，就返回一个RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量。如果写入失败， 则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，几次之后如果还是失败，就返回错误信息。</p><h2 id="使用Kafka生产者"><a href="#使用Kafka生产者" class="headerlink" title="使用Kafka生产者"></a><strong>使用Kafka生产者</strong></h2><h3 id="三种发送方式"><a href="#三种发送方式" class="headerlink" title="三种发送方式"></a><strong>三种发送方式</strong></h3><p>我们通过生成者的send方法进行发送。send方法会返回一个包含RecordMetadata的Future对象。RecordMetadata里包含了目标主题，分区信息和消息的偏移量。</p><h4 id="发送并忘记"><a href="#发送并忘记" class="headerlink" title="发送并忘记"></a><strong>发送并忘记</strong></h4><p>忽略send方法的返回值，不做任何处理。大多数情况下，消息会正常到达，而且生产者会自动重试，但有时会丢失消息。</p><h4 id="同步非阻塞发送"><a href="#同步非阻塞发送" class="headerlink" title="同步非阻塞发送"></a><strong>同步非阻塞发送</strong></h4><p>获得send方法返回的Future对象，在合适的时候调用Future的get方法。参见代码，模块kafka-no-spring下包sendtype中。</p><h4 id="异步发送"><a href="#异步发送" class="headerlink" title="异步发送"></a><strong>异步发送</strong></h4><p>实现接口org.apache.kafka.clients.producer.Callback，然后将实现类的实例作为参数传递给send方法。参见代码，模块kafka-no-spring下包sendtype中。</p><h3 id="多线程下的生产者"><a href="#多线程下的生产者" class="headerlink" title="多线程下的生产者"></a><strong>多线程下的生产者</strong></h3><p>KafkaProducer的实现是线程安全的，所以我们可以在多线程的环境下，安全的使用KafkaProducer的实例，如何节约资源的使用呢？参见代码，模块kafka-no-spring下包concurrent中</p><h3 id="更多发送配置"><a href="#更多发送配置" class="headerlink" title="更多发送配置"></a><strong>更多发送配置</strong></h3><p>生产者有很多属性可以设置，大部分都有合理的默认值，无需调整。有些参数可能对内存使用，性能和可靠性方面有较大影响。可以参考org.apache.kafka.clients.producer包下的ProducerConfig类。</p><h5 id="acks："><a href="#acks：" class="headerlink" title="acks："></a>acks：</h5><p>指定了必须要有多少个分区副本收到消息，生产者才会认为写入消息是成功的，这个参数对消息丢失的可能性有重大影响。</p><p>acks=0：生产者在写入消息之前不会等待任何来自服务器的响应，容易丢消息，但是吞吐量高。</p><p>acks=1：只要集群的首领节点收到消息，生产者会收到来自服务器的成功响应。如果消息无法到达首领节点（比如首领节点崩溃，新首领没有选举出来），生产者会收到一个错误响应，为了避免数据丢失，生产者会重发消息。不过，如果一个没有收到消息的节点成为新首领，消息还是会丢失。默认使用这个配置。</p><p>acks=all：只有当所有参与复制的节点都收到消息，生产者才会收到一个来自服务器的成功响应。延迟高。</p><h5 id="buffer-memory"><a href="#buffer-memory" class="headerlink" title="buffer.memory"></a>buffer.memory</h5><p>设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果数据产生速度大于向broker发送的速度，导致生产者空间不足，producer会阻塞或者抛出异常。缺省33554432 (32M)</p><h5 id="max-block-ms"><a href="#max-block-ms" class="headerlink" title="max.block.ms"></a>max.block.ms</h5><p>指定了在调用send()方法或者使用partitionsFor()方法获取元数据时生产者的阻塞时间。当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞。在阻塞时间达到max.block.ms时，生产者会抛出超时异常。缺省60000ms</p><h5 id="retries"><a href="#retries" class="headerlink" title="retries"></a>retries</h5><p>发送失败时，指定生产者可以重发消息的次数。默认情况下，生产者在每次重试之间等待100ms，可以通过参数retry.backoff.ms参数来改变这个时间间隔。缺省0</p><h5 id="receive-buffer-bytes和send-buffer-bytes"><a href="#receive-buffer-bytes和send-buffer-bytes" class="headerlink" title="receive.buffer.bytes和send.buffer.bytes"></a>receive.buffer.bytes和send.buffer.bytes</h5><p>指定TCP socket接受和发送数据包的缓存区大小。如果它们被设置为-1，则使用操作系统的默认值。如果生产者或消费者处在不同的数据中心，那么可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。缺省102400</p><h5 id="batch-size"><a href="#batch-size" class="headerlink" title="batch.size"></a>batch.size</h5><p>当多个消息被发送同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。当批次内存被填满后，批次里的所有消息会被发送出去。但是生产者不一定都会等到批次被填满才发送，半满甚至只包含一个消息的批次也有可能被发送。缺省16384(16k)</p><h5 id="linger-ms"><a href="#linger-ms" class="headerlink" title="linger.ms"></a>linger.ms</h5><p>指定了生产者在发送批次前等待更多消息加入批次的时间。它和batch.size以先到者为先。也就是说，一旦我们获得消息的数量够batch.size的数量了，他将会立即发送而不顾这项设置，然而如果我们获得消息字节数比batch.size设置要小的多，我们需要“linger”特定的时间以获取更多的消息。这个设置默认为0，即没有延迟。设定linger.ms=5，例如，将会减少请求数目，但是同时会增加5ms的延迟，但也会提升消息的吞吐量。</p><h5 id="compression-type"><a href="#compression-type" class="headerlink" title="compression.type"></a>compression.type</h5><p>producer用于压缩数据的压缩类型。默认是无压缩。正确的选项值是none、gzip、snappy。压缩最好用于批量处理，批量处理消息越多，压缩性能越好。snappy占用cpu少，提供较好的性能和可观的压缩比，如果比较关注性能和网络带宽，用这个。如果带宽紧张，用gzip，会占用较多的cpu，但提供更高的压缩比。</p><h5 id="client-id"><a href="#client-id" class="headerlink" title="client.id"></a>client.id</h5><p>当向server发出请求时，这个字符串会发送给server。目的是能够追踪请求源头，以此来允许ip/port许可列表之外的一些应用可以发送信息。这项应用可以设置任意字符串，因为没有任何功能性的目的，除了记录和跟踪。</p><h5 id="max-in-flight-requests-per-connection"><a href="#max-in-flight-requests-per-connection" class="headerlink" title="max.in.flight.requests.per.connection"></a>max.in.flight.requests.per.connection</h5><p>指定了生产者在接收到服务器响应之前可以发送多个消息，值越高，占用的内存越大，当然也可以提升吞吐量。发生错误时，可能会造成数据的发送顺序改变,默认是5 (修改）。</p><p>如果需要保证消息在一个分区上的严格顺序，这个值应该设为1。不过这样会严重影响生产者的吞吐量。</p><h5 id="request-timeout-ms"><a href="#request-timeout-ms" class="headerlink" title="request.timeout.ms"></a>request.timeout.ms</h5><p>客户端将等待请求的响应的最大时间,如果在这个时间内没有收到响应，客户端将重发请求;超过重试次数将抛异常</p><h5 id="metadata-fetch-timeout-ms"><a href="#metadata-fetch-timeout-ms" class="headerlink" title="metadata.fetch.timeout.ms"></a>metadata.fetch.timeout.ms</h5><p>是指我们所获取的一些元数据的第一个时间数据。元数据包含：topic，host，partitions。此项配置是指当等待元数据fetch成功完成所需要的时间，否则会跑出异常给客户端</p><h5 id="timeout-ms"><a href="#timeout-ms" class="headerlink" title="timeout.ms"></a>timeout.ms</h5><p>此配置选项控制broker等待副本确认的最大时间。如果确认的请求数目在此时间内没有实现，则会返回一个错误。这个超时限制是以server端度量的，没有包含请求的网络延迟。这个参数和acks的配置相匹配。</p><h5 id="max-request-size"><a href="#max-request-size" class="headerlink" title="max.request.size"></a>max.request.size</h5><p>控制生产者发送请求最大大小。假设这个值为1M，如果一个请求里只有一个消息，那这个消息不能大于1M，如果一次请求是一个批次，该批次包含了1000条消息，那么每个消息不能大于1KB。注意：broker具有自己对消息记录尺寸的覆盖，如果这个尺寸小于生产者的这个设置，会导致消息被拒绝。</p><h4 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a><strong>顺序保证</strong></h4><p>Kafka 可以保证同一个分区里的消息是有序的。也就是说，如果生产者一定的顺序发送消息， broker 就会按照这个顺序把它们写入分区，消费者也会按照同样的顺序读取它们。在某些情况下， 顺序是非常重要的。例如，往一个账户存入100 元再取出来，这个与先取钱再存钱是截然不同的！不过，有些场景对顺序不是很敏感。</p><p>如果把retires设为非零整数，同时把max.in.flight.request.per.connection设为比1 大的数，那么，如果第一个批次消息写入失败，而第二个批次写入成功， broker 会重试写入第一个批次。如果此时第一个批次也写入成功，那么两个批次的顺序就反过来了。</p><p>一般来说，如果某些场景要求消息是有序的，那么消息是否写入成功也是很关键的，所以不建议把retires设为0 。可以把max.in.flight.request.per.connection 设为1，这样在生产者尝试发送第一批消息时，就不会有其他的消息发送给broker 。不过这样会严重影响生产者的吞吐量，所以只有在对消息的顺序有严格要求的情况下才能这么做。</p><h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a><strong>序列化</strong></h2><p>创建生产者对象必须指定序列化器，默认的序列化器并不能满足我们所有的场景。我们完全可以自定义序列化器。只要实现org.apache.kafka.common.serialization.Serializer接口即可。</p><p>如何实现，看模块kafka-no-spring下包selfserial中代码。</p><h3 id="自定义序列化需要考虑的问题"><a href="#自定义序列化需要考虑的问题" class="headerlink" title="自定义序列化需要考虑的问题"></a><strong>自定义序列化需要考虑的问题</strong></h3><p>自定义序列化容易导致程序的脆弱性。举例，在我们上面的实现里，我们有多种类型的消费者，每个消费者对实体字段都有各自的需求，比如，有的将字段变更为long型，有的会增加字段，这样会出现新旧消息的兼容性问题。特别是在系统升级的时候，经常会出现一部分系统升级，其余系统被迫跟着升级的情况。</p><p>解决这个问题，可以考虑使用自带格式描述以及语言无关的序列化框架。比如Protobuf，或者Kafka官方推荐的Apache Avro。</p><p>Avro会使用一个JSON文件作为schema来描述数据，Avro在读写时会用到这个schema，可以把这个schema内嵌在数据文件中。这样，不管数据格式如何变动，消费者都知道如何处理数据。</p><p>但是内嵌的消息，自带格式，会导致消息的大小不必要的增大，消耗了资源。我们可以使用schema注册表机制，将所有写入的数据用到的schema保存在注册表中，然后在消息中引用schema的标识符，而读取的数据的消费者程序使用这个标识符从注册表中拉取schema来反序列化记录。</p><p><strong>注意</strong>：Kafka本身并不提供schema注册表，需要借助第三方，现在已经有很多的开源实现，比如Confluent Schema Registry，可以从GitHub上获取。如何使用参考如下网址：</p><p><a href="https://cloud.tencent.com/developer/article/1336568" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1336568</a></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4m0qqhgpij30or0e6770.jpg" alt="img"> </p><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a><strong>分区</strong></h2><p>我们在新增ProducerRecord对象中可以看到，ProducerRecord包含了目标主题，键和值，Kafka的消息都是一个个的键值对。键可以设置为默认的null。</p><p>键的主要用途有两个：一，用来决定消息被写往主题的哪个分区，拥有相同键的消息将被写往同一个分区，二，还可以作为消息的附加消息。</p><p>如果键值为null，并且使用默认的分区器，分区器使用轮询算法将消息均衡地分布到各个分区上。</p><p>如果键不为空，并且使用默认的分区器，Kafka对键进行散列（Kafka自定义的散列算法，具体算法原理不知），然后根据散列值把消息映射到特定的分区上。很明显，同一个键总是被映射到同一个分区。但是只有不改变主题分区数量的情况下，键和分区之间的映射才能保持不变，一旦增加了新的分区，就无法保证了，所以如果要使用键来映射分区，那就要在创建主题的时候把分区规划好，而且永远不要增加新分区。</p><h3 id="自定义分区器"><a href="#自定义分区器" class="headerlink" title="自定义分区器"></a><strong>自定义分区器</strong></h3><p>某些情况下，数据特性决定了需要进行特殊分区，比如电商业务，北京的业务量明显比较大，占据了总业务量的20%，我们需要对北京的订单进行单独分区处理，默认的散列分区算法不合适了， 我们就可以自定义分区算法，对北京的订单单独处理，其他地区沿用散列分区算法。或者某些情况下，我们用value来进行分区。</p><p>具体实现，先创建一个4分区的主题，然后观察模块kafka-no-spring下包SelfPartitionProducer中代码。</p><h1 id="Kafka的消费者"><a href="#Kafka的消费者" class="headerlink" title="Kafka的消费者"></a><strong>Kafka的消费者</strong></h1><h2 id="消费者和消费者群组、分区再均衡"><a href="#消费者和消费者群组、分区再均衡" class="headerlink" title="消费者和消费者群组、分区再均衡"></a><strong>消费者和消费者群组、分区再均衡</strong></h2><p>消费者的含义，同一般消息中间件中消费者的概念。在高并发的情况下，生产者产生消息的速度是远大于消费者消费的速度，单个消费者很可能会负担不起，此时有必要对消费者进行横向伸缩，于是我们可以使用多个消费者从同一个主题读取消息，对消息进行分流。</p><h3 id="消费者群组"><a href="#消费者群组" class="headerlink" title="消费者群组"></a><strong>消费者群组</strong></h3><p>Kafka里消费者从属于消费者群组，一个群组里的消费者订阅的都是同一个主题，每个消费者接收主题一部分分区的消息。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4m0qmsfnhj30f50amq50.jpg" alt="img"> </p><p>如上图，主题T有4个分区，群组中只有一个消费者，则该消费者将收到主题T1全部4个分区的消息。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4m0qlxma1j30fi0abtb3.jpg" alt="img"> </p><p>如上图，在群组中增加一个消费者2，那么每个消费者将分别从两个分区接收消息，上图中就表现为消费者1接收分区1和分区3的消息，消费者2接收分区2和分区4的消息。</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4m0qndb1fj30ex0bf779.jpg" alt="img"> </p><p>如上图，在群组中有4个消费者，那么每个消费者将分别从1个分区接收消息。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4m0qofemfj30fj0dk41v.jpg" alt="img"> </p><p>但是，当我们增加更多的消费者，超过了主题的分区数量，就会有一部分的消费者被闲置，不会接收到任何消息。</p><p>往消费者群组里增加消费者是进行横向伸缩能力的主要方式。所以我们有必要为主题设定合适规模的分区，在负载均衡的时候可以加入更多的消费者。但是要记住，一个群组里消费者数量超过了主题的分区数量，多出来的消费者是没有用处的。</p><p>如果是多个应用程序，需要从同一个主题中读取数据，只要保证每个应用程序有自己的消费者群组就行了。如下图所示：</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4m0qppc15j30a30bw410.jpg" alt="img"> </p><p>具体实现，先建立一个2分区的主题，看模块kafka-no-spring下包consumergroup中代码。</p><h3 id="分区再均衡"><a href="#分区再均衡" class="headerlink" title="分区再均衡"></a><strong>分区再均衡</strong></h3><p>当消费者群组里的消费者发生变化，或者主题里的分区发生了变化，都会导致再均衡现象的发生。从前面的知识中，我们知道，Kafka中，存在着消费者对分区所有权的关系，</p><p>这样无论是消费者变化，比如增加了消费者，新消费者会读取原本由其他消费者读取的分区，消费者减少，原本由它负责的分区要由其他消费者来读取，增加了分区，哪个消费者来读取这个新增的分区，这些行为，都会导致分区所有权的变化，这种变化就被称为<strong>再均衡</strong>。</p><p>再均衡对Kafka很重要，这是消费者群组带来高可用性和伸缩性的关键所在。不过一般情况下，尽量减少再均衡，因为再均衡期间，消费者是无法读取消息的，会造成整个群组一小段时间的不可用。</p><p>消费者通过向称为群组协调器的broker（不同的群组有不同的协调器）发送心跳来维持它和群组的从属关系以及对分区的所有权关系。如果消费者长时间不发送心跳，群组协调器认为它已经死亡，就会触发一次再均衡。</p><p>在0.10.1及以后的版本中，心跳由单独的线程负责，相关的控制参数为max.poll.interval.ms。</p><h4 id="消费者分区分配的过程"><a href="#消费者分区分配的过程" class="headerlink" title="消费者分区分配的过程"></a><strong>消费者分区分配的过程</strong></h4><p>消费者要加入群组时，会向群组协调器发送一个JoinGroup请求，第一个加入群主的消费者成为群主，群主会获得群组的成员列表，并负责给每一个消费者分配分区。分配完毕后，群组把分配情况发送给群组协调器，协调器再把这些信息发送给所有的消费者，每个消费者只能看到自己的分配信息，只有群主知道群组里所有消费者的分配信息。这个过程在每次再均衡时都会发生。</p><h2 id="使用Kafka消费者"><a href="#使用Kafka消费者" class="headerlink" title="使用Kafka消费者"></a><strong>使用Kafka消费者</strong></h2><h3 id="订阅"><a href="#订阅" class="headerlink" title="订阅"></a><strong>订阅</strong></h3><p>创建消费者后，使用subscribe()方法订阅主题，这个方法接受一个主题列表为参数，也可以接受一个正则表达式为参数；正则表达式同样也匹配多个主题。如果新创建了新主题，并且主题名字和正则表达式匹配，那么会立即触发一次再均衡，消费者就可以读取新添加的主题。比如，要订阅所有和test相关的主题，可以subscribe(“tets.*”)</p><h3 id="轮询"><a href="#轮询" class="headerlink" title="轮询"></a><strong>轮询</strong></h3><p>为了不断的获取消息，我们要在循环中不断的进行轮询，也就是不停调用poll方法。</p><p>poll方法的参数为超时时间，控制poll方法的阻塞时间，它会让消费者在指定的毫秒数内一直等待broker返回数据。poll方法将会返回一个记录（消息）列表，每一条记录都包含了记录所属的主题信息，记录所在分区信息，记录在分区里的偏移量，以及记录的键值对。</p><p>poll方法不仅仅只是获取数据，在新消费者第一次调用时，它会负责查找群组，加入群组，接受分配的分区。如果发生了再均衡，整个过程也是在轮询期间进行的。</p><h3 id="多线程下的消费者"><a href="#多线程下的消费者" class="headerlink" title="多线程下的消费者"></a><strong>多线程下的消费者</strong></h3><p>KafkaConsumer的实现<strong>不是</strong>线程安全的，所以我们在多线程的环境下，使用KafkaConsumer的实例要小心，应该每个消费数据的线程拥有自己的KafkaConsumer实例，如何使用？参见代码，模块kafka-no-spring下包concurrent中</p><h3 id="消费者配置"><a href="#消费者配置" class="headerlink" title="消费者配置"></a><strong>消费者配置</strong></h3><p>消费者有很多属性可以设置，大部分都有合理的默认值，无需调整。有些参数可能对内存使用，性能和可靠性方面有较大影响。可以参考org.apache.kafka.clients.consumer包下ConsumerConfig类。</p><h5 id="fetch-min-bytes"><a href="#fetch-min-bytes" class="headerlink" title="fetch.min.bytes"></a>fetch.min.bytes</h5><p>每次fetch请求时，server应该返回的最小字节数。如果没有足够的数据返回，请求会等待，直到足够的数据才会返回。缺省为1个字节。多消费者下，可以设大这个值，以降低broker的工作负载</p><h5 id="fetch-wait-max-ms"><a href="#fetch-wait-max-ms" class="headerlink" title="fetch.wait.max.ms"></a>fetch.wait.max.ms</h5><p>如果没有足够的数据能够满足fetch.min.bytes，则此项配置是指在应答fetch请求之前，server会阻塞的最大时间。缺省为500个毫秒。和上面的fetch.min.bytes结合起来，要么满足数据的大小，要么满足时间，就看哪个条件先满足。</p><h5 id="max-partition-fetch-bytes"><a href="#max-partition-fetch-bytes" class="headerlink" title="max.partition.fetch.bytes"></a>max.partition.fetch.bytes</h5><p>指定了服务器从每个分区里返回给消费者的最大字节数，默认1MB。假设一个主题有20个分区和5个消费者，那么每个消费者至少要有4MB的可用内存来接收记录，而且一旦有消费者崩溃，这个内存还需更大。注意，这个参数要比服务器的message.max.bytes更大，否则消费者可能无法读取消息。</p><h5 id="session-timeout-ms"><a href="#session-timeout-ms" class="headerlink" title="session.timeout.ms"></a>session.timeout.ms</h5><p>如果consumer在这段时间内没有发送心跳信息，则它会被认为挂掉了。默认3秒。</p><h5 id="auto-offset-reset"><a href="#auto-offset-reset" class="headerlink" title="auto.offset.reset"></a>auto.offset.reset</h5><p>消费者在读取一个没有偏移量的分区或者偏移量无效的情况下，如何处理。默认值是latest，从最新的记录开始读取，另一个值是earliest，表示消费者从起始位置读取分区的记录。</p><p><strong>注意</strong>：默认值是latest，意思是说，在偏移量无效的情况下，消费者将从最新的记录开始读取数据（<strong>在消费者启动之后生成的记录</strong>），可以先启动生产者，再启动消费者，观察到这种情况。观察代码，在模块kafka-no-spring下包hellokafka中。</p><h5 id="enable-auto-commit"><a href="#enable-auto-commit" class="headerlink" title="enable .auto.commit"></a>enable .auto.commit</h5><p>默认值true，表明消费者是否自动提交偏移。为了尽量避免重复数据和数据丢失，可以改为false，自行控制何时提交。</p><h5 id="partition-assignment-strategy"><a href="#partition-assignment-strategy" class="headerlink" title="partition.assignment.strategy"></a>partition.assignment.strategy</h5><p>分区分配给消费者的策略。系统提供两种策略。默认为Range。允许自定义策略。</p><h6 id="Range"><a href="#Range" class="headerlink" title="Range"></a><em>Range</em></h6><p>把主题的连续分区分配给消费者。例如，有主题T1和T2，各有3个分区，消费者C1和C2，则<strong>可能</strong>的分配形式为：</p><p>C1: T1(0，1),T2(0,，1)</p><p>C2: T1(2),T2(2)</p><h6 id="RoundRobin"><a href="#RoundRobin" class="headerlink" title="RoundRobin"></a><em>RoundRobin</em></h6><p>把主题的分区循环分配给消费者。例如，有主题T1和T2，各有3个分区，消费者C1和C2，则<strong>可能</strong>的分配形式为：</p><p>C1: T1(0，2),T2(1)</p><p>C2: T1(1),T2(0，2)</p><h6 id="自定义策略"><a href="#自定义策略" class="headerlink" title="自定义策略"></a><em>自定义策略</em></h6><p>extends 类AbstractPartitionAssignor，然后在消费者端增加参数：</p><p>properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, 类.class.getName());即可。</p><h5 id="client-id-1"><a href="#client-id-1" class="headerlink" title="client.id"></a>client.id</h5><p>当向server发出请求时，这个字符串会发送给server。目的是能够追踪请求源头，以此来允许ip/port许可列表之外的一些应用可以发送信息。这项应用可以设置任意字符串，因为没有任何功能性的目的，除了记录和跟踪。</p><h5 id="max-poll-records"><a href="#max-poll-records" class="headerlink" title="max.poll.records"></a>max.poll.records</h5><p>控制每次poll方法返回的的记录数量。</p><h5 id="receive-buffer-bytes和send-buffer-bytes-1"><a href="#receive-buffer-bytes和send-buffer-bytes-1" class="headerlink" title="receive.buffer.bytes和send.buffer.bytes"></a>receive.buffer.bytes和send.buffer.bytes</h5><p>指定TCP socket接受和发送数据包的缓存区大小。如果它们被设置为-1，则使用操作系统的默认值。如果生产者或消费者处在不同的数据中心，那么可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。</p><h2 id="提交和偏移量"><a href="#提交和偏移量" class="headerlink" title="提交和偏移量"></a><strong>提交和偏移量</strong></h2><p>当我们调用poll方法的时候，broker返回的是生产者写入Kafka但是还没有被消费者读取过的记录，消费者可以使用Kafka来追踪消息在分区里的位置，我们称之为<strong>偏移量</strong>。消费者更新自己读取到哪个消息的操作，我们称之为<strong>提交</strong>。</p><p>消费者是如何提交偏移量的呢？消费者会往一个叫做_consumer_offset的特殊主题发送一个消息，里面会包括每个分区的偏移量。发生了再均衡之后，消费者可能会被分配新的分区，为了能够继续工作，消费者者需要读取每个分区最后一次提交的偏移量，然后从指定的地方，继续做处理。</p><p>如果提交的偏移量小于消费者实际处理的最后一个消息的偏移量，处于两个偏移量之间的消息会被重复处理，</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4m0qkueuvj30sn085q57.jpg" alt="img"> </p><p>如果提交的偏移量大于客户端处理的最后一个消息的偏移量,那么处于两个偏移量之间的消息将会丢失</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4m0qla9fqj30t807agna.jpg" alt="img"> </p><p>所以, 处理偏移量的方式对客户端会有很大的影响 。KafkaConsumer API提供了很多种方式来提交偏移量 。</p><h3 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a><strong>自动提交</strong></h3><p>最简单的提交方式是让消费者自动提交偏移量。 如果 enable.auto.comnit被设为 true，消费者会自动把从poll()方法接收到的<strong>最大</strong>偏移量提交上去。提交时间间隔由auto.commit.interval.ms控制，默认值是5s。自动提交是在轮询里进行的，消费者每次在进行轮询时会检査是否该提交偏移量了，如果是，那么就会提交从上一次轮询返回的偏移量。</p><p>不过,在使用这种简便的方式之前,需要知道它将会带来怎样的结果。</p><p>假设我们仍然使用默认的5s提交时间间隔, 在最近一次提交之后的3s发生了再均衡，再均衡之后,消费者从最后一次提交的偏移量位置开始读取消息。这个时候偏移量已经落后了3s，所以在这3s内到达的消息会被重复处理。可以通过修改提交时间间隔来更频繁地提交偏移量, 减小可能出现重复消息的时间窗, 不过这种情况是无法完全避免的 。</p><p>在使用自动提交时,每次调用轮询方法都会把上一次调用返回的偏移量提交上去,它并不知道具体哪些消息已经被处理了,所以在再次调用之前最好确保所有当前调用返回的消息都已经处理完毕(enable.auto.comnit被设为 true时，在调用 close()方法之前也会进行自动提交)。一般情况下不会有什么问题,不过在处理异常或提前退出轮询时要格外小心。</p><p>自动提交虽然方便,不过并没有为我们留有余地来避免重复处理消息。</p><h3 id="手动提交"><a href="#手动提交" class="headerlink" title="手动提交"></a><strong>手动提交</strong></h3><p>我们通过控制偏移量提交时间来消除丢失消息的可能性，并在发生再均衡时减少重复消息的数量。消费者API提供了另一种提交偏移量的方式，开发者可以在必要的时候提交当前偏移量,而不是基于时间间隔。</p><p>把auto.commit. offset设为 false，自行决定何时提交偏移量。使用 commitsync()提交偏移量最简单也最可靠。这个方法会提交由poll()方法返回的最新偏移量，提交成功后马上返回,如果提交失败就抛出异常。</p><p>注意： commitsync()将会提交由poll()返回的最新偏移量,所以在处理完所有记录后要确保调用了 commitsync()，否则还是会有丢失消息的风险。如果发生了再均衡,从最近批消息到发生再均衡之间的所有消息都将被重复处理。</p><p>具体使用，参见模块kafka-no-spring下包commit包中代码。</p><h3 id="异步提交"><a href="#异步提交" class="headerlink" title="异步提交"></a><strong>异步提交</strong></h3><p>手动提交时，在broker对提交请求作出回应之前，应用程序会一直阻塞。这时我们可以使用异步提交API，我们只管发送提交请求，无需等待broker的响应。</p><p>具体使用，参见模块kafka-no-spring下包commit包中代码。</p><p>在成功提交或碰到无法恢复的错误之前, commitsync()会一直重试,但是 commitAsync不会。它之所以不进行重试,是因为在它收到服务器响应的时候,可能有一个更大的偏移量已经提交成功。</p><p>假设我们发出一个请求用于提交偏移量2000,,这个时候发生了短暂的通信问题,服务器收不到请求,自然也不会作出任何响应。与此同时,我们处理了另外一批消息,并成功提交了偏移量3000。如果commitAsync()重新尝试提交偏移量2000,它有可能在偏移量3000之后提交成功。这个时候如果发生再均衡,就会出现重复消息。</p><p>commitAsync()也支持回调,在 broker作出响应时会执行回调。回调经常被用于记录提交错误或生成度量指标。</p><p>回调具体使用，参见模块kafka-no-spring下包commit包中代码。</p><h3 id="同步和异步组合"><a href="#同步和异步组合" class="headerlink" title="同步和异步组合"></a><strong>同步和异步组合</strong></h3><p>一般情况下,针对偶尔出现的提交失败,不进行重试不会有太大问题，因为如果提交失败是因为临时问题导致的,那么后续的提交总会有成功的。但如果这是发生在关闭消费者或再均衡前的最后一次提交,就要确保能够提交成功。</p><p>因此,在消费者关闭前一般会组合使用 commitAsync()和 commitsync()。具体使用，参见模块kafka-no-spring下包commit包中代码。</p><h3 id="特定提交"><a href="#特定提交" class="headerlink" title="特定提交"></a><strong>特定提交</strong></h3><p>在我们前面的提交中，提交偏移量的频率与处理消息批次的频率是一样的。但如果想要更频繁地提交该怎么办?</p><p>如果poll()方法返回一大批数据,为了避免因再均衡引起的重复处理整批消息,想要在批次中间提交偏移量该怎么办?这种情况无法通过调用 commitSync()或 commitAsync()来实现，因为它们只会提交最后一个偏移量,而此时该批次里的消息还没有处理完。</p><p>消费者API允许在调用 commitsync()和 commitAsync()方法时传进去希望提交的分区和偏移量的map。假设我们处理了半个批次的消息,最后一个来自主题“customers”，分区3的消息的偏移量是5000，你可以调用 commitsync()方法来提交它。不过，因为消费者可能不只读取一个分区,因为我们需要跟踪所有分区的偏移量,所以在这个层面上控制偏移量的提交会让代码变复杂。</p><p>具体使用，参见模块kafka-no-spring下包commit包中代码。</p><h2 id="再均衡监听器"><a href="#再均衡监听器" class="headerlink" title="再均衡监听器"></a><strong>再均衡监听器</strong></h2><p>在提交偏移量一节中提到过,消费者在退出和进行分区再均衡之前,会做一些清理工作比如，提交偏移量、关闭文件句柄、数据库连接等。</p><p>在为消费者分配新分区或移除旧分区时,可以通过消费者API执行一些应用程序代码，在调用 subscribe()方法时传进去一个 ConsumerRebalancelistener实例就可以了。</p><p>ConsumerRebalancelistener有两个需要实现的方法。</p><p>1) public void onPartitionsRevoked( Collection&lt; TopicPartition&gt; partitions)方法会在</p><p>再均衡开始之前和消费者停止读取消息之后被调用。如果在这里提交偏移量，下一个接管分区的消费者就知道该从哪里开始读取了</p><p>2) public void onPartitionsAssigned( Collection&lt; TopicPartition&gt; partitions)方法会在重新分配分区之后和消费者开始读取消息之前被调用。</p><p>具体使用，我们先创建一个3分区的主题，然后实验一下，参见模块kafka-no-spring下rebalance包中代码。</p><h2 id="从特定偏移量处开始记录"><a href="#从特定偏移量处开始记录" class="headerlink" title="从特定偏移量处开始记录"></a><strong>从特定偏移量处开始记录</strong></h2><p>到目前为止,我们知道了如何使用poll()方法从各个分区的最新偏移量处开始处理消息。</p><p>不过,有时候我们也需要从特定的偏移量处开始读取消息。</p><p>如果想从分区的起始位置开始读取消息,或者直接跳到分区的末尾开始读取消息,可以使 seekToBeginning(Collection<topicpartition> tp)和 seekToEnd( Collection<topicpartition>tp)这两个方法。</topicpartition></topicpartition></p><p>不过,Kaka也为我们提供了用于查找特定偏移量的API。它有很多用途,比如向后回退几个消息或者向前跳过几个消息(对时间比较敏感的应用程序在处理滞后的情况下希望能够向前跳过若干个消息)。在使用 Kafka以外的系统来存储偏移量时,它将给我们带来更大的惊喜–让消息的业务处理和偏移量的提交变得一致。</p><p>试想一下这样的场景:应用程序从Kaka读取事件(可能是网站的用户点击事件流),对它们进行处理(可能是使用自动程序清理点击操作并添加会话信息),然后把结果保存到数据库。假设我们真的不想丢失任何数据,也不想在数据库里多次保存相同的结果。</p><p>我们可能会，毎处理一条记录就提交一次偏移量。尽管如此,在记录被保存到数据库之后以及偏移量被提交之前,应用程序仍然有可能发生崩溃,导致重复处理数据,数据库里就会出现重复记录。</p><p>如果保存记录和偏移量可以在一个原子操作里完成,就可以避免出现上述情况。记录和偏移量要么都被成功提交,要么都不提交。如果记录是保存在数据库里而偏移量是提交到Kafka上,那么就无法实现原子操作不过,如果在同一个事务里把记录和偏移量都写到数据库里会怎样呢?那么我们就会知道记录和偏移量要么都成功提交,要么都没有,然后重新处理记录。</p><p>现在的问题是:如果偏移量是保存在数据库里而不是 Kafka里,那么消费者在得到新分区时怎么知道该从哪里开始读取?这个时候可以使用seek()方法。在消费者启动或分配到新分区时,可以使用seck()方法查找保存在数据库里的偏移量。我们可以使用使用 Consumer Rebalancelistener和seek()方法确保我们是从数据库里保存的偏移量所指定的位置开始处理消息的。</p><p>具体使用，参见模块kafka-no-spring下包rebalance包中代码。</p><h2 id="优雅退出"><a href="#优雅退出" class="headerlink" title="优雅退出"></a><strong>优雅退出</strong></h2><p>如果确定要退出循环,需要通过另一个线程调用 consumer. wakeup()方法。如果循环运行在主线程里,可以在 ShutdownHook里调用该方法。要记住, consumer. wakeup()是消费者唯一一个可以从其他线程里安全调用的方法。调用 consumer. wakeup()可以退出poll(),并抛出 WakeupException异常。我们不需要处理 Wakeup Exception,因为它只是用于跳出循环的一种方式。不过,在退出线程之前调用 consumer.close()是很有必要的,它会提交任何还没有提交的东西,并向群组协调器发送消息,告知自己要离开群组,接下来就会触发再均衡,而不需要等待会话超时。</p><h2 id="反序列化"><a href="#反序列化" class="headerlink" title="反序列化"></a><strong>反序列化</strong></h2><p>不过就是序列化过程的一个反向，原理和实现可以参考生产者端的实现，同样也可以自定义反序列化器。</p><h2 id="独立消费者"><a href="#独立消费者" class="headerlink" title="独立消费者"></a><strong>独立消费者</strong></h2><p>到目前为止,我们讨论了消费者群组,分区被自动分配给群组里的消费者,在群组里新增或移除消费者时自动触发再均衡。不过有时候可能只需要一个消费者从一个主题的所有分区或者某个特定的分区读取数据。这个时候就不需要消费者群组和再均衡了,只需要把主题或者分区分配给消费者,然后开始读取消息并提交偏移量。</p><p>如果是这样的话,就不需要订阅主题,取而代之的是为自己分配分区。一个消费者可以订阅主题(并加入消费者群组),或者为自己分配分区,但不能同时做这两件事情。</p><p>具体使用，参见模块kafka-no-spring下包independconsumer中代码。</p><h1 id="Spring和Kafka的整合"><a href="#Spring和Kafka的整合" class="headerlink" title="Spring和Kafka的整合"></a><strong>Spring和Kafka的整合</strong></h1><p>参见模块kafka-with-spring下</p><h1 id="SpringBoot和Kafka的整合"><a href="#SpringBoot和Kafka的整合" class="headerlink" title="SpringBoot和Kafka的整合"></a><strong>SpringBoot和Kafka的整合</strong></h1><p>参见模块kafka-with-springboot下</p><p>测试方式，启动项目后，在浏览器的地址栏中：</p><p><a href="http://localhost:8080/kafka/send?key=要发送的消息的键&amp;value=要发送的消息的内容" target="_blank" rel="noopener">http://localhost:8080/kafka/send?key=要发送的消息的键&amp;value=要发送的消息的内容</a></p><p>和</p><p><a href="http://localhost:8080/kafka/sendAck?key=要发送的消息的键&amp;value=要发送的消息的内容" target="_blank" rel="noopener">http://localhost:8080/kafka/sendAck?key=要发送的消息的键&amp;value=要发送的消息的内容</a></p><h1 id="（削峰填谷）流量整形"><a href="#（削峰填谷）流量整形" class="headerlink" title="（削峰填谷）流量整形"></a><strong>（削峰填谷）流量整形</strong></h1><p>参见模块kafka-traffic-shaping下，启动kafka-traffic-shaping后，可以在kafka-traffic-shaping-client</p><p>中执行test目录下的两个测试类，观看使用了Mq前后的处理效果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第一个Kafka程序&quot;&gt;&lt;a href=&quot;#第一个Kafka程序&quot; class=&quot;headerlink&quot; title=&quot;第一个Kafka程序&quot;&gt;&lt;/a&gt;&lt;strong&gt;第一个Kafka程序&lt;/strong&gt;&lt;/h1&gt;&lt;h2 id=&quot;创建我们的主题&quot;&gt;&lt;a href
      
    
    </summary>
    
      <category term="消息中间件" scheme="https://ellenjack.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
      <category term="Kafka" scheme="https://ellenjack.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/"/>
    
    
      <category term="Kafka" scheme="https://ellenjack.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>手写SpringMVC笔记</title>
    <link href="https://ellenjack.github.io/2019/07/01/spring-10/"/>
    <id>https://ellenjack.github.io/2019/07/01/spring-10/</id>
    <published>2019-06-30T17:39:49.000Z</published>
    <updated>2020-03-25T16:12:24.801Z</updated>
    
    <content type="html"><![CDATA[<p>1,新建项目</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpl96v9qj30d50cjta8.jpg" alt="img">  <img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpla0465j30e50ciabb.jpg" alt="img"></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpl5r9dkj30da0c8gna.jpg" alt="img">  <img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jpl9ihcdj30fl09oacy.jpg" alt="img"></p><p>此时工程创建完毕.</p><p>2,新建注解及控制类,服务类及DispatcherServlet类(见源码)</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpl4tpeoj30al0fediw.jpg" alt="img"> </p><p>内容分别如下:</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpl4d9o9j30my06fmzv.jpg" alt="img"> </p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jplaysorj30lf0600ub.jpg" alt="img"> </p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jpl7p3r4j30um082goc.jpg" alt="img"> </p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpl33kvoj30pc069gnb.jpg" alt="img"> </p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpl3guuoj30oe060q4o.jpg" alt="img"> </p><p>声明注解到控制层(此时注解待解析)</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpl6bt96j30um0jkgse.jpg" alt="img"> </p><p>声明service服务类注解EnjoyServiceImpl</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpl8kpxbj30kd0fyjvq.jpg" alt="img"> </p><p>接口类如下</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpl5bjv3j30gy08nwgg.jpg" alt="img"> </p><p>创建一个新的DispatherServlet类,用来初始化bean和拦截请求</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpl84c1kj30he045dgn.jpg" alt="img"> </p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jplah0gyj30lc0fm7b1.jpg" alt="img"> </p><p>它的子方法请下载云盘里的源码跟进查看,每一行代码都写了注解.</p><p>3,将DispatcherServlet配置到web.xml(在项目启动时会加载这个DispatcherServlet的init方法)</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpl3wdfsj30uk0dmai5.jpg" alt="img"> </p><p>4,DispatcherServlet的doPost方法里对请求路径进行拦截,并根据路径到找对应要执行的方法</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpl78tszj30qx0db7ao.jpg" alt="img"> </p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jpl6r8l9j30eq07dmyo.jpg" alt="img"> </p><p>使用处理器解析后的参数放到args数组, 直接使用method.invoke(instance, args)完成请求调用;</p><p>内容较大,文字不好描述, 关于处理器这块,请看视频.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1,新建项目&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/006tNc79ly1g4jpl96v9qj30d50cjta8.jpg&quot; alt=&quot;img&quot;&gt;  &lt;img src=&quot;http://ww4.sinaimg.cn/lar
      
    
    </summary>
    
      <category term="框架" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="Spring" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/Spring/"/>
    
    
      <category term="Spring" scheme="https://ellenjack.github.io/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>Servlet3.0与SpringMvc那些事</title>
    <link href="https://ellenjack.github.io/2019/07/01/spring-9/"/>
    <id>https://ellenjack.github.io/2019/07/01/spring-9/</id>
    <published>2019-06-30T17:38:49.000Z</published>
    <updated>2020-03-25T16:12:24.804Z</updated>
    
    <content type="html"><![CDATA[<p>1，以前来写web的三大组件：以前写servlet filter listener都需要在web.xml进行注册，包括springmvc的前端控制器DispactherServlet也需要在web.xml注册，现在可以通过注解的方式快速搭建我们的web应用</p><p>2，servlet3.0需要tomcat7以上版本进行支持</p><p>3，创建动态web工程（Dynamic Web Project），看一看原生版的servlet：</p><p>   步骤如下</p><p>3.1创建工程：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jowb7l5xj30dd0jrn16.jpg" alt="img">   <img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jowfa9coj30dk0k1tad.jpg" alt="img"></p><p>  3.2新建jsp页面</p><p>   <img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jowfrtbzj30hp0l7mzq.jpg" alt="img"></p><p>  3.3打开页面，新增请求地址，请求地址为order</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jowgp0n6j30um0caq84.jpg" alt="img"> </p><p>3.4那么我们建立一个原生的servlet来处理 order的请求</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4joubc54fj30um07wadh.jpg" alt="img"> </p><p>加入tomcat，启动后测试访问地址，结果如下：</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jouieozxj30um04zt9e.jpg" alt="img"> </p><p>可以访问到路径地址。</p><p>当然这些注解不是我们讲的重点，原生的servlet开发还是很少的。</p><p>4，Shared libraries（共享库） and runtimes pluggability（运行时插件）的原理,在后面的框架整合里，用得比较多，来分析下它；</p><p><strong>ServletContainerInitializer初始化web容器：</strong></p><p>在web容器启动时为提供给第三方组件机会做一些初始化的工作，例如注册servlet或者filters等，servlet规范(JSR356)中通过ServletContainerInitializer实现此功能。</p><p>每个框架要使用ServletContainerInitializer就必须在对应的jar包的<strong>META-INF/services</strong> 目录创建一个名为javax.servlet.ServletContainerInitializer的文件，文件内容指定具体的ServletContainerInitializer实现类，那么，当web容器启动时就会运行这个初始化器做一些组件内的初始化工作。</p><p><strong>操作步骤：</strong></p><p>4.1创建META-INF/services目录</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jowhl8j1j30j309itbj.jpg" alt="img"> </p><p>4.2创建javax.servlet.ServletContainerInitializer文件</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jowi1jjqj30fr02n0t5.jpg" alt="img"> </p><p>4.3,新建JamesServletContainerInitializer实现ServletContainerInitializer接口</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jp06mvxlj30om0a9jvi.jpg" alt="img"></p><p>4.4编辑javax.servlet.ServletContainerInitializer文件内容</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jou92r6aj30nz02r3zk.jpg" alt="img"> </p><p>4.5一般伴随着ServletContainerInitializer一起使用的还有HandlesTypes注解，通过HandlesTypes可以将感兴趣的一些类注入到ServletContainerInitializer的onStartup方法作为参数传入。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jou40zfqj30ul0haqby.jpg" alt="img"> </p><p>并新建JamesService接口的所有子类型</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jp20k6krj30a601yaa2.jpg" alt="img"></p><p>JamesService接口：</p><p>分别新建JamesServiceOther,JamesServiceImpl,AbstractJamesService</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jouh2c50j30f901zwet.jpg" alt="img"> </p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jowddqrej30fx023aac.jpg" alt="img"> </p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jou3iyyzj30kv028t95.jpg" alt="img"> </p><p>4.6启动tomcat测试，看打印日志，不难发现，都拿到了，可以根据需要来反射创建对象</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4joujtmlgj30ll066gpd.jpg" alt="img"> </p><p>这其实就是基于运行时插件的机制，启动并运行这个ServletContainerInitializer，在整合springmvc的时候会用到</p><p>4.7使用ServletContext注册web组件（其实就是Servlet,Filter,Listener三大组件），</p><p>对于我们自己写的JamesServlet，我们可以使用@WebServlet注解来加入JamesServlet组件，</p><p>但若是我们要导入第三方阿里的连接池或filter，以前的web.xml方式就可通过配置加载就可以了，但现在我们使用ServletContext注入进来；</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jowiik05j30ul05mq5i.jpg" alt="img"> </p><p>操作步骤：新建以下三个组件</p><p>A，新建OrderFilter.java过滤器</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jou88pv1j30k20ca0vh.jpg" alt="img"> </p><p>B，新建OrderListener.java监听类</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jouf3m1xj30kj0f9wj5.jpg" alt="img"> </p><p>C，新建OrderServlet.java类</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4joucvlgsj30oa06c0uq.jpg" alt="img"> </p><p>D，使用ServletContext来注册以上三个组件</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jou9k6iij30um0dfdn3.jpg" alt="img"> </p><p>注意：在运行的过程中，是不可以注册组件， 和IOC道理一样，出于安全考虑</p><p>5，利用以上机制来整合springmvc;创建一个新的maven工程,springmvc注解版</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4joweiw9cj30el0dgta8.jpg" alt="img"> <img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jowcgnxsj30eo0dfmz2.jpg" alt="img"></p><p>5.1，建立完工程后，pom.xml会报错，老铁们，怎么办？？？不要慌，哈哈看下面吧</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jowbzomcj30my082n0v.jpg" alt="img"> </p><p>做个设置即可</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4joukpeufj30jj0btgpi.jpg" alt="img"> </p><p>再右键工程名，update更新一下maven配置就不会有错啦 啦 ……</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4joufkqyuj30lz07zac7.jpg" alt="img"> </p><p>5.2，加入必要的jar包依赖</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jowg89q1j30o909in0h.jpg" alt="img"> </p><p>5.3，导入依赖包后，查看maven的一个spring-web.jar包</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jou7rk3hj30k10kl0zr.jpg" alt="img"> </p><p>打开ServletContainerInitializer这个文件看看</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jouagvv4j30mj045tal.jpg" alt="img"> </p><p>5.4打开SpringServletContainerInitializer源码类</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jouay059j30uk0dk45m.jpg" alt="img"> </p><p>5.5打开WebApplicationInitializer源码看看组件及实现（ctrl+t）</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jouiv5m6j30ul05j0w7.jpg" alt="img"> </p><p>子类AbstractContextLoaderInitializer作用：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jowcyd0cj30pl0fy11g.jpg" alt="img"> </p><p>子类AbstractDispatcherServletInitializer的作用：从名字来看可知是DispatcherServlet初始化</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4joud8x1vj30ul0lutnb.jpg" alt="img"> </p><p>子类AbstractAnnotationConfigDispatcherServletInitializer：注解方式配置的dispatcherServlet初始化器</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4joucduzyj30uk0fpn5e.jpg" alt="img"> </p><p>root根容器与servlet容器的区别在哪呢？父子容器</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jowjgabkj30lu0jd0wh.jpg" alt="img"> </p><p>很明显，servlet的容器用来处理@Controller，视图解析，和web相关组件</p><p>而root根容器主要针对服务层，和数据源DAO层及事务控制相关处理（图源自spring官网）</p><p><a href="https://docs.spring.io/spring/docs/5.0.2.RELEASE/spring-framework-reference/web.html#mvc-servlet-context-hierarchy" target="_blank" rel="noopener">https://docs.spring.io/spring/docs/5.0.2.RELEASE/spring-framework-reference/web.html#mvc-servlet-context-hierarchy</a></p><p>后面我们根据这些来配置操作一下。</p><p>6，与springmvc的整合流程。</p><p>操作步骤：</p><p>新建JamesWebInitializer继承AbstractAnnotationConfigDispatcherServletInitializer类</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jowj5algj30ul0hptev.jpg" alt="img"> </p><p>新建两个配置类JamesRootConfig和JamesAppConfig，形成父子容器的效果</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jowh3eh6j30rt093adw.jpg" alt="img"> </p><p>再建JamesAppConfig类</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jou59z58j30um092djm.jpg" alt="img"> </p><p>再建OrderController控制类来测试</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jou79h5aj30oj0bhdjr.jpg" alt="img"> </p><p>再建OrderService服务层类</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4joug1n5jj30hl07rdhs.jpg" alt="img"> </p><p>OrderController来调用一下service组件</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4joua0d2zj30i908nwgp.jpg" alt="img"> </p><p>注意：JamesWebAppInitializer还需要指定配置类（配置文件）位置，修改以下返回</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4joulosimj30ul0gbjy1.jpg" alt="img"> </p><p>重启tomcat，进行测试：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jouk9pxqj30ul056gmr.jpg" alt="img"> </p><p>这就使用注解的方式（配置类）来完成配置springmvc的整合</p><p>7，如何定制与接管springmvc</p><p>以前是通过配置的方式来完成相应的处理</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jou5q71hj30uk0960wt.jpg" alt="img"> </p><p>现在使用配置注解，定制我们的springmvc,可看官网描述，加入@EnableWebMvc,来定制配置功能。</p><p>我们直接在JamesAppConfig实现WebMvcConfigurer</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jouhjovvj30um0k87dv.jpg" alt="img"> </p><p>点击进去WebMvcConfigurer， ctrl+t发现WebMvcConfigurerAdapter实现了WebMvcConfigurer接口，但方法都为空，我们只要继承一下这个类即可</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jougk068j30ul05kdih.jpg" alt="img"> </p><p>开始继承WebMvcConfigurerAdapter这个类（可以挑选部分方法进行重写）。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jou4ba7nj30um09xgpi.jpg" alt="img"> </p><p>我们得新建这些目录</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jowbfy4jj30hy06d0tj.jpg" alt="img"> </p><p>在pages下新建一个名为 ok.jsp的页面</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jou4t47gj30ee02egln.jpg" alt="img"> </p><p>页面内容如下：</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jou8likfj30ul080tby.jpg" alt="img"> </p><p>直接在OrderController控制类加一个解析器的定制页面返回</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jou66szoj30jp0dfq67.jpg" alt="img"> </p><p>重启tomcat，测试一下，结果为如下：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4joudua7zj30pq049my1.jpg" alt="img"> </p><p>静态资源如何配置访问呢？</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jouhxcjrj30uk0an42k.jpg" alt="img"> </p><p>xml配置文件有个<a href="mvc:default-servlet-handler/" target="_blank" rel="noopener">mvc:default-servlet-handler/</a>，效果一样。</p><p>比如新增一张图片和一个JSP页面</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4joubtdpkj30in0793za.jpg" alt="img"> </p><p>新增index.jsp修改一下：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4joweusjbj30lk0633za.jpg" alt="img"> </p><p>浏览器测试结果如下，能访问到页面</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jou6nv2tj30li06gaau.jpg" alt="img"> </p><p>接下来我们玩一个稍微复杂点的，拦截器？</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jowdw20nj30oi0egte2.jpg" alt="img"> </p><p>新建 JamesInterceptor拦截器，需实现HandlerInterceptor接口</p><p>之前在xml里有， <a href="mvc:interceptors" target="_blank" rel="noopener">mvc:interceptors</a>,效果是一样的。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4joue606tj30ul0cewj8.jpg" alt="img"> </p><p>把拦截器加到子容器配置类</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4joujb6f9j30pb0dd0xr.jpg" alt="img"> </p><p>重启tomcat进行测试，输入网些访问ok方法</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jouemjufj30k8045dgr.jpg" alt="img"> </p><p>同时eclipse打印内容如下，拦截成功。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4joul7iwkj30mr04u40i.jpg" alt="img"> </p><p>8，servlet3.0异步请求分析</p><p>8.1，什么是同步处理，请求发出后，等待服务端响应</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpe5k2ftj30h40f50ts.jpg" alt="img"> </p><p>8.2同步请求原理，从tomcat中获取连接线程进行处理，但tomcat的线程数有限，会造成线程资源的紧张。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jpe3k7t9j30jg0cqmym.jpg" alt="img"> </p><p>8.3同步机制操作步骤：</p><p>a,在servlet工程目录下，修改JamesServlet类，把当前处理的线程也打印出来</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpe41wg7j30uk0ckjvt.jpg" alt="img"> </p><p>重启tomcat，得到如下结果</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpe1no3pj30sf03w0ur.jpg" alt="img"> </p><p>从头到尾都是由同一个线程4进行处理的，同一线程处理</p><p>很明显，线程从头执行到尾，会造成资源占用不能释放</p><p>b,异步请求操作步骤：</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpe9po0hj30wt0lek0v.jpg" alt="img"> </p><p>从servlet3.0文档的9.6章节也可以看到，要声明的内容</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpe6cqs6j30qb05m0vu.jpg" alt="img"> </p><p>重启tomcat,查看运行结果如下，主线程与副线程分别为不同的线程，主线程从开始到结束不等待副线程就返回了：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jpe57b3bj30um055tco.jpg" alt="img"> </p><p>页面返回结果如下：等待3S后才返回，但线程资源其实早已释放</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpe5xo0jj30um04bdgl.jpg" alt="img"> </p><p>c,异步请求原理</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jpe09ogjj30um0ehadp.jpg" alt="img"> </p><p>当然怎么样定义servlet的异步处理线程池，不多讲，springmvc已集成了异步处理线程池</p><p>9，springmvc的异步请求</p><p>我们可以打官网</p><p><a href="https://docs.spring.io/spring/docs/5.0.2.RELEASE/spring-framework-reference/web.html#mvc-servlet-context-hierarchy" target="_blank" rel="noopener">https://docs.spring.io/spring/docs/5.0.2.RELEASE/spring-framework-reference/web.html#mvc-servlet-context-hierarchy</a></p><p>第1.7.1章节，讲述得很清晰</p><p>springmvc异步机制是基于servlet3来做的封装处理，通过这两种返回值都可以完成异步</p><p>官网例子如下：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpe36io1j30df05n3zd.jpg" alt="img">或<img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpe15fqcj30g005idh5.jpg" alt="img"></p><p>我们接下来实现一下：</p><p>操作步骤：</p><p>a,新建AsyncOrderController测试类 </p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpe8a3ttj30ul0e7ag9.jpg" alt="img"> </p><p>控制台打印结果如下：</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpean64dj30um03ctbi.jpg" alt="img"> </p><p>页面运行结果如下：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jpeb1t65j30um03zq3q.jpg" alt="img"> </p><p>Callable的原理是什么呢？还是一样，请打开官网哈…………第1.7.1章节</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpe0pzq0j30qe06paec.jpg" alt="img"> </p><p>思考：控制台打印结果为什么会两次进入拦截器preHandle呢？</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jpe98vzwj30um080tdc.jpg" alt="img"> </p><p>很明显可知：请求进入时拦截了一次，将Callable返回结果时，将请求重新派发给容器时又拦截了一次，所以进了两次拦截；</p><p>如何验证？只要在拦截器打印的地方加上getRequestURI()便知晓。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jpea6mv1j30ul050dil.jpg" alt="img"> </p><p>重启tomcat，并测试结果如下：分析见箭头的中文描述：</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpe6szs5j30ul0bndno.jpg" alt="img"> </p><p>10，springmvc异步请求及返回实战</p><p>以上只是原理，但在开发的过程并不是像Callable简单</p><p>比如现在我们有以下需求：</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpe7sb5tj30pf0bedi1.jpg" alt="img"> </p><p>需求描述：以创建订单为例，tomcat启动线程1来完成一个请求，但实际上是订单服务才能创建订单，那么tomcat线程应该把请求转发给订单服务，使用消息中间件来处理，订单服务把处理结果也放到消息中间件，由tomcat的线程N拿到结果后，响应给客户端。</p><p>我们打开官网第1.7.1章节</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jpe8r8q7j30um0arwjc.jpg" alt="img"> </p><p>操作步骤：</p><p>很明显我们不会用到MQ等消息中间件，写一个队列为模拟消息中间件</p><p>a,新建JamesDefferdQueue消息队列类</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpe2l2gzj30ul0augq3.jpg" alt="img"> </p><p>b,在AsyncOrderController新增两方法（其实就是两个线程，线程1和线程N）</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpe7b8jcj30um0f710h.jpg" alt="img"> </p><p>测试结果为：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jpe23o7tj30px02lq3m.jpg" alt="img"> </p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jpe00e6qj30pz03k3ze.jpg" alt="img"> </p><p>通过create (tomcat线程N处理的订单结果)，异步返回给createOrder(tomcat线程1),两结果一致，异步返回了结果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1，以前来写web的三大组件：以前写servlet filter listener都需要在web.xml进行注册，包括springmvc的前端控制器DispactherServlet也需要在web.xml注册，现在可以通过注解的方式快速搭建我们的web应用&lt;/p&gt;
&lt;p&gt;2
      
    
    </summary>
    
      <category term="框架" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="Spring" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/Spring/"/>
    
    
      <category term="Spring" scheme="https://ellenjack.github.io/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>BeanFactory的两个重要后置处理器</title>
    <link href="https://ellenjack.github.io/2019/07/01/spring-8/"/>
    <id>https://ellenjack.github.io/2019/07/01/spring-8/</id>
    <published>2019-06-30T17:37:49.000Z</published>
    <updated>2020-03-25T16:12:24.804Z</updated>
    
    <content type="html"><![CDATA[<p><strong>1，扩展原理－BeanFactoryPostProcessor</strong></p><p>BeanFactoryPostProcessor：beanFactory的后置处理器；</p><p>作用如下：          </p><p>a),在BeanFactory标准初始化之后调用，来定制和修改BeanFactory的内容；</p><pre><code>b),所有的bean定义已经保存加载到beanFactory，但是bean的实例还未创建</code></pre><p><strong>注意：</strong>之前也讲过BeanPostProcessor，它是bean后置处理器，bean创建对象初始化前后进行拦截工作的</p><p>操作步骤：</p><p>1〉新建ExtConfig.java配置类</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4joji8q0qj30hj06eta8.jpg" alt="img">    </p><p>新建JamesBeanFactoryPostProcessor.java处理器类（在com.enjoy.cap12.processor目录下）</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4joje8ighj30ns082dk2.jpg" alt="img"> </p><p>BeanFacotry是在bean组件创建之前还是之后生成的呢？写一个测试用例</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jp7puv6wj30o0034mxr.jpg" alt="img"></p><p>不难发现，在“Moon constructor”创建之前，当前9个bean已被加载到beanFactory中了。</p><p>测试结果结下：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jojgddncj30ul04in2p.jpg" alt="img"> </p><p> 那么以上BeanFactoryPostProcessor执行原理是怎么样的呢，打断点F5调试一下:</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jp49yos9j30n203274j.jpg" alt></p><p>跟踪debug栈,不难发现以下步骤如下：</p><p>  1)、ioc容器创建对象</p><p>  2)、invokeBeanFactoryPostProcessors(beanFactory);</p><pre><code>如何找到所有的BeanFactoryPostProcessor并执行他们的方法；    a）、直接在BeanFactory中找到所有类型是BeanFactoryPostProcessor的组件，并执行他们的方法</code></pre><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jp6g5srcj30o009bady.jpg" alt></p><p> *             b）、在初始化创建其他组件前面执行</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jojhcjy6j30uj0jgdom.jpg" alt="img"> </p><p>然后再点进去,</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jojhurobj30um05f0x6.jpg" alt="img"> </p><p><strong>2，扩展原理－</strong> <strong>BeanDefinitionRegistryPostProcessor</strong></p><p>postProcessBeanDefinitionRegistry();在所有bean定义信息将要被加载，bean实例还未创建的；</p><p>操作步骤：</p><p>新建JamesBeanDefinitionRegistryPostProcessor</p><p><strong>注意</strong>：可使用BeanDefinitionBuilder构建器来创建bean定义信息</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jojf1uvnj30y60c510s.jpg" alt="img"> </p><p>测试结果如下：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jojgv5bej30um07e10a.jpg" alt="img"> </p><p>源码分析：从refresh()–&gt;invokeBeanFactoryPostProcessors()–&gt;PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(), 跟进去即发现代码逻辑如下：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jojfhmvxj30ul0iadrv.jpg" alt="img"> </p><p>所以，在任何情况下都会优先执行BeanDefinitionRegistryPostProcessor的处理器，而BeanFactoryPostProcessor的处理器在它后面执行</p><p><strong>3，IOC容器处理流程（其实就是研究一下refresh()下的这些方法）</strong></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jojfznccj30o10omths.jpg" alt="img"> </p><p>Spring容器的refresh()【创建刷新】;</p><p>1、prepareRefresh()刷新前的预处理;</p><pre><code>1）、initPropertySources()初始化一些属性设置;子类自定义个性化的属性设置方法；2）、getEnvironment().validateRequiredProperties();检验属性的合法等3）、earlyApplicationEvents= new LinkedHashSet&lt;ApplicationEvent&gt;();保存容器中的一些早期的事件；</code></pre><p>2、obtainFreshBeanFactory();获取BeanFactory；</p><pre><code>1）、refreshBeanFactory();刷新【创建】BeanFactory；        110行：创建了一个this.beanFactory = new DefaultListableBeanFactory();        设置id；2）、getBeanFactory();返回刚才GenericApplicationContext创建的BeanFactory对象；3）、将创建的BeanFactory【DefaultListableBeanFactory】返回；</code></pre><p>3、prepareBeanFactory(beanFactory);BeanFactory的预准备工作（以上创建了beanFactory,现在对BeanFactory对象进行一些设置属性）；</p><pre><code>1）、设置BeanFactory的类加载器、支持表达式解析器...2）、添加部分BeanPostProcessor【ApplicationContextAwareProcessor】3）、设置忽略的自动装配的接口EnvironmentAware、EmbeddedValueResolverAware、xxx；4）、注册可以解析的自动装配；我们能直接在任何组件中自动注入：        BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext5）、添加BeanPostProcessor【ApplicationListenerDetector】6）、添加编译时的AspectJ；7）、给BeanFactory中注册一些能用的组件；    environment【ConfigurableEnvironment】、    systemProperties【Map&lt;String, Object&gt;】、    systemEnvironment【Map&lt;String, Object&gt;】</code></pre><p>/**</p><ul><li>扩展原理：</li><li>BeanPostProcessor：bean后置处理器，bean创建对象初始化前后进行拦截工作的</li><li></li><li>1、BeanFactoryPostProcessor：beanFactory的后置处理器；</li><li>在BeanFactory标准初始化之后调用，来定制和修改BeanFactory的内容；</li><li>所有的bean定义已经保存加载到beanFactory，但是bean的实例还未创建</li><li></li><li></li><li>BeanFactoryPostProcessor原理:</li><li>1)、ioc容器创建对象</li><li>2)、invokeBeanFactoryPostProcessors(beanFactory);</li><li>如何找到所有的BeanFactoryPostProcessor并执行他们的方法；</li><li>1）、直接在BeanFactory中找到所有类型是BeanFactoryPostProcessor的组件，并执行他们的方法</li><li>2）、在初始化创建其他组件前面执行</li><li></li></ul><ul><li>2、BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor</li><li>postProcessBeanDefinitionRegistry();</li><li>在所有bean定义信息将要被加载，bean实例还未创建的；</li><li></li><li>优先于BeanFactoryPostProcessor执行；</li><li>利用BeanDefinitionRegistryPostProcessor给容器中再额外添加一些组件；</li><li></li><li>原理：</li><li>1）、ioc创建对象</li><li>2）、refresh()-》invokeBeanFactoryPostProcessors(beanFactory);</li><li>3）、从容器中获取到所有的BeanDefinitionRegistryPostProcessor组件。</li><li>1、依次触发所有的postProcessBeanDefinitionRegistry()方法</li><li>2、再来触发postProcessBeanFactory()方法BeanFactoryPostProcessor； 为什么先执行postProcessBeanDefinitionRegistry()方法？两方法打断点，debug栈</li><li></li><li>4）、再来从容器中找到BeanFactoryPostProcessor组件；然后依次触发postProcessBeanFactory()方法<br>**/     </li></ul><p>＝＝＝＝＝IOC流程＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝<br>Spring容器的refresh()【创建刷新】;<br>1、prepareRefresh()刷新前的预处理;<br>    1）、initPropertySources()初始化一些属性设置;子类自定义个性化的属性设置方法；<br>    2）、getEnvironment().validateRequiredProperties();检验属性的合法等<br>    3）、earlyApplicationEvents= new LinkedHashSet<applicationevent>();保存容器中的一些早期的事件；<br>2、obtainFreshBeanFactory();获取BeanFactory；<br>    1）、refreshBeanFactory();刷新【创建】BeanFactory；<br>            110行：创建了一个this.beanFactory = new DefaultListableBeanFactory();<br>            设置id；<br>    2）、getBeanFactory();返回刚才GenericApplicationContext创建的BeanFactory对象；<br>    3）、将创建的BeanFactory【DefaultListableBeanFactory】返回；</applicationevent></p><p>3、prepareBeanFactory(beanFactory);BeanFactory的预准备工作（以上创建了beanFactory,现在对BeanFactory对象进行一些设置属性）；<br>    1）、设置BeanFactory的类加载器、支持表达式解析器…<br>    2）、添加部分BeanPostProcessor【ApplicationContextAwareProcessor】<br>    3）、设置忽略的自动装配的接口EnvironmentAware、EmbeddedValueResolverAware、xxx；<br>    4）、注册可以解析的自动装配；我们能直接在任何组件中自动注入：<br>            BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext<br>    5）、添加BeanPostProcessor【ApplicationListenerDetector】<br>    6）、添加编译时的AspectJ；<br>    7）、给BeanFactory中注册一些能用的组件；<br>        environment【ConfigurableEnvironment】、<br>        systemProperties【Map&lt;String, Object&gt;】、<br>        systemEnvironment【Map&lt;String, Object&gt;】<br>4、postProcessBeanFactory(beanFactory);BeanFactory准备工作完成后进行的后置处理工作；<br>    1）、子类通过重写这个方法来在BeanFactory创建并预准备完成以后做进一步的设置<br>======================以上是BeanFactory的创建及预准备工作==================================</p><p>5、invokeBeanFactoryPostProcessors(beanFactory);执行BeanFactoryPostProcessor的方法；<br>    BeanFactoryPostProcessor：BeanFactory的后置处理器。在BeanFactory标准初始化之后执行的；<br>    两个接口：BeanFactoryPostProcessor、BeanDefinitionRegistryPostProcessor<br>    1）、执行BeanFactoryPostProcessor的方法；<br>        先执行BeanDefinitionRegistryPostProcessor<br>        1）、83行：获取所有的BeanDefinitionRegistryPostProcessor；<br>        2）、86行：看先执行实现了PriorityOrdered优先级接口的BeanDefinitionRegistryPostProcessor、<br>            postProcessor.postProcessBeanDefinitionRegistry(registry)<br>        3）、99行：在执行实现了Ordered顺序接口的BeanDefinitionRegistryPostProcessor；<br>            postProcessor.postProcessBeanDefinitionRegistry(registry)<br>        4）、109行：最后执行没有实现任何优先级或者是顺序接口的BeanDefinitionRegistryPostProcessors；<br>            postProcessor.postProcessBeanDefinitionRegistry(registry)</p><pre><code>再执行BeanFactoryPostProcessor的方法1）、139行：获取所有的BeanFactoryPostProcessor2）、147行：看先执行实现了PriorityOrdered优先级接口的BeanFactoryPostProcessor、    postProcessor.postProcessBeanFactory()3）、167行：在执行实现了Ordered顺序接口的BeanFactoryPostProcessor；    postProcessor.postProcessBeanFactory()4）、175行：最后执行没有实现任何优先级或者是顺序接口的BeanFactoryPostProcessor；    postProcessor.postProcessBeanFactory()</code></pre><p>6、registerBeanPostProcessors(beanFactory);注册BeanPostProcessor（Bean的后置处理器）【 intercept bean creation】<br>        不同接口类型的BeanPostProcessor；在Bean创建前后的执行时机是不一样的<br>        BeanPostProcessor、<br>        DestructionAwareBeanPostProcessor、<br>        InstantiationAwareBeanPostProcessor、<br>        SmartInstantiationAwareBeanPostProcessor、<br>        MergedBeanDefinitionPostProcessor【internalPostProcessors】、</p><pre><code>1）、189行：获取所有的 BeanPostProcessor;后置处理器都默认可以通过PriorityOrdered、Ordered接口来执行优先级2）、204行：先注册PriorityOrdered优先级接口的BeanPostProcessor；    把每一个BeanPostProcessor；添加到BeanFactory中    beanFactory.addBeanPostProcessor(postProcessor);3）、224行：再注册Ordered接口的4）、236行：最后注册没有实现任何优先级接口的5）、最终注册MergedBeanDefinitionPostProcessor；6）、注册一个ApplicationListenerDetector；来在Bean创建完成后检查是否是ApplicationListener，如果是    applicationContext.addApplicationListener((ApplicationListener&lt;?&gt;) bean);</code></pre><p>7、initMessageSource();初始化MessageSource组件（做国际化功能；消息绑定，消息解析）；<br>        1）、718行：获取BeanFactory<br>        2）、719行：看容器中是否有id为messageSource的，类型是MessageSource的组件<br>            如果有赋值给messageSource，如果没有自己创建一个DelegatingMessageSource；<br>                MessageSource：取出国际化配置文件中的某个key的值；能按照区域信息获取；<br>        3）、739行：把创建好的MessageSource注册在容器中，以后获取国际化配置文件的值的时候，可以自动注入MessageSource；<br>            beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource);<br>            MessageSource.getMessage(String code, Object[] args, String defaultMessage, Locale locale);以后可通过getMessage获取</p><p>8、initApplicationEventMulticaster();初始化事件派发器；<br>        1）、753行：获取BeanFactory<br>        2）、754行：从BeanFactory中获取applicationEventMulticaster的ApplicationEventMulticaster；<br>        3）、762行：如果上一步没有配置；创建一个SimpleApplicationEventMulticaster<br>        4）、763行：将创建的ApplicationEventMulticaster添加到BeanFactory中，以后其他组件直接自动注入</p><p>9、onRefresh();留给子容器（子类）<br>        1、子类重写这个方法，在容器刷新的时候可以自定义逻辑；</p><p>10、registerListeners();给容器中将所有项目里面的ApplicationListener注册进来；<br>        1、822行：从容器中拿到所有的ApplicationListener<br>        2、824行：将每个监听器添加到事件派发器中；<br>            getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName);<br>        3、832行：派发之前步骤产生的事件；</p><p>11、finishBeanFactoryInitialization(beanFactory);初始化所有剩下的单实例bean；<br>    1、867行：beanFactory.preInstantiateSingletons();初始化后剩下的单实例bean，跟进<br>        1）、734行：获取容器中的所有Bean，依次进行初始化和创建对象<br>        2）、738行：获取Bean的定义信息；RootBeanDefinition<br>        3）、739行：Bean不是抽象的，是单实例的，是懒加载；<br>            1）、740行：判断是否是FactoryBean；是否是实现FactoryBean接口的Bean；<br>            2）、760行：不是工厂Bean。利用getBean(beanName);创建对象<br>                0、199行：getBean(beanName)； ioc.getBean();<br>                1、doGetBean(name, null, null, false);<br>                2、246行： getSingleton(beanName)先获取缓存中保存的单实例Bean《跟进去其实就是从MAP中拿》。如果能获取到说明这个Bean之前被创建过（所有创建过的单实例Bean都会被缓存起来）<br>                    从private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);获取的<br>                3、缓存中获取不到，开始Bean的创建对象流程；<br>                4、287行：标记当前bean已经被创建（防止多线程同时创建，使用synchronized）<br>                5、291行:获取Bean的定义信息；<br>                6、295行：getDependsOn()，bean.xml里创建person时，加depend-on=”jeep,moon”是先把jeep和moon创建出来<br>                         【获取当前Bean依赖的其他Bean;如果有按照getBean()把依赖的Bean先创建出来；】<br>                7、启动单实例Bean的创建流程；<br>                    1）、462行：createBean(beanName, mbd, args);<br>                    2）、490行：Object bean = resolveBeforeInstantiation(beanName, mbdToUse);让BeanPostProcessor先拦截返回代理对象；<br>                        【InstantiationAwareBeanPostProcessor】：提前执行；<br>                        先触发：postProcessBeforeInstantiation()；<br>                        如果有返回值：触发postProcessAfterInitialization()；<br>                    3）、如果前面的InstantiationAwareBeanPostProcessor没有返回代理对象；调用4）<br>                    4）、501行：Object beanInstance = doCreateBean(beanName, mbdToUse, args);创建Bean<br>                         1）、541行：【创建Bean实例】；createBeanInstance(beanName, mbd, args);<br>                             利用工厂方法或者对象的构造器创建出Bean实例；<br>                         2）、applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);<br>                             调用MergedBeanDefinitionPostProcessor的postProcessMergedBeanDefinition(mbd, beanType, beanName);<br>                         3）、578行：【Bean属性赋值】populateBean(beanName, mbd, instanceWrapper);<br>                             赋值之前：<br>                             1）、拿到InstantiationAwareBeanPostProcessor后置处理器；<br>                                 1305行：postProcessAfterInstantiation()；<br>                             2）、拿到InstantiationAwareBeanPostProcessor后置处理器；<br>                                 1348行：postProcessPropertyValues()；<br>                             =====赋值之前：===<br>                             3）、应用Bean属性的值；为属性利用setter方法等进行赋值；<br>                                 applyPropertyValues(beanName, mbd, bw, pvs);<br>                         4）、【Bean初始化】initializeBean(beanName, exposedObject, mbd);<br>                             1）、1693行：【执行Aware接口方法】invokeAwareMethods(beanName, bean);执行xxxAware接口的方法<br>                                 BeanNameAware\BeanClassLoaderAware\BeanFactoryAware<br>                             2）、1698行：【执行后置处理器初始化之前】applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);<br>                                 BeanPostProcessor.postProcessBeforeInitialization（）;<br>                             3）、1702行：【执行初始化方法】invokeInitMethods(beanName, wrappedBean, mbd);<br>                                 1）、是否是InitializingBean接口的实现；执行接口规定的初始化；<br>                                 2）、是否自定义初始化方法；<br>                             4）、1710行：【执行后置处理器初始化之后】applyBeanPostProcessorsAfterInitialization<br>                                 BeanPostProcessor.postProcessAfterInitialization()；</p><pre><code>            5）、将创建的Bean添加到缓存中singletonObjects；sharedInstance = getSingleton(beanName, ()跟进去                 254行：addSingleton（），放到MAP中        ioc容器就是这些Map；很多的Map里面保存了单实例Bean，环境信息。。。。；所有Bean都利用getBean创建完成以后；    检查所有的Bean是否是SmartInitializingSingleton接口的；如果是；就执行afterSingletonsInstantiated()；</code></pre><p>12、finishRefresh();完成BeanFactory的初始化创建工作；IOC容器就创建完成；<br>        1）、882行：initLifecycleProcessor();初始化和生命周期有关的后置处理器；LifecycleProcessor<br>            默认从容器中找是否有lifecycleProcessor的组件【LifecycleProcessor】；如果没有new DefaultLifecycleProcessor();<br>            加入到容器；</p><pre><code>        自己也可以尝试写一个LifecycleProcessor的实现类，可以在BeanFactory            void onRefresh();            void onClose();        2）、    885行：getLifecycleProcessor().onRefresh();        拿到前面定义的生命周期处理器（BeanFactory）；回调onRefresh()；    3）、888行：publishEvent(new ContextRefreshedEvent(this));发布容器刷新完成事件；    4）、891行：liveBeansView.registerApplicationContext(this);======总结===========1）、Spring容器在启动的时候，先会保存所有注册进来的Bean的定义信息；    1）、xml注册bean；&lt;bean&gt;    2）、注解注册Bean；@Service、@Component、@Bean、xxx2）、Spring容器会合适的时机创建这些Bean    1）、用到这个bean的时候；利用getBean创建bean；创建好以后保存在容器中；    2）、统一创建剩下所有的bean的时候；finishBeanFactoryInitialization()；3）、后置处理器；BeanPostProcessor    1）、每一个bean创建完成，都会使用各种后置处理器进行处理；来增强bean的功能；        AutowiredAnnotationBeanPostProcessor:处理自动注入        AnnotationAwareAspectJAutoProxyCreator:来做AOP功能；        xxx....        增强的功能注解：        AsyncAnnotationBeanPostProcessor        ....4）、事件驱动模型；    ApplicationListener；事件监听；    ApplicationEventMulticaster；事件派发：</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;1，扩展原理－BeanFactoryPostProcessor&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;BeanFactoryPostProcessor：beanFactory的后置处理器；&lt;/p&gt;
&lt;p&gt;作用如下：          &lt;/p&gt;
&lt;p&gt;a),在Bea
      
    
    </summary>
    
      <category term="框架" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="Spring" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/Spring/"/>
    
    
      <category term="Spring" scheme="https://ellenjack.github.io/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>声明式事务</title>
    <link href="https://ellenjack.github.io/2019/07/01/spring-7/"/>
    <id>https://ellenjack.github.io/2019/07/01/spring-7/</id>
    <published>2019-06-30T16:46:46.000Z</published>
    <updated>2020-03-25T16:12:24.803Z</updated>
    
    <content type="html"><![CDATA[<p>1， 环境搭建：导入数据源、数据库驱动、Spring-jdbc依赖</p><p>在pom.xml新增c3p0依赖包(c3p0封装了jdbc 对DataSource接口的实现)</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jo2ugjmnj30gz054q4c.jpg" alt="img"> </p><p>在pom.xml新增数据库驱动依赖包</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jo2vdysnj30ok05pq4r.jpg" alt="img"> </p><p>在pom.xml新增spring-jdbc依赖包（jdbcTemplate）</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jo2xr6tdj30ng058q4y.jpg" alt="img"> </p><p>2，新建Cap10MainConfig,将数据源和操作模板加载到IOC容器中</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jo2yr3w9j30um0iewn6.jpg" alt="img"> </p><p>3，新建Order测试表</p><p>CREATE TABLE <code>order</code> (<br>  <code>orderid</code> int(11) DEFAULT NULL,<br>  <code>ordertime</code> datetime DEFAULT NULL,<br>  <code>ordermoney</code> decimal(20,0) DEFAULT NULL,<br>  <code>orderstatus</code> char(1) DEFAULT NULL<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8</p><p>4，新建OrderDao操作数据库类</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jo2yc0s0j30ul078tb3.jpg" alt="img"> </p><p>5，新建 OrderService类，将orderDao注入进来</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jo2wb557j30j608vjt8.jpg" alt="img"> </p><p>6，将OrderService和OrderDao扫描进来，加载到容器</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jo2tq6wyj30kk03kdh3.jpg" alt="img"> </p><p>7，新建测试用例进入测试（<strong>测试结果：正常向数据库插入了一条记录</strong>）</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jo2vvie4j30um089wh8.jpg" alt="img"> </p><p>8，对OrderService引入异常，看是否还能插入数据库？</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jo2uyg6hj30pw0b3mzd.jpg" alt="img"> </p><p>测试结果：报异常， 但数据库正常插入。</p><p>9，可以给OrderService添加事务，若出现异常，看是否能全部回滚？</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jo2z5n5kj30gj09gwgc.jpg" alt="img"> </p><p>测试结果：事务不起作用， 照样可以成功插入</p><p>10，基于上以分析，其实我们之前在xml配置里， 会配置开启基于注解的事务管理功能</p><pre><code>@EnableTransactionalManagement开启基于注解的事务管理功能，和AOP一样Enablexx</code></pre><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jo2x9c43j30or05awgs.jpg" alt="img"> </p><p>再测试，测试结果为：出错啦…………IOC容器没有这个事务管理器bean。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jo2wsr8ej30ul05a77n.jpg" alt="img"> </p><p>11，将事务管理器的bean加载到容器中，修改配置类，新增以下注册</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jo2zqkh2j30um04utbd.jpg" alt="img"> </p><p>再测试，测试结果：<strong>正常回滚，没有报错</strong></p><p>12, @EnableTransactionManagement源码分析（与AOP的创建拦截流程一致）：</p><p> 1）、@EnableTransactionManagement</p><pre><code>利用TransactionManagementConfigurationSelector给容器中会导入组件导入两个组件AutoProxyRegistrarProxyTransactionManagementConfiguration</code></pre><p> 2）、AutoProxyRegistrar：</p><pre><code>给容器中注册一个 InfrastructureAdvisorAutoProxyCreator 组件；基本的动态代理创建器InfrastructureAdvisorAutoProxyCreator：？利用后置处理器机制在对象创建以后，包装对象，返回一个代理对象（增强器），代理对象执行方法利用拦截器链进行调用；</code></pre><p> 3）、ProxyTransactionManagementConfiguration 做了什么？</p><pre><code>1、给容器中注册事务增强器；    1）、事务增强器要用事务注解的信息，AnnotationTransactionAttributeSource解析事务注解    2）、事务拦截器：        TransactionInterceptor；保存了事务属性信息，事务管理器；        他是一个 MethodInterceptor；        在目标方法执行的时候；            执行拦截器链；            事务拦截器：                1）、先获取事务相关的属性                2）、再获取PlatformTransactionManager，如果事先没有添加指定任何transactionmanger                    最终会从容器中按照类型获取一个PlatformTransactionManager；                3）、执行目标方法                    如果异常，获取到事务管理器，利用事务管理回滚操作；                    如果正常，利用事务管理器，提交事务</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1， 环境搭建：导入数据源、数据库驱动、Spring-jdbc依赖&lt;/p&gt;
&lt;p&gt;在pom.xml新增c3p0依赖包(c3p0封装了jdbc 对DataSource接口的实现)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/006
      
    
    </summary>
    
      <category term="框架" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="Spring" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/Spring/"/>
    
    
      <category term="Spring" scheme="https://ellenjack.github.io/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>Spring的AOP底层源码分析</title>
    <link href="https://ellenjack.github.io/2019/06/30/spring-6/"/>
    <id>https://ellenjack.github.io/2019/06/30/spring-6/</id>
    <published>2019-06-30T03:22:17.000Z</published>
    <updated>2020-03-25T16:12:24.803Z</updated>
    
    <content type="html"><![CDATA[<p>使用JoinPoint可以拿到相关的内容, 比如方法名,  参数</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmudvzulj30v705fmxf.jpg" alt></p><p>那么方法正常返回, 怎么拿方法的返回值呢?</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmudrttkj30g802e0so.jpg" alt></p><p>那么如果是异常呢?定义</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmudoswfj30sm046q4c.jpg" alt></p><p><strong>小结:</strong> AOP看起来很麻烦, 只要3步就可以了:</p><p>  1,将业务逻辑组件和切面类都加入到容器中, 告诉spring哪个是切面类(@Aspect)</p><p>  2,在切面类上的每个通知方法上标注通知注解, 告诉Spring何时运行(写好切入点表达式,参照官方文档)</p><p>  3,开启基于注解的AOP模式  @EableXXXX</p><p><strong>九</strong> <strong>CAP27 AOP</strong> <strong>源码透析</strong></p><p> * AOP原理：【看给容器中注册了什么组件，这个组件什么时候工作，这个组件的功能是什么？】</p><p> *     <strong>@EnableAspectJAutoProxy</strong>；核心从这个入手,AOP整个功能要启作用,就是靠这个,加入它才有AOP</p><p>​       跟进<strong>@EnableAspectJAutoProxy</strong>源码:</p><p>//导入了此类,点进去看</p><p>@Import(AspectJAutoProxyRegistrar.<strong>class</strong>)</p><p><strong>public</strong> <strong>@interface</strong> EnableAspectJAutoProxy {</p><p>​    //proxyTargetClass属性，默认false，采用JDK动态代理织入增强(实现接口的方式)；如果设为true，则采用CGLIB动态代理织入增强</p><p>   <strong>boolean</strong> proxyTargetClass() <strong>default</strong> <strong>false</strong>;</p><p>​    //通过aop框架暴露该代理对象，aopContext能够访问</p><p>   <strong>boolean</strong> exposeProxy() <strong>default</strong> <strong>false</strong>;</p><p>}</p><p>它引入AspectJAutoProxyRegistrar, 并实现了ImportBeanDefinitionRegistrar接口</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jmuyhromj30ix01dwea.jpg" alt></p><p>ImportBeanDefinitionRegistrar接口作用: 能给容器中自定义注册组件, 以前也使用过, 比如我们以前也使用过这个类</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jmuydcrcj30p50410ss.jpg" alt></p><p>在<strong>AspectJAutoProxyRegistrar</strong>里可以自定义注册一些bean</p><p>那么注册了什么bean呢? 以debug模式进行测试一下</p><p>给<strong>AspectJAutoProxyRegistrar</strong> <strong>类</strong>的<strong>registerBeanDefinitions</strong>()方法打上断点.</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmuy9lpsj30hp0dzdgw.jpg" alt></p><p>看注册bean的如何处理?</p><p>AopConfigUtils.<em>registerAspectJAnnotationAutoProxyCreatorIfNecessary</em>(registry);</p><p>注册一个这个组件, 如果有需要的话….</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmvhkrv8j30rk0dywfg.jpg" alt></p><p>点进去看看</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmvh6ck7j30n206d3yq.jpg" alt></p><p>想注册一个AnnotationAwareAspectJAutoProxyCreator的组件, 如果registry已经有了的话,就执行以下操作;</p><p>但是我们的注册中还没有, 第一次, 所以来创建一个cls, 用registry把bean的定义做好, bean的名叫做internalAutoProxyCreator</p><p>其实就是利用<strong>@EnableAspectJAutoProxy</strong> <strong>中的AspectJAutoProxyRegistrar</strong> <strong>给我们容器中注册一个</strong>AnnotationAwareAspectJAutoProxyCreator组件;</p><p>翻译过来其实就叫做 ”注解装配模式的ASPECT切面自动代理创建器”组件</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmvh09tzj30m20dnt9p.jpg" alt></p><p>判断if(registry.containsBeanDefinition(<em>ATUO_PROXY_CREATOR_BEAN_NAME</em>))</p><p>{</p><p>​    如果容器中bean已经有了 internalAutoProxyCreator, 执行内部内容</p><p>}</p><p>else</p><p>创建AnnotationAwareAspectJAutoProxyCreator信息; 把此bean注册在registry中.</p><p>做完后, 相当于</p><p>其实就是 <em>ATUO_PROXY_CREATOR_BEAN_NAME**值为</em>internalAutoProxyCreator,给容器中注册internalAutoProxyCreator组件, 该组件类型为AnnotationAwareAspectJAutoProxyCreator.class</p><p>可以打开之前讲过的Cap6Test, 用到了registry…</p><p>因此我们要重点研究AnnotationAwareAspectJAutoProxyCreator组件(ASPECT自动代理创建器), 研究这个透了, 整个原理也就明白了, 所有的原理就是看容 器注册了什么组件, 这个组件什么时候工作, 及工作时候的功能是什么?  只要把这几个研究清楚了,原理就都清楚了.</p><p>AnnotationAwareAspectJAutoProxyCreator神奇的组件分析:</p><p>类关系图如下,继承关系:</p><p>  AnnotationAwareAspectJAutoProxyCreator：</p><p> *  AnnotationAwareAspectJAutoProxyCreator</p><p> *     -&gt;AspectJAwareAdvisorAutoProxyCreator</p><p> *         -&gt;AbstractAdvisorAutoProxyCreator</p><p> *            -&gt;AbstractAutoProxyCreator</p><p> *              implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware</p><p> *                       关注后置处理器（在bean初始化完成前后做事情）、自动装配BeanFactory</p><p>SmartInstantiationAwareBeanPostProcessor: bean的后置处理器</p><p>BeanFactoryAware 能把beanFacotry bean工厂传进来 </p><p>通过分析以上的bean继承关系我们发现,   具有BeanPostProcessor特点, 也有Aware接口的特点, 实现了BeanFactoryAware 接口</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmwiypegj30wc0f3aas.jpg" alt></p><p>那我们来分析做为beanPostProcessor后置处理器做了哪些工作, 做为BeanFactoryAware又做了哪些工作</p><p><strong>一</strong> <strong>,</strong> <strong>分析</strong> <strong>创建和注册AnnotationAwareAspectJAutoProxyCreator的</strong> <strong>流程</strong> <strong>:</strong></p><p>1）、register()传入配置类，准备创建ioc容器</p><p>2）、注册配置类，调用refresh（）刷新创建容器；</p><p>3）、registerBeanPostProcessors(beanFactory);注册bean的后置处理器来方便拦截bean的创建(主要是分析创建AnnotationAwareAspectJAutoProxyCreator)；</p><p>​    1）、 先获取ioc容器已经定义了的需要创建对象的所有BeanPostProcessor</p><p>​    2）、给容器中加别的BeanPostProcessor</p><p>​    3）、优先注册实现了PriorityOrdered接口的BeanPostProcessor；</p><p>​    4）、再给容器中注册实现了Ordered接口的BeanPostProcessor；</p><p>​    5）、注册没实现优先级接口的BeanPostProcessor；</p><p>​    6）、注册BeanPostProcessor，实际上就是创建BeanPostProcessor对象，保存在容器中；</p><p>​       创建internalAutoProxyCreator的BeanPostProcessor【其实就是AnnotationAwareAspectJAutoProxyCreator】</p><p>​       1）、创建Bean的实例</p><p>​       2）、populateBean；给bean的各种属性赋值</p><p>​       3）、initializeBean：初始化bean；</p><p>​              1）、invokeAwareMethods()：处理Aware接口的方法回调</p><p>​              2）、applyBeanPostProcessorsBeforeInitialization()：应用后置处理器的postProcessBeforeInitialization（）</p><p>​              3）、invokeInitMethods()；执行自定义的初始化方法</p><p>​              4）、applyBeanPostProcessorsAfterInitialization()；执行后置处理器的postProcessAfterInitialization（）；</p><p>​       4）、BeanPostProcessor(AnnotationAwareAspectJAutoProxyCreator)创建成功；–》aspectJAdvisorsBuilder</p><p>​    7）、把BeanPostProcessor注册到BeanFactory中；</p><p>​       beanFactory.addBeanPostProcessor(postProcessor);</p><p>注意:以上是创建和注册AnnotationAwareAspectJAutoProxyCreator的过程</p><p>​           AnnotationAwareAspectJAutoProxyCreator =&gt; InstantiationAwareBeanPostProcessor</p><p><strong>二</strong> <strong>,</strong> <strong>如何创建增强的</strong> <strong>Caculator</strong> <strong>增强</strong> <strong>bean</strong> <strong>的</strong> <strong>流程</strong> <strong>:</strong></p><p>  1,refresh—&gt;finishBeanFactoryInitialization(beanFactory);完成BeanFactory初始化工作；创建剩下的单实例bean</p><p>​       1）、遍历获取容器中所有的Bean，依次创建对象getBean(beanName);</p><p>​              getBean-&gt;doGetBean()-&gt;getSingleton()-&gt;</p><p>​       2）、创建bean</p><p>​              【AnnotationAwareAspectJAutoProxyCreator在所有bean创建之前会有一个拦截，InstantiationAwareBeanPostProcessor，会调用postProcessBeforeInstantiation()】</p><p>​              2.1）、先从缓存中获取当前bean，如果能获取到，说明bean是之前被创建过的，直接使用，否则再创建；</p><p>​                  只要创建好的Bean都会被缓存起来</p><p>​              2.2）、createBean（）;创建bean；</p><p>​                  AnnotationAwareAspectJAutoProxyCreator 会在任何bean创建之前先尝试返回bean的实例</p><p>​                  【BeanPostProcessor是在Bean对象创建完成初始化前后调用的】</p><p>​                  【InstantiationAwareBeanPostProcessor是在创建Bean实例之前先尝试用后置处理器返回对象的】</p><p>​                  2.2.1）、resolveBeforeInstantiation(beanName, mbdToUse);解析BeforeInstantiation,如果能返回代理对象就使用，如果不能就继续,后置处理器先尝试返回对象；</p><p>​           bean = applyBeanPostProcessorsBeforeInstantiation（）：</p><p>​           拿到所有后置处理器，如果是InstantiationAwareBeanPostProcessor;</p><p>​           就执行postProcessBeforeInstantiation</p><p>​           if (bean != null) {</p><p>​                  bean = applyBeanPostProcessorsAfterInitialization(bean, beanName);</p><p>​           }</p><p>​                  2.2.2）、doCreateBean(beanName, mbdToUse, args);真正的去创建一个bean实例；和单实例bean创建流程一样；</p><p>​       </p><p>​                      </p><p>  <strong>三</strong> <strong>,</strong> <strong>【</strong> <strong>AnnotationAwareAspectJAutoProxyCreator</strong> <strong>】作用</strong> <strong>:</strong></p><p>​    <strong>InstantiationAwareBeanPostProcessor</strong></p><p>  ：</p><p>  1）、每一个bean创建之前，调用postProcessBeforeInstantiation()；</p><p>​       关心MathCalculator和LogAspect的创建</p><p>​       1）、判断当前bean是否在advisedBeans中（保存了所有需要增强bean）</p><p>​       2）、判断当前bean是否是基础类型的Advice、Pointcut、Advisor、AopInfrastructureBean，</p><p>​           或者是否是切面（@Aspect）</p><p>​       3）、是否需要跳过</p><p>​           1）、获取候选的增强器（切面里面的通知方法）【List<advisor> candidateAdvisors】</advisor></p><p>​              每一个封装的通知方法的增强器是 InstantiationModelAwarePointcutAdvisor；</p><p>​              判断每一个增强器是否是 AspectJPointcutAdvisor 类型的；返回true</p><p>​           2）、永远返回false</p><p>  2）、创建对象</p><p>  postProcessAfterInitialization；</p><p>​       return wrapIfNecessary(bean, beanName, cacheKey);//包装如果需要的情况下</p><p>​       1）、获取当前bean的所有增强器（通知方法）  Object[]  specificInterceptors</p><p>​           1、找到候选的所有的增强器（找哪些通知方法是需要切入当前bean方法的）</p><p>​           2、获取到能在bean使用的增强器。</p><p>​           3、给增强器排序</p><p>​       2）、保存当前bean在advisedBeans中；</p><p>​       3）、如果当前bean需要增强，创建当前bean的代理对象；</p><p>​           1）、获取所有增强器（通知方法）</p><p>​           2）、保存到proxyFactory</p><p>​           3）、创建代理对象：Spring自动决定</p><p>​              JdkDynamicAopProxy(config);jdk动态代理；</p><p>​              ObjenesisCglibAopProxy(config);cglib的动态代理；</p><p>​       4）、给容器中返回当前组件使用cglib增强了的代理对象；</p><p>​       5）、以后容器中获取到的就是这个组件的代理对象，执行目标方法的时候，代理对象就会执行通知方法的流程；</p><p><strong>四，</strong> <strong>目标方法执行</strong> <strong>（</strong> <strong>caculator.div()</strong> <strong>方法执行切面拦截</strong> <strong>）</strong>；</p><p>​       容器中保存了组件的代理对象（cglib增强后的对象），这个对象里面保存了详细信息（比如增强器，目标对象，xxx）；</p><p>​       1）、CglibAopProxy.intercept();拦截目标方法的执行</p><p>​       2）、根据ProxyFactory对象获取将要执行的目标方法拦截器链；</p><p>​           List<object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);</object></p><p>​           1）、List<object> interceptorList保存所有拦截器 5</object></p><p>​              一个默认的ExposeInvocationInterceptor 和 4个增强器；</p><p>​           2）、遍历所有的增强器，将其转为Interceptor；</p><p>​              registry.getInterceptors(advisor);</p><p>​           3）、将增强器转为List<methodinterceptor>；</methodinterceptor></p><p>​              如果是MethodInterceptor，直接加入到集合中</p><p>​              如果不是，使用AdvisorAdapter将增强器转为MethodInterceptor；</p><p>​              转换完成返回MethodInterceptor数组；</p><p>​       3）、如果没有拦截器链，直接执行目标方法;</p><p>​           拦截器链（每一个通知方法又被包装为方法拦截器，利用MethodInterceptor机制）</p><p>​       4）、如果有拦截器链，把需要执行的目标对象，目标方法，</p><p>​           拦截器链等信息传入创建一个 CglibMethodInvocation 对象，</p><p>​           并调用 Object retVal =  mi.proceed();</p><p>​       5）、拦截器链的触发过程;</p><p>​           1)、如果没有拦截器执行执行目标方法，或者拦截器的索引和拦截器数组-1大小一样（指定到了最后一个拦截器）执行目标方法；</p><p>​           2)、链式获取每一个拦截器，拦截器执行invoke方法，每一个拦截器等待下一个拦截器执行完成返回以后再来执行；</p><p>​              拦截器链的机制，保证通知方法与目标方法的执行顺序；</p><p>​       </p><p>​    总结：</p><p>​       1）、  @EnableAspectJAutoProxy 开启AOP功能</p><p>​       2）、 @EnableAspectJAutoProxy 会给容器中注册一个组件 AnnotationAwareAspectJAutoProxyCreator</p><p>​       3）、AnnotationAwareAspectJAutoProxyCreator是一个后置处理器；</p><p>​       4）、容器的创建流程：</p><p>​           1）、registerBeanPostProcessors（）注册后置处理器；创建AnnotationAwareAspectJAutoProxyCreator对象</p><p>​           2）、finishBeanFactoryInitialization（）初始化剩下的单实例bean</p><p>​              1）、创建业务逻辑组件和切面组件</p><p>​              2）、AnnotationAwareAspectJAutoProxyCreator拦截组件的创建过程</p><p>​              3）、组件创建完之后，判断组件是否需要增强</p><p>​                  是：切面的通知方法，包装成增强器（Advisor）;给业务逻辑组件创建一个代理对象（cglib）；</p><p>​       5）、执行目标方法：</p><p>​           1）、代理对象执行目标方法</p><p>​           2）、CglibAopProxy.intercept()；</p><p>​              1）、得到目标方法的拦截器链（增强器包装成拦截器MethodInterceptor）</p><p>​              2）、利用拦截器的链式机制，依次进入每一个拦截器进行执行；</p><p>​              3）、效果：</p><p>​                  正常执行：前置通知-》目标方法-》后置通知-》返回通知</p><p>​                  出现异常：前置通知-》目标方法-》后置通知-》异常通知</p><p>拦截流程图如下：</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jmwivm0xj30qg0eejv3.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用JoinPoint可以拿到相关的内容, 比如方法名,  参数&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006tNc79ly1g4jmudvzulj30v705fmxf.jpg&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;那么方法正常返回,
      
    
    </summary>
    
      <category term="框架" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="Spring" scheme="https://ellenjack.github.io/categories/%E6%A1%86%E6%9E%B6/Spring/"/>
    
    
      <category term="Spring" scheme="https://ellenjack.github.io/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>docker实战</title>
    <link href="https://ellenjack.github.io/2019/06/25/docker-3/"/>
    <id>https://ellenjack.github.io/2019/06/25/docker-3/</id>
    <published>2019-06-25T09:44:47.000Z</published>
    <updated>2020-03-25T16:12:24.794Z</updated>
    
    <content type="html"><![CDATA[<h3 id="nginx镜像制作实战"><a href="#nginx镜像制作实战" class="headerlink" title="nginx镜像制作实战"></a><strong>nginx镜像制作实战</strong></h3><h4 id="docker容器的主业"><a href="#docker容器的主业" class="headerlink" title="docker容器的主业"></a><strong>docker容器的主业</strong></h4><p>docker理念里，容器启动时，应当为它指定主业是什么，如nginx容器主业就是nginx代理服务，tomcat容器就是web服务等等</p><p>1、容器创建时，必须指定主业任务，如不指定，则容器无事可干立即退出。</p><p>2、在dockerfile打包镜像时，可以使用cmd命令来指定一个默认的主业，如下：</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jmnpxyiqj30fe02ydgd.jpg" alt></p><p>3、既然镜像里是默认主业，即意味着创建容器时，可以覆盖此默认命令，如下</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmnptnolj30fe01r753.jpg" alt></p><h4 id="推荐的-ENTRYPOINT方式"><a href="#推荐的-ENTRYPOINT方式" class="headerlink" title="推荐的 ENTRYPOINT方式"></a><strong>推荐的</strong> <strong>ENTRYPOINT方式</strong></h4><p>1、镜像本身应该有稳定的主业，应当指定后即不能更改用途，于是引入ENTRYPOINT</p><p>2、使用ENTRYPOINT字义即容器入口，它不能被run中cmd覆盖，如下例：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmnpo31sj30fe02ojs3.jpg" alt></p><p>执行：docker build -t nginxx:v3 .</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jmo2h987j30fe01n3z6.jpg" alt></p><p>以后使用nginxx:v3这个镜像时，只能做nginx服务来使用啦</p><h4 id="手动打包springboot镜像"><a href="#手动打包springboot镜像" class="headerlink" title="手动打包springboot镜像"></a><strong>手动打包springboot镜像</strong></h4><p>我们需要对业务项目打包发布，一样需要制作成为业务镜像，供运维使用，下面讲述springboot的制作过程：</p><p>1、将springboot打好的jar包上传</p><p>2、在同级目录下，创建Dockerfile文件，内容如下：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmo2c2foj30fe02pq3x.jpg" alt></p><p>3、dockerfile打包业务镜像</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmo27pqpj30fe07udj3.jpg" alt></p><p>4、启动镜像，即得到业务运行</p><p>docker run -d -p 8090:8090  –name member member:v1</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmoff2vej30fe01a74p.jpg" alt></p><p>5、浏览器打开页面校验：<a href="http://192.168.244.7:8090/" target="_blank" rel="noopener">http://192.168.244.7:8090/</a></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmofcfmrj30fe046aat.jpg" alt></p><h4 id="maven源码打包用法"><a href="#maven源码打包用法" class="headerlink" title="maven源码打包用法"></a><strong>maven源码打包用法</strong></h4><p>更多的情况，我们是直接在运维环境里，上传源码，直接maven打包jar，然后再进一步打包成镜像，与手动打包过程类似</p><p>如果环境中没有安装maven，请手动安装，脚本如下：</p><p>sudo yum install -y yum-utils device-mapper-persistent-data lvm2</p><p># yum-config-manager –add-repo <a href="http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo" target="_blank" rel="noopener">http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo</a></p><p># yum-config-manager –enable epel-apache-maven</p><p>// 安装maven</p><p># yum install -y apache-maven</p><p>1、上传原码到docker环境中（一般是git/svn直接拉取源码）</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmof8uerj30fe02w75j.jpg" alt></p><p>2、maven打包</p><p>mvn clean package</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmot22j5j30fe04qjt8.jpg" alt></p><p>生成的jar在同级target目录下</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmosxy4oj30fe052ac9.jpg" alt></p><p>3、执行docker命令生成镜像</p><p>dockerfile文件内容</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jmosq36dj30fe01tt94.jpg" alt></p><p>命令创建镜像</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmp5rf9rj30b203tjsk.jpg" alt></p><h4 id="maven插件打包"><a href="#maven插件打包" class="headerlink" title="maven插件打包"></a><strong>maven插件打包</strong></h4><p>前面打springboot包的方式，需要手动上传项目jar或者源码到服务器（违和感很强），这对于开发人员日常发布开发环境项目，极为不便</p><p>下面，演示一个maven插件：docker-maven-plugin用法，来打通环境。</p><h5 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h5><p>1、需要我们windows上安装docker服务</p><p>2、需要docker服务配置http仓库接口，windows上docker服务配置如下（传统配置模式无权限修改文件）</p><h5 id="本地环境配置"><a href="#本地环境配置" class="headerlink" title="本地环境配置"></a>本地环境配置</h5><p>1、windows上<strong>安装docker-toolbox，傻瓜安装即可。</strong></p><p><strong>2、</strong>打开Docker Quickstart Terminal终端，等待初始始化完成后。</p><p>3、输入docker-machine env命令，返回docker服务的api接口和证书位置，如下：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmp5jh7fj30fd0380u1.jpg" alt></p><p>4、输入docker-machine ssh命令，进入sh环境中，配置http仓库路径</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmp5frkgj30fe05b75k.jpg" alt></p><p>修改文件配置（当前用户是docker不是root，要sudo提升至root）：</p><p>sudo vi /var/lib/boot2docker/profile</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmpl46apj30be05jjsi.jpg" alt></p><p>5、修改完成，保存。重启docker服务</p><p>sudo /etc/init.d/docker restart</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmpl177jj30e001o3yn.jpg" alt></p><h5 id="项目环境配置maven插件"><a href="#项目环境配置maven插件" class="headerlink" title="项目环境配置maven插件"></a>项目环境配置maven插件</h5><p>在我们的工程pom中加入docker-maven-plugin插件的配置，如下</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmpkyhjzj30cr07s76e.jpg" alt> </p><p>1、其中，imageName配置镜像的全路径名，即指定私库的名称</p><p>2、dockerHost和dockerCertPath对应配置上一步中docker的api和证书值</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmpzcgrfj30fd0380u1.jpg" alt></p><h5 id="打包运行"><a href="#打包运行" class="headerlink" title="打包运行"></a>打包运行</h5><p>以idea为例，整个项目装配完成，只需要操作maven的一二三步骤，即直接镜像进入仓库，整个过程毫无违和感</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmpz860uj30fe06fjso.jpg" alt> </p><p>若使用的不是idea工具，可直接使用maven命令，一句完成打包，如下：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmpz23t0j30fe058t9t.jpg" alt></p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmqg96iwj30fe09lmz4.jpg" alt></p><h5 id="校验镜像仓库结果"><a href="#校验镜像仓库结果" class="headerlink" title="校验镜像仓库结果"></a>校验镜像仓库结果</h5><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jmqf5inzj30fe0500tj.jpg" alt></p><p>至此，我们的服务器环境，已经可以直接运行docker run 镜像得到结果了</p><h1 id="Docker-Compose使用"><a href="#Docker-Compose使用" class="headerlink" title="Docker-Compose使用"></a><strong>Docker-Compose使用</strong></h1><p>当项目涉及容器较多时，需要一个管理容器的工具</p><h2 id="docker-compose安装"><a href="#docker-compose安装" class="headerlink" title="docker-compose安装"></a><strong>docker-compose安装</strong></h2><h3 id="curl方式安装"><a href="#curl方式安装" class="headerlink" title="curl方式安装"></a><strong>curl方式安装</strong></h3><p>sudo curl -L <a href="https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname" target="_blank" rel="noopener">https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname</a> -s<code>-</code>uname -m` &gt; /usr/local/bin/docker-compose        </p><h3 id="增加可执行权限"><a href="#增加可执行权限" class="headerlink" title="增加可执行权限"></a><strong>增加可执行权限</strong></h3><p>sudo chmod +x /usr/local/bin/docker-compose</p><h3 id="查看版本"><a href="#查看版本" class="headerlink" title="查看版本"></a><strong>查看版本</strong></h3><p>docker-compose version</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmqf1wxnj30e202qjse.jpg" alt></p><h2 id="docker-compose-yaml命令"><a href="#docker-compose-yaml命令" class="headerlink" title="docker-compose.yaml命令"></a><strong>docker-compose.yaml命令</strong></h2><p>docker-compose的命令与docker命令极为相似，用法上没有区别，下面列出它特有的几种命令： </p><p>up 创建并启动容器：docker-compose up -d –scale 服务名=数字 </p><p>​            ———- d表示后台运行，scale是表示对应的服务同时启动几个容器</p><p>down 停止并删除容器： docker-compose down</p><p>​            ———- 会停掉容器，并删除掉容器。如果不希望删除容器，请使用stop</p><h2 id="docker-compose实战"><a href="#docker-compose实战" class="headerlink" title="docker-compose实战"></a><strong>docker-compose实战</strong></h2><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jmsb8gcgj30fe0bmjtg.jpg" alt></p><p>编写一个项目整体服务，一个网关nginx + springboot的集群，如上图</p><p>其中nginx服务，将配置文件挂载在主机当前项目目录的路径下：nginx/conf.d/</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmsb64igj30fe07ytb4.jpg" alt></p><p>命令：docker-compose up -d</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmsb3olyj30fe03kjsw.jpg" alt></p><p>docker-compose up -d –scale member-1=2</p><p>把member-1服务启动两个容器</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmsncxdkj30fe04dwgc.jpg" alt></p><h1 id="Docker网络路由"><a href="#Docker网络路由" class="headerlink" title="Docker网络路由"></a><strong>Docker网络路由</strong></h1><h2 id="docker的跨主机网络路由"><a href="#docker的跨主机网络路由" class="headerlink" title="docker的跨主机网络路由"></a><strong>docker的跨主机网络路由</strong></h2><p>假设我们现在有两台docker主机，各启动了自己的容器在运行</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmsn8k8pj30fe06iab2.jpg" alt></p><h3 id="问题由来"><a href="#问题由来" class="headerlink" title="问题由来"></a><strong>问题由来</strong></h3><p>1、在网桥模式下，同一个主机下的容器，使用同一个网桥docker0，它们组成一个局域网，如上图主机1的172.17.6.0网段下的三个容器</p><p>2、同一个主机下的容器，相互之间网络是通的</p><p>3、但不同主机下，是不同的局域网，它们之间网络不能互通。如：172.17.6.2的容器，想要访问172.17.8.2的容器</p><h3 id="方案"><a href="#方案" class="headerlink" title="方案"></a><strong>方案</strong></h3><p>a机192.168.244.7，容器网段172.17.6.1/16，a机起了容器ip是172.17.6.2</p><p>b机192.168.244.8，容器网段172.17.8.1/16，b机起了容器ip是172.17.8.2</p><h4 id="两台机分别配置路由表"><a href="#两台机分别配置路由表" class="headerlink" title="两台机分别配置路由表"></a><strong>两台机分别配置路由表</strong></h4><p>a机，route add -net 172.17.8.0 netmask 255.255.255.0  gw 192.168.244.8</p><p>b机，route add -net 172.17.6.0 netmask 255.255.255.0  gw 192.168.244.7</p><p>添加好后，路由表类似下图</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmsn5no9j30fe03dabj.jpg" alt></p><p>然后a机ping b机容器，发现仍是ping不通，卡住ping不通，就是数据包被drop掉了</p><h4 id="ip-forward配置"><a href="#ip-forward配置" class="headerlink" title="ip_forward配置"></a><strong>ip_forward配置</strong></h4><p>我们在b机上使用以下命令查看网络包转发情况，发现有掉包</p><p>iptables -t filter -nvL FORWARD</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jmsyrbwrj30fe037myu.jpg" alt></p><p>我们需要b机上配置，寻找172.17段ip的网络包不要丢掉，要转发</p><p>a机：    iptables -I DOCKER  –dst 172.17.0.0/16 -j ACCEPT</p><p>b机：    iptables -I DOCKER  –dst 172.17.0.0/16 -j ACCEPT</p><p>网络ok，整个网络包的流程，完整如下：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmsylf74j30fe061dgz.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;nginx镜像制作实战&quot;&gt;&lt;a href=&quot;#nginx镜像制作实战&quot; class=&quot;headerlink&quot; title=&quot;nginx镜像制作实战&quot;&gt;&lt;/a&gt;&lt;strong&gt;nginx镜像制作实战&lt;/strong&gt;&lt;/h3&gt;&lt;h4 id=&quot;docker容器的主业&quot;
      
    
    </summary>
    
      <category term="工具" scheme="https://ellenjack.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="docker" scheme="https://ellenjack.github.io/categories/%E5%B7%A5%E5%85%B7/docker/"/>
    
    
      <category term="docker" scheme="https://ellenjack.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Java8新增的并发</title>
    <link href="https://ellenjack.github.io/2019/06/20/thread-8/"/>
    <id>https://ellenjack.github.io/2019/06/20/thread-8/</id>
    <published>2019-06-20T15:21:00.000Z</published>
    <updated>2020-03-29T11:28:31.519Z</updated>
    
    <content type="html"><![CDATA[<h2 id="原子操作CAS"><a href="#原子操作CAS" class="headerlink" title="原子操作CAS"></a>原子操作CAS</h2><h3 id="LongAdder"><a href="#LongAdder" class="headerlink" title="LongAdder"></a>LongAdder</h3><p>JDK1.8时，java.util.concurrent.atomic包中提供了一个新的原子类：LongAdder。<br> 根据Oracle官方文档的介绍，LongAdder在高并发的场景下会比它的前辈————AtomicLong 具有更好的性能，代价是消耗更多的内存空间。</p><p><strong>AtomicLong</strong>是利用了底层的CAS操作来提供并发性的，调用了<strong>Unsafe</strong>类的<strong>getAndAddLong</strong>方法，该方法是个<strong>native</strong>方法，它的逻辑是采用自旋的方式不断更新目标值，直到更新成功。</p><p>在并发量较低的环境下，线程冲突的概率比较小，自旋的次数不会很多。但是，高并发环境下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时<strong>AtomicLong</strong>的自旋会成为瓶颈。</p><p>这就是<strong>LongAdder</strong>引入的初衷——解决高并发环境下<strong>AtomicLong</strong>的自旋瓶颈问题。</p><p><strong>AtomicLong</strong>中有个内部变量<strong>value</strong>保存着实际的long值，所有的操作都是针对该变量进行。也就是说，高并发环境下，value变量其实是一个热点，也就是N个线程竞争一个热点。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jnenhvsrj309m00v3ya.jpg" alt></p><p><strong>LongAdder</strong>的基本思路就是<strong>分散热点</strong>，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。</p><p>这种做法和ConcurrentHashMap中的“分段锁”其实就是类似的思路。</p><p><strong>LongAdder</strong>提供的API和<strong>AtomicLong</strong>比较接近，两者都能以原子的方式对long型变量进行增减。</p><p>但是<strong>AtomicLong</strong>提供的功能其实更丰富，尤其是<strong>addAndGet</strong>、<strong>decrementAndGet</strong>、<strong>compareAndSet</strong>这些方法。</p><p><strong>addAndGet</strong>、<strong>decrementAndGet</strong>除了单纯的做自增自减外，还可以立即获取增减后的值，而<strong>LongAdder</strong>则需要做同步控制才能精确获取增减后的值。如果业务需求需要精确的控制计数，做计数比较，<strong>AtomicLong</strong>也更合适。</p><p>另外，从空间方面考虑，<strong>LongAdder</strong>其实是一种“空间换时间”的思想，从这一点来讲<strong>AtomicLong</strong>更适合。</p><p>总之，低并发、一般的业务场景下AtomicLong是足够了。如果并发量很多，存在大量写多读少的情况，那LongAdder可能更合适。适合的才是最好的，如果真出现了需要考虑到底用AtomicLong好还是LongAdder的业务场景，那么这样的讨论是没有意义的，因为这种情况下要么进行性能测试，以准确评估在当前业务场景下两者的性能，要么换个思路寻求其它解决方案。</p><p>对于<strong>LongAdder</strong>来说，内部有一个base变量，一个Cell[]数组。</p><p>base变量：非竞态条件下，直接累加到该变量上。</p><p>Cell[]数组：竞态条件下，累加个各个线程自己的槽Cell[i]中。</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnenf1v8j30bq00pa9u.jpg" alt></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnencgzfj30aa00q3ya.jpg" alt></p><p>所以，最终结果的计算应该是</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jnf5lhhsj30fd0790sv.jpg" alt></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnf5jahqj306201j743.jpg" alt></p><p>在实际运用的时候，只有从未出现过并发冲突的时候，base基数才会使用到，一旦出现了并发冲突，之后所有的操作都只针对Cell[]数组中的单元Cell。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jnf5g0c9j30lv06h3yw.jpg" alt></p><p>而LongAdder最终结果的求和，并没有使用全局锁，返回值不是绝对准确的，因为调用这个方法时还有其他线程可能正在进行计数累加，所以只能得到某个时刻的近似值，这也就是<strong>LongAdder</strong>并不能完全替代<strong>LongAtomic</strong>的原因之一。</p><p>而且从测试情况来看，线程数越多，并发操作数越大，LongAdder的优势越大，线程数较小时，AtomicLong的性能还超过了LongAdder。</p><h3 id="其他新增"><a href="#其他新增" class="headerlink" title="其他新增"></a>其他新增</h3><p>除了新引入LongAdder外，还有引入了它的三个兄弟类：<strong>LongAccumulator</strong> <strong>、</strong> <strong>DoubleAdder</strong> <strong>、</strong> <strong>DoubleAccumulator</strong>。</p><p>LongAccumulator是LongAdder的增强版。LongAdder只能针对数值的进行加减运算，而LongAccumulator提供了自定义的函数操作。</p><p>通过LongBinaryOperator，可以自定义对入参的任意操作，并返回结果（LongBinaryOperator接收2个long作为参数，并返回1个long）。</p><p>LongAccumulator内部原理和LongAdder几乎完全一样。</p><p>DoubleAdder和DoubleAccumulator用于操作double原始类型。</p><h2 id="StampLock"><a href="#StampLock" class="headerlink" title="StampLock"></a>StampLock</h2><p>StampedLock是Java8引入的一种新的所机制,简单的理解,可以认为它是读写锁的一个改进版本,读写锁虽然分离了读和写的功能,使得读与读之间可以完全并发,但是读和写之间依然是冲突的,读锁会完全阻塞写锁,它使用的依然是悲观的锁策略.如果有大量的读线程,他也有可能引起写线程的饥饿。</p><p>而StampedLock则提供了一种乐观的读策略,这种乐观策略的锁非常类似于无锁的操作,使得乐观锁完全不会阻塞写线程。</p><p>它的思想是读写锁中读不仅不阻塞读，同时也不应该阻塞写。</p><p><strong>读不阻塞写的实现思路：</strong></p><p>在读的时候如果发生了写，则应当重读而不是在读的时候直接阻塞写！即读写之间不会阻塞对方，但是写和写之间还是阻塞的！</p><p>StampedLock的内部实现是基于CLH的。</p><p>参考代码，参见cn.enjoyedu.cha. StampedLockDemo</p><h2 id="CompleteableFuture"><a href="#CompleteableFuture" class="headerlink" title="CompleteableFuture"></a>CompleteableFuture</h2><h3 id="Future的不足"><a href="#Future的不足" class="headerlink" title="Future的不足"></a>Future的不足</h3><p>Future是Java 5添加的类，用来描述一个异步计算的结果。你可以使用isDone方法检查计算是否完成，或者使用get阻塞住调用线程，直到计算完成返回结果，你也可以使用cancel方法停止任务的执行。</p><p>虽然Future以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的CPU资源，而且也不能及时地得到计算结果，为什么不能用观察者设计模式当计算结果完成及时通知监听者呢？。</p><p>Java的一些框架，比如Netty，自己扩展了Java的 Future接口，提供了addListener等多个扩展方法，Google guava也提供了通用的扩展Future:ListenableFuture、SettableFuture 以及辅助类Futures等,方便异步编程。</p><p>同时Future接口很难直接表述多个Future 结果之间的依赖性。实际开发中，我们经常需要达成以下目的：</p><p>将两个异步计算合并为一个——这两个异步计算之间相互独立，同时第二个又依赖于第一个的结果。</p><p>等待 Future 集合中的所有任务都完成。</p><p>仅等待 Future集合中最快结束的任务完成（有可能因为它们试图通过不同的方式计算同一个值），并返回它的结果。</p><p>应对 Future 的完成事件（即当 Future 的完成事件发生时会收到通知，并能使用 Future 计算的结果进行下一步的操作，不只是简单地阻塞等待操作的结果）</p><h3 id="CompleteableFuture-1"><a href="#CompleteableFuture-1" class="headerlink" title="CompleteableFuture"></a>CompleteableFuture</h3><p>JDK1.8才新加入的一个实现类CompletableFuture，实现了Future<t>， CompletionStage<t>两个接口。实现了Future接口，意味着可以像以前一样通过阻塞或者轮询的方式获得结果。</t></t></p><h4 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h4><p>除了直接new出一个CompletableFuture的实例，还可以通过工厂方法创建CompletableFuture的实例</p><p><strong>工厂方法：</strong></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jnfxjkocj30da01jt8l.jpg" alt></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnfxgt95j30dy01g0sm.jpg" alt></p><p>Asynsc表示异步,而supplyAsync与runAsync不同在与前者异步返回一个结果,后者是void.第二个函数第二个参数表示是用我们自己创建的线程池,否则采用默认的ForkJoinPool.commonPool()作为它的线程池。</p><p><strong>获得结果的方法</strong></p><p>public T get()</p><p>public T get(long timeout, TimeUnit unit)</p><p>public T getNow(T valueIfAbsent)</p><p>public T join()</p><p>getNow有点特殊，如果结果已经计算完则返回结果或者抛出异常，否则返回给定的valueIfAbsent值。</p><p>join返回计算的结果或者抛出一个unchecked异常(CompletionException)，它和get对抛出的异常的处理有些细微的区别。</p><p>参见cn.enjoyedu.cha.cfdemo下CFDemo和JoinAndGet</p><p><strong>辅助方法</strong></p><p>public static CompletableFuture<void> allOf(CompletableFuture&lt;?&gt;… cfs)</void></p><p>public static CompletableFuture<object> anyOf(CompletableFuture&lt;?&gt;… cfs)</object></p><p>allOf方法是当所有的CompletableFuture都执行完后执行计算。</p><p>anyOf方法是当任意一个CompletableFuture执行完后就会执行计算，计算的结果相同。</p><p>参见cn.enjoyedu.cha.cfdemo下AllofAnyOf</p><p>CompletionStage是一个接口，从命名上看得知是一个完成的阶段，它代表了一个特定的计算的阶段，可以同步或者异步的被完成。你可以把它看成一个计算流水线上的一个单元，并最终会产生一个最终结果，这意味着几个CompletionStage可以串联起来，一个完成的阶段可以触发下一阶段的执行，接着触发下一次，再接着触发下一次，……….。</p><p>总结CompletableFuture几个关键点：</p><p>1、计算可以由 Future ，Consumer 或者 Runnable 接口中的 apply，accept 或者 run等方法表示。</p><p>2、计算的执行主要有以下</p><p>a. 默认执行</p><p>b. 使用默认的CompletionStage的异步执行提供者异步执行。这些方法名使用someActionAsync这种格式表示。</p><p>c. 使用 Executor 提供者异步执行。这些方法同样也是someActionAsync这种格式，但是会增加一个Executor 参数。</p><p>CompletableFuture里大约有五十种方法，但是可以进行归类，</p><p><strong>变换类 thenApply：</strong></p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jnfxe1cnj30cm0230so.jpg" alt></p><p>关键入参是函数式接口Function。它的入参是上一个阶段计算后的结果，返回值是经过转化后结果。</p><p><strong>消费类 thenAccept：</strong></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jngmdny6j30cv021wef.jpg" alt></p><p>关键入参是函数式接口Consumer。它的入参是上一个阶段计算后的结果， 没有返回值。</p><p> <strong>执行操作类 thenRun：</strong></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jngmasg1j30cr02ajrc.jpg" alt></p><p>对上一步的计算结果不关心，执行下一个操作，入参是一个Runnable的实例，表示上一步完成后执行的操作。</p><p><strong>结合转化类:</strong></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jngm80mwj30pc02bmx7.jpg" alt></p><p>需要上一步的处理返回值，并且other代表的CompletionStage 有返回值之后，利用这两个返回值，进行转换后返回指定类型的值。</p><p>两个CompletionStage是并行执行的，它们之间并没有先后依赖顺序，other并不会等待先前的CompletableFuture执行完毕后再执行。</p><p><strong>结合转化类</strong></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jnhc7laaj30js0243yi.jpg" alt></p><p>对于Compose可以连接两个CompletableFuture，其内部处理逻辑是当第一个CompletableFuture处理没有完成时会合并成一个CompletableFuture,如果处理完成，第二个future会紧接上一个CompletableFuture进行处理。</p><p>第一个CompletableFuture 的处理结果是第二个future需要的输入参数。</p><p><strong>结合消费类:</strong></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jnhc534vj30og02cwej.jpg" alt></p><p>需要上一步的处理返回值，并且other代表的CompletionStage 有返回值之后，利用这两个返回值，进行消费</p><p><strong>运行后执行类：</strong></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnhc2pauj30ju024gln.jpg" alt></p><p>不关心这两个CompletionStage的结果，只关心这两个CompletionStage都执行完毕，之后再进行操作（Runnable）。</p><p><strong>取最快转换类：</strong></p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jnhuptjij30o902aq30.jpg" alt></p><p>两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的转化操作。现实开发场景中，总会碰到有两种渠道完成同一个事情，所以就可以调用这个方法，找一个最快的结果进行处理。</p><p><strong>取最快消费类：</strong></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnhumvxlj30mp025q2z.jpg" alt></p><p>两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的消费操作。</p><p><strong>取最快运行后执行类：</strong></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jnhuk0wfj30ju023dfv.jpg" alt></p><p>两个CompletionStage，任何一个完成了都会执行下一步的操作（Runnable）。</p><p><strong>异常补偿类：</strong></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnid9xe5j30em02v0so.jpg" alt></p><p>当运行时出现了异常，可以通过exceptionally进行补偿。</p><p><strong>运行后记录结果类：</strong></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnid3oewj30lv025jrf.jpg" alt></p><p>action执行完毕后它的结果返回原始的CompletableFuture的计算结果或者返回异常。所以不会对结果产生任何的作用。</p><p><strong>运行后处理结果类：</strong></p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jnicviouj30l202274c.jpg" alt></p><p>运行完成时，对结果的处理。这里的完成时有两种情况，一种是正常执行，返回值。另外一种是遇到异常抛出造成程序的中断。</p><h3 id="补充：Lambda速成"><a href="#补充：Lambda速成" class="headerlink" title="补充：Lambda速成"></a>补充：Lambda速成</h3><p>本补充章节仅为没接触过Lambda的同学快速入门和速查，更具体的Lamba的知识请自行查阅相关书籍和博客。相关代码放在cn.enjoyedu.cha.lambda下</p><p>现在我们有一个实体类，我们会对这个实体类进行操作。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jnj3bu4hj308p05jweg.jpg" alt></p><h4 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h4><p>我们想从一批Circle中挑选出挑选出半径为2的圆，于是我们写了一个方法</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnj2znodj30ka06jjrn.jpg" alt></p><p>这样，无疑很不优雅，如果我们想挑选半径为3的圆，难道还要再写一个方法？于是我们考虑将选择条件进行参数化，比如根据颜色挑选出圆或者根据半径挑选出圆</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jnj2hj5sj30r306rdg7.jpg" alt></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnjmweeqj30q906q74n.jpg" alt></p><p>但是，这种实现，还是有问题的，1、选择条件变化了，那么相应的方法也要变，比如我们想挑选半径大于3的圆，怎么办？如果我要根据多个条件选择，怎么办？难道把所有的条件都传入吗？于是，我们考虑定义一个挑选圆的接口，程序进化到了第二歩</p><h4 id="第二步"><a href="#第二步" class="headerlink" title="第二步"></a>第二步</h4><p>进行行为参数化，定义一个接口</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnjms56gj30cs02st8n.jpg" alt></p><p> 在进行圆的挑选的方法里，我们把这个接口作为参数进行传递</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnjmo7pmj30tg07faaf.jpg" alt></p><p>然后，我们只要按业务需求实现接口，并传入实现类的实例即可</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnk41d42j30nb08wmxo.jpg" alt></p><p>这种方式可以提高灵活性，但是业务上每增加一个挑选行为， 我们就需要显式声明一个接口ChoiceCircle的实现类，于是我们可以考虑使用内部匿名类，进入第三步。</p><h4 id="第三步"><a href="#第三步" class="headerlink" title="第三步"></a>第三步</h4><p>在实际使用时，我们不再声明一个接口ChoiceCircle的实现类</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnk3vxubj30p509x0td.jpg" alt></p><p>匿名内部类占用代码空间较多，而且存在着模版代码，这种情况下，Lambda表达式就可以派上用场了</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnk3ssnwj30kq03j74c.jpg" alt></p><p>所以可以把Lambda表达式看成匿名内部类的一个简洁写法</p><h4 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a>Lambda</h4><p>在语法上，Lambda表达式包含三个部分，参数列表，箭头，主体，比如：</p><p> <strong>(parameters) -&gt; expression</strong></p><p>或</p><p> <strong>(parameters) -&gt;</strong> <strong>｛</strong> <strong>statements;</strong> <strong>｝</strong></p><p>Lambda表达式用在函数式接口上，所谓函数式接口，是只定义了一个抽象方法的接口（Interface），接口中是否有默认方法，不影响。</p><p>注解@FunctionalInterface可以帮助我们在设计函数式接口时防止出错。</p><p>我们常用的Runnable,Callable都是函数式接口，JDK8中新增了几个函数式接口：</p><p><strong>Predicate<t> :</t></strong></p><p>包含test方法，接受泛型的T，返回boolean，可以视为断言（检查）接口</p><p><strong>Consumer<t> :</t></strong></p><p>包含accept方法，接受泛型的T，无返回，可以视为数据消费接口</p><p><strong>Function&lt;T</strong> <strong>，</strong> <strong>R&gt; :</strong></p><p>包含apply方法，接受泛型的T，返回R，可以视为映射转换接口</p><p><strong>Supplier<t></t></strong></p><p>包含get方法，无输入，返回T，可以视为创建一个新对象接口</p><p><strong>UnaryOperator<t></t></strong></p><p>扩展至Function&lt;T，T&gt;，所以这个本质上也是一个映射转换接口，只不过映射转换后的类型保持不变</p><p><strong>BiFunction&lt;T, U, R&gt;</strong></p><p>包含apply方法，接受泛型的T、U，返回R，可以视为复合型映射转换接口</p><p><strong>BinaryOperator<t></t></strong></p><p>扩展至Function BiFunction&lt;T,T,T&gt;，所以这个本质上也是一个复合型映射转换接口，只不过映射转换后的类型保持不变</p><p><strong>BiPredicate</strong> <strong>&lt;T, U&gt;</strong> </p><p>包含test方法，接受泛型的T，U，返回boolean，可以视为复合型断言（检查）接口</p><p><strong>BiConsumer&lt;T</strong> <strong>，</strong> <strong>U&gt;:</strong></p><p>包含accept方法，接受泛型的T，U，无返回，可以视为复合型数据消费接口</p><p>同时还提供了一些为了防止自动装箱机制，而特意声明的原始类型特化的函数式接口，比如，</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jnknlotrj30b307daa7.jpg" alt></p><p>在意义上，和对应的Predicate接口并没有差别。</p><h4 id="函数描述符"><a href="#函数描述符" class="headerlink" title="函数描述符"></a>函数描述符</h4><p>函数式接口的抽象方法的签名基本上就是Lambda表达式的签名。我们将这种抽象方法叫作函数描述符。</p><p>Runnable接口可以看作一个什么也不接受什么也不返回（void）的函数的签名，因为它只有一个叫作run的抽象方法，这个方法什么也不接受，什么也不返回（void）。</p><p>我们可以用 () -&gt; void代表参数列表为空，且返回void的函数。这正是Runnable接口所代表的。我们于是可以称() -&gt; void是Runnable接口的函数描述符。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jnknitraj30bd09h3yr.jpg" alt></p><p>再考察Callable接口和Supplier接口</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnknfe13j30b805jmx8.jpg" alt></p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jnmm0x5zj30ab05g748.jpg" alt></p><p>从函数描述符来看，Callable接口和Supplier接口是一样的，都是</p><p>() -&gt; X</p><p>所以同一个Lambda可以同时用在这两个函数式接口上，比如：</p><p>Callable<integer> = () -&gt; 33;</integer></p><p>Supplier&lt;&gt;<integer> = () -&gt; 33;</integer></p><h1 id="扩充知识点-Disruptor"><a href="#扩充知识点-Disruptor" class="headerlink" title="扩充知识点- Disruptor"></a>扩充知识点- Disruptor</h1><h2 id="应用背景和介绍"><a href="#应用背景和介绍" class="headerlink" title="应用背景和介绍"></a>应用背景和介绍</h2><p>Disruptor是英国外汇交易公司LMAX开发的一个高性能队列，研发的初衷是解决内部的内存队列的延迟问题，而不是分布式队列。基于Disruptor开发的系统单线程能支撑每秒600万订单，2010年在QCon演讲后，获得了业界关注。</p><p>据目前资料显示：应用Disruptor的知名项目有如下的一些：Storm, Camel, Log4j2,还有目前的美团点评技术团队也有很多不少的应用，或者说有一些借鉴了它的设计机制。 </p><p>Disruptor是一个高性能的线程间异步通信的框架，即在同一个JVM进程中的多线程间消息传递。</p><h2 id="传统队列问题"><a href="#传统队列问题" class="headerlink" title="传统队列问题"></a>传统队列问题</h2><p>在JDK中，Java内部的队列BlockQueue的各种实现，仔细分析可以得知，队列的底层数据结构一般分成三种：数组、链表和堆，堆这里是为了实现带有优先级特性的队列暂且不考虑。 </p><p>在稳定性和性能要求特别高的系统中，为了防止生产者速度过快，导致内存溢出，只能选择有界队列；同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择 Array格式的数据结构。这样筛选下来，符合条件的队列就只有ArrayBlockingQueue。但是ArrayBlockingQueue是通过<strong>加锁</strong>的方式保证线程安全，而且ArrayBlockingQueue还存在<strong>伪共享</strong>问题，这两个问题严重影响了性能。</p><p>ArrayBlockingQueue的这个伪共享问题存在于哪里呢，分析下核心的部分源码，其中最核心的三个成员变量为</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jnmm0x5zj30ab05g748.jpg" alt> 是在ArrayBlockingQueue的核心enqueue和dequeue方法中经常会用到的，这三个变量很容易放到同一个缓存行中，进而产生伪共享问题。</p><h2 id="高性能的原理"><a href="#高性能的原理" class="headerlink" title="高性能的原理"></a>高性能的原理</h2><p>引入环形的数组结构：数组元素不会被回收，避免频繁的GC，</p><p>无锁的设计：采用CAS无锁方式，保证线程的安全性</p><p>属性填充：通过添加额外的无用信息，避免伪共享问题</p><p>环形数组结构是整个Disruptor的核心所在。 </p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jnmlutzjj30hi09swff.jpg" alt></p><p>首先因为是数组，所以要比链表快，而且根据我们对上面缓存行的解释知道，数组中的一个元素加载，相邻的数组元素也是会被预加载的，因此在这样的结构中，cpu无需时不时去主存加载数组中的下一个元素。而且，你可以为数组预先分配内存，使得数组对象一直存在（除非程序终止）。这就意味着不需要花大量的时间用于垃圾回收。此外，不像链表那样，需要为每一个添加到其上面的对象创造节点对象—对应的，当删除节点时，需要执行相应的内存清理操作。环形数组中的元素采用覆盖方式，避免了jvm的GC。 </p><p>其次结构作为环形，数组的大小为2的n次方，这样元素定位可以通过位运算效率会更高，这个跟一致性哈希中的环形策略有点像。在disruptor中，这个牛逼的环形结构就是RingBuffer，既然是数组，那么就有大小，而且这个大小必须是2的n次方</p><p>其实质只是一个普通的数组，只是当放置数据填充满队列（即到达2^n-1位置）之后，再填充数据，就会从0开始，覆盖之前的数据，于是就相当于一个环。</p><p>每个生产者首先通过CAS竞争获取可以写的空间，然后再进行慢慢往里放数据，如果正好这个时候消费者要消费数据，那么每个消费者都需要获取最大可消费的下标。</p><p>同时，Disruptor 不像传统的队列，分为一个队头指针和一个队尾指针，而是只有一个角标（上图的seq），它属于一个volatile变量，同时也是我们能够不用锁操作就能实现Disruptor的原因之一，而且通过缓存行补充，避免伪共享问题。该指针是通过一直自增的方式来获取下一个可写或者可读数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;原子操作CAS&quot;&gt;&lt;a href=&quot;#原子操作CAS&quot; class=&quot;headerlink&quot; title=&quot;原子操作CAS&quot;&gt;&lt;/a&gt;原子操作CAS&lt;/h2&gt;&lt;h3 id=&quot;LongAdder&quot;&gt;&lt;a href=&quot;#LongAdder&quot; class=&quot;header
      
    
    </summary>
    
      <category term="并发编程" scheme="https://ellenjack.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="多线程" scheme="https://ellenjack.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>JMM和底层实现原理</title>
    <link href="https://ellenjack.github.io/2019/06/20/thread-7/"/>
    <id>https://ellenjack.github.io/2019/06/20/thread-7/</id>
    <published>2019-06-20T15:01:24.000Z</published>
    <updated>2020-03-29T11:28:31.548Z</updated>
    
    <content type="html"><![CDATA[<h2 id="JMM基础-计算机原理"><a href="#JMM基础-计算机原理" class="headerlink" title="JMM基础-计算机原理"></a>JMM基础-计算机原理</h2><p>Java内存模型即Java Memory Model，简称JMM。JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。Java1.5版本对其进行了重构，现在的Java仍沿用了Java1.5的版本。Jmm遇到的问题与现代计算机中遇到的问题是差不多的。</p><p>物理计算机中的并发问题，物理机遇到的并发问题与虚拟机中的情况有不少相似之处，物理机对并发的处理方案对于虚拟机的实现也有相当大的参考意义。</p><p>根据《Jeff Dean在Google全体工程大会的报告》我们可以看到</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn1oitx4j30hv0ap3zg.jpg" alt></p><p>计算机在做一些我们平时的基本操作时，需要的响应时间是不一样的。</p><p>（以下案例仅做说明，并不代表真实情况。）</p><p>如果从内存中读取1M的int型数据由CPU进行累加，耗时要多久？</p><p>做个简单的计算，1M的数据，Java里int型为32位，4个字节，共有1024<em>1024/4 = 262144个整数 ，则CPU 计算耗时：262144 </em>0.6 = 157 286 纳秒，而我们知道从内存读取1M数据需要250000纳秒，两者虽然有差距（当然这个差距并不小，十万纳秒的时间足够CPU执行将近二十万条指令了），但是还在一个数量级上。但是，没有任何缓存机制的情况下，意味着每个数都需要从内存中读取，这样加上CPU读取一次内存需要100纳秒，262144个整数从内存读取到CPU加上计算时间一共需要262144*100+250000 = 26 464 400 纳秒，这就存在着数量级上的差异了。</p><p>而且现实情况中绝大多数的运算任务都不可能只靠处理器“计算”就能完成，处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个I/O操作是基本上是无法消除的（无法仅靠寄存器来完成所有运算任务）。早期计算机中cpu和内存的速度是差不多的，但在现代计算机中，cpu的指令速度远超内存的存取速度,由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn1ofwszj30kd09vwiy.jpg" alt></p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn1nkpp3j30ji0bidlt.jpg" alt></p><p>在计算机系统中，寄存器划是L0级缓存，接着依次是L1，L2，L3（接下来是内存，本地磁盘，远程存储）。越往上的缓存存储空间越小，速度越快，成本也更高；越往下的存储空间越大，速度更慢，成本也更低。从上至下，每一层都可以看做是更下一层的缓存，即：L0寄存器是L1一级缓存的缓存，L1是L2的缓存，依次类推；每一层的数据都是来至它的下一层，所以每一层的数据是下一层的数据的子集。</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn2apo0aj30k00jvq4g.jpg" alt></p><p>在现代CPU上，一般来说L0， L1，L2，L3都集成在CPU内部，而L1还分为一级数据缓存（Data Cache，D-Cache，L1d）和一级指令缓存（Instruction Cache，I-Cache，L1i），分别用于存放数据和执行数据的指令解码。每个核心拥有独立的运算处理单元、控制器、寄存器、L1、L2缓存，然后一个CPU的多个核心共享最后一层CPU缓存L3</p><h2 id="物理内存模型带来的问题"><a href="#物理内存模型带来的问题" class="headerlink" title="物理内存模型带来的问题"></a>物理内存模型带来的问题</h2><p>基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统带来更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory）。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致。</p><p>现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jn2amfexj30l204kt9c.jpg" alt></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn2ajky7j30jy0evgo0.jpg" alt></p><p>处理器A和处理器B按程序的顺序并行执行内存访问，最终可能得到x=y=0的结果。</p><p>处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（步骤A1，B1），然后从内存中读取另一个共享变量（步骤A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（步骤A3，B3）。当以这种时序执行时，程序就可以得到x=y=0的结果。</p><p>从内存操作实际发生的顺序来看，直到处理器A执行A3来刷新自己的写缓存区，写操作A1才算真正执行了。虽然处理器A执行内存操作的顺序为：A1→A2，但内存操作实际发生的顺序却是A2→A1。</p><p>如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等。</p><h2 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h2><p>前面我们已经知道，CPU中有好几级高速缓存。但是CPU缓存系统中是以缓存行（cache line）为单位存储的。目前主流的CPU Cache的Cache Line大小都是64Bytes。Cache Line可以简单的理解为CPU Cache中的最小缓存单位，今天的CPU不再是按字节访问内存，而是以64字节为单位的块(chunk)拿取，称为一个缓存行(cache line)。当你读一个特定的内存地址，整个缓存行将从主存换入缓存。</p><p>一个缓存行可以存储多个变量（存满当前缓存行的字节数）；而CPU对缓存的修改又是以缓存行为最小单位的，在多线程情况下，如果需要修改“共享同一个缓存行的变量”，就会无意中影响彼此的性能，这就是伪共享（False Sharing）。</p><p>为了避免伪共享，我们可以使用数据填充的方式来避免，即单个数据填充满一个CacheLine。这本质是一种空间换时间的做法。但是这种方式在Java7以后可能失效。</p><p>Java8中已经提供了官方的解决方案，Java8中新增了一个注解@sun.misc.Contended。</p><p>比如JDK的ConcurrentHashMap中就有使用</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn312ce6j30i602zweg.jpg" alt></p><p>加上这个注解的类会自动补齐缓存行，需要注意的是此注解默认是无效的，需要在jvm启动时设置-XX:-RestrictContended才会生效。</p><p>测试代码，参见cn.enjoyedu.ch9. FalseSharing</p><p>一个类中，只有一个long类型的变量：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn2znr7yj30e80270sl.jpg" alt></p><p>定义一个VolatileLong类型的数组，然后让多个线程同时并发访问这个数组，这时可以想到，在多个线程同时处理数据时，数组中的多个VolatileLong对象可能存在同一个缓存行中。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn2zkmqfj30pl04jgls.jpg" alt></p><p>运行后，可以得到运行时间</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jn3mucgnj30qm08bmy1.jpg" alt></p><p>花费了39秒多。</p><p>我们改用进行了缓存行填充的变量</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn3mq7vvj310o08rq41.jpg" alt></p><p>花费了8.1秒，如果任意注释上下填充行的任何一行，时间表现不稳定，从8秒到20秒都有，但是还是比不填充要快。具体原因目前未知。</p><p>再次改用注解标识的变量，同时加入参数-XX:-RestrictContended</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn3mmd7hj30dv058q2w.jpg" alt></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn4io346j30rb068gm7.jpg" alt></p><p>花费了7.7秒。</p><p>由上述的实验结果表明，伪共享确实会影响应用的性能。</p><h2 id="Java内存模型（JMM）"><a href="#Java内存模型（JMM）" class="headerlink" title="Java内存模型（JMM）"></a>Java内存模型（JMM）</h2><p>从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个<strong>私有</strong>的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jn4il8k7j30c702rmxa.jpg" alt></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jn4iiebfj30i307wjur.jpg" alt></p><h2 id="Java内存模型带来的问题"><a href="#Java内存模型带来的问题" class="headerlink" title="Java内存模型带来的问题"></a>Java内存模型带来的问题</h2><h3 id="可见性问题"><a href="#可见性问题" class="headerlink" title="可见性问题"></a>可见性问题</h3><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn56masvj30qe0bl753.jpg" alt></p><p>左边CPU中运行的线程从主存中拷贝共享对象obj到它的CPU缓存，把对象obj的count变量改为2。但这个变更对运行在右边CPU中的线程不可见，因为这个更改还没有flush到主存中。</p><p>在多线程的环境下，如果某个线程首次读取共享变量，则首先到主内存中获取该变量，然后存入工作内存中，以后只需要在工作内存中读取该变量即可。同样如果对该变量执行了修改的操作，则先将新值写入工作内存中，然后再刷新至主内存中。但是什么时候最新的值会被刷新至主内存中是不太确定，一般来说会很快，但具体时间不知。</p><p>要解决共享对象可见性这个问题，我们可以使用volatile关键字或者是加锁。</p><h3 id="竞争问题"><a href="#竞争问题" class="headerlink" title="竞争问题"></a>竞争问题</h3><p>线程A和线程B共享一个对象obj。假设线程A从主存读取Obj.count变量到自己的CPU缓存，同时，线程B也读取了Obj.count变量到它的CPU缓存，并且这两个线程都对Obj.count做了加1操作。此时，Obj.count加1操作被执行了两次，不过都在不同的CPU缓存中。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jn56iqmkj30q90c5my0.jpg" alt></p><p>如果这两个加1操作是串行执行的，那么Obj.count变量便会在原始值上加2，最终主存中的Obj.count的值会是3。然而图中两个加1操作是并行的，不管是线程A还是线程B先flush计算结果到主存，最终主存中的Obj.count只会增加1次变成2，尽管一共有两次加1操作。 要解决上面的问题我们可以使用java synchronized代码块</p><h3 id="重排序"><a href="#重排序" class="headerlink" title="重排序"></a>重排序</h3><h4 id="重排序类型"><a href="#重排序类型" class="headerlink" title="重排序类型"></a>重排序类型</h4><p>除了共享内存和工作内存带来的问题，还存在重排序的问题：在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。</p><p>1）编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</p><p>2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</p><p>3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</p><h4 id="数据依赖性"><a href="#数据依赖性" class="headerlink" title="数据依赖性"></a>数据依赖性</h4><p>数据依赖性：如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分为下列3种类型，上面3种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn56en46j30ma09k0tg.jpg" alt></p><p>例如：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn6lclm4j306804vmx8.jpg" alt></p><p>很明显，A和C存在数据依赖，B和C也存在数据依赖，而A和B之间不存在数据依赖，如果重排序了A和C或者B和C的执行顺序，程序的执行结果就会被改变。</p><p>很明显，不管如何重排序，都必须保证代码在单线程下的运行正确，连单线程下都无法正确，更不用讨论多线程并发的情况，所以就提出了一个as-if-serial的概念。</p><h4 id="as-if-serial"><a href="#as-if-serial" class="headerlink" title="as-if-serial"></a>as-if-serial</h4><p>as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。</p><p>为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。（强调一下，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。）但是，如果操作之间不存在数据依赖关系，这些操作依然可能被编译器和处理器重排序。</p><p>A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。因此在最终执行的指令序列中，C不能被重排序到A和B的前面（C排到A和B的前面，程序的结果将会被改变）。但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn6l971oj309d028mx3.jpg" alt> <img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn6l6r2cj309d024dfr.jpg" alt></p><p>as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器可以让我们感觉到：单线程程序看起来是按程序的顺序来执行的。asif-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。</p><h4 id="控制依赖性"><a href="#控制依赖性" class="headerlink" title="控制依赖性"></a>控制依赖性</h4><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn79iz6bj30a80a3dfx.jpg" alt></p><p>上述代码中，flag变量是个标记，用来标识变量a是否已被写入，在use方法中变量i的赋值依赖if (flag)的判断，这里就叫控制依赖，如果发生了重排序，结果就不对了。</p><p>考察代码，我们可以看见，</p><p>操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。操作3和操作4则存在所谓<strong>控制依赖关系</strong>。</p><p>在程序中，当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（Reorder Buffer，ROB）的硬件缓存中。当操作3的条件判断为真时，就把该计算结果写入变量i中。猜测执行实质上对操作3和4做了重排序，问题在于这时候，a的值还没被线程A赋值。</p><p>在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）。</p><p>但是对多线程来说就完全不同了：这里假设有两个线程A和B，A首先执行init ()方法，随后B线程接着执行use ()方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量a的写入呢？答案是：不一定能看到。</p><p>让我们先来看看，当操作1和操作2重排序，操作3和操作4重排序时，可能会产生什么效果？操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还没有被线程A写入，这时就会发生错误！</p><p>所以在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。</p><h3 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h3><p>Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，从而让程序按我们预想的流程去执行。</p><p>1、保证特定操作的执行顺序。</p><p>2、影响某些数据（或则是某条指令的执行结果）的内存可见性。</p><p>编译器和CPU能够重排序指令，保证最终相同的结果，尝试优化性能。插入一条Memory Barrier会告诉编译器和CPU：不管什么指令都不能和这条Memory Barrier指令重排序。</p><p>Memory Barrier所做的另外一件事是强制刷出各种CPU cache，如一个Write-Barrier（写入屏障）将刷出所有在Barrier之前写入 cache 的数据，因此，任何CPU上的线程都能读取到这些数据的最新版本。</p><p>JMM把内存屏障指令分为4类</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn79fxghj30o009i0wk.jpg" alt></p><p> StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。</p><h3 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h3><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn79aeoaj30b70gn0tz.jpg" alt></p><p>JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得多线程在这两个时间点按某种顺序执行。</p><p>临界区内的代码则可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。</p><p>回想一下，为啥线程安全的单例模式中一般的双重检查不能保证真正的线程安全？</p><h2 id="happens-before"><a href="#happens-before" class="headerlink" title="happens-before"></a>happens-before</h2><p>在Java 规范提案中为让大家理解内存可见性的这个概念，提出了happens-before的概念来阐述操作之间的内存可见性。对应Java程序员来说，理解happens-before是理解JMM的关键。</p><p>JMM这么做的原因是：程序员对于这两个操作是否真的被重排序并不关心，程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变）。因此，happens-before关系本质上和as-if-serial语义是一回事。as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证<strong>正确同步</strong>的多线程程序的执行结果不被改变。</p><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系 。 </p><p>两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）</p><h4 id="加深理解"><a href="#加深理解" class="headerlink" title="加深理解"></a>加深理解</h4><p>上面的定义看起来很矛盾，其实它是站在不同的角度来说的。</p><p>1）站在Java程序员的角度来说：JMM保证，如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</p><p>2）站在编译器和处理器的角度来说：JMM允许，两个操作之间存在happens-before关系，<strong>不要求</strong> <strong>Java</strong> <strong>平台的具体实现必须要按照</strong> <strong>happens-before</strong> <strong>关系指定的顺序来执行</strong>。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序是允许的。</p><p>回顾我们前面存在数据依赖性的代码：</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn7vsvp3j305k03imx7.jpg" alt></p><p>站在我们Java程序员的角度：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn7vpyelj305u038t8t.jpg" alt></p><p>但是仔细考察，2、3是必需的，而1并不是必需的，因此JMM对这三个happens-before关系的处理就分为两类：</p><p>1.会改变程序执行结果的重排序</p><p>2.不会改变程序执行结果的重排序</p><p>JMM对这两种不同性质的重排序，采用了不同的策略，如下：</p><p>1.对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序；</p><p>2.对于不会改变程序执行结果的重排序，JMM对编译器和处理器不做要求。</p><p>于是，站在我们程序员的角度，看起来这个三个操作满足了happens-before关系，而站在编译器和处理器的角度，进行了重排序，而排序后的执行结果，也是满足happens-before关系的。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn7vmzvwj30jq0lhjw2.jpg" alt></p><h4 id="Happens-Before规则"><a href="#Happens-Before规则" class="headerlink" title="Happens-Before规则"></a>Happens-Before规则</h4><p>JMM为我们提供了以下的Happens-Before规则：</p><p>1）程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</p><p>2）监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。</p><p>3）volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。</p><p>4）传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。</p><p>5）start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。</p><p>6）join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 </p><p>7 ）线程中断规则:对线程interrupt方法的调用happens-before于被中断线程的代码检测到中断事件的发生。</p><h2 id="volatile详解"><a href="#volatile详解" class="headerlink" title="volatile详解"></a>volatile详解</h2><h4 id="volatile特性"><a href="#volatile特性" class="headerlink" title="volatile特性"></a>volatile特性</h4><p>可以把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jn8c6btzj30k109v3ys.jpg" alt></p><p>可以看成</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn8c2bpkj30np0b5aaj.jpg" alt></p><p>所以volatile变量自身具有下列特性：</p><p>可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。</p><p>原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。</p><h4 id="volatile的内存语义"><a href="#volatile的内存语义" class="headerlink" title="volatile的内存语义"></a>volatile的内存语义</h4><p>内存语义：可以简单理解为 volatile，synchronize，atomic，lock 之类的在 JVM 中的内存方面实现原则。</p><p>volatile写的内存语义如下：<br> 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。 </p><p>volatile读的内存语义如下：<br> 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 </p><p>所以对于代码</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jn8by9pjj30bw0ba74g.jpg" alt></p><p>如果我们将<strong>flag</strong>变量以<strong>volatile</strong>关键字修饰，那么实际上：线程A在写flag变量后，本地内存A中被线程A更新过的两个共享变量的值都被刷新到主内存中。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn8u4behj30h00btmxh.jpg" alt></p><p>在读flag变量后，本地内存B包含的值已经被置为无效。此时，线程B必须从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值变成一致。</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn8u0llwj30j70cpwez.jpg" alt></p><p>如果我们把volatile写和volatile读两个步骤综合起来看的话，在读线程B读一个volatile变量后，写线程A在写这个volatile变量之前所有可见的共享变量的值都将立即变得对读线程B可见。</p><h4 id="为何volatile不是线程安全的"><a href="#为何volatile不是线程安全的" class="headerlink" title="为何volatile不是线程安全的"></a>为何volatile不是线程安全的</h4><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn8tw4kmj30le0af767.jpg" alt></p><h4 id="volatile内存语义的实现"><a href="#volatile内存语义的实现" class="headerlink" title="volatile内存语义的实现"></a>volatile内存语义的实现</h4><h5 id="volatile重排序规则表"><a href="#volatile重排序规则表" class="headerlink" title="volatile重排序规则表"></a>volatile重排序规则表</h5><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn9anw36j30mx06j0th.jpg" alt></p><p>总结起来就是：</p><p>当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。</p><p>当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。</p><p>当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。</p><h5 id="volatile的内存屏障"><a href="#volatile的内存屏障" class="headerlink" title="volatile的内存屏障"></a>volatile的内存屏障</h5><p>在Java中对于volatile修饰的变量，编译器在生成字节码时，会在指令序列中插入<strong>内存屏障</strong>来禁止特定类型的处理器重排序问题。</p><h6 id="volatile写"><a href="#volatile写" class="headerlink" title="volatile写"></a>volatile写</h6><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn9akxlpj30au0bc74z.jpg" alt></p><p>storestore屏障：对于这样的语句store1; storestore; store2，在store2及后续写入操作执行前，保证store1的写入操作对其它处理器可见。(也就是说如果出现storestore屏障，那么store1指令一定会在store2之前执行，CPU不会store1与store2进行重排序)</p><p>storeload屏障：对于这样的语句store1; storeload; load2，在load2及后续所有读取操作执行前，保证store1的写入对所有处理器可见。(也就是说如果出现storeload屏障，那么store1指令一定会在load2之前执行,CPU不会对store1与load2进行重排序)</p><h6 id="volatile读"><a href="#volatile读" class="headerlink" title="volatile读"></a>volatile读</h6><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jn9ahdu4j30am0blgmb.jpg" alt></p><p>在每个volatile读操作的后面插入一个LoadLoad屏障。在每个volatile读操作的后面插入一个loadstore屏障。</p><p>  loadload屏障：对于这样的语句load1; loadload; load2，在load2及后续读取操作要读取的数据被访问前，保证load1要读取的数据被读取完毕。（也就是说，如果出现loadload屏障，那么load1指令一定会在load2之前执行，CPU不会对load1与load2进行重排序） </p><p>  loadstore屏障：对于这样的语句load1; loadstore; store2，在store2及后续写入操作被刷出前，保证load1要读取的数据被读取完毕。（也就是说，如果出现loadstore屏障，那么load1指令一定会在store2之前执行，CPU不会对load1与store2进行重排序）</p><h3 id="volatile的实现原理"><a href="#volatile的实现原理" class="headerlink" title="volatile的实现原理"></a>volatile的实现原理</h3><p>通过对OpenJDK中的unsafe.cpp源码的分析，会发现被volatile关键字修饰的变量会存在一个“lock:”的前缀。</p><p>Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。</p><p>同时该指令会将当前处理器缓存行的数据直接写会到系统内存中，且这个写回内存的操作会使在其他CPU里缓存了该地址的数据无效。</p><p>1、 在具体的执行上，它先对总线和缓存加锁，然后执行后面的指令，最后释放锁后会把高速缓存中的脏数据全部刷新回主内存。在Lock锁住总线的时候，其他CPU的读写请求都会被阻塞，直到锁释放。</p><h2 id="final的内存语义"><a href="#final的内存语义" class="headerlink" title="final的内存语义"></a>final的内存语义</h2><p>在构造线程的类时，我们有种方式就是让类中所有的成员变量都不可变，利用的就是final关键字，那么这个final为何可以做到呢？重排序这种优化动作对构造方法，一样也是存在的。这就说明，一个成员变量加了final关键字后，JMM一定是做了相关处理的。</p><h3 id="final的两个重排序规则"><a href="#final的两个重排序规则" class="headerlink" title="final的两个重排序规则"></a>final的两个重排序规则</h3><p>对应final域，编译器和处理器需要遵守两个重排序规则。我们以代码cn.enjoyedu.ch9.semantics. FinalMemory来说明</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jna6qfhkj30dp0alt93.jpg" alt></p><p>我们假设一个线程A执行writer方法，随后另一个线程B执行reader方法。</p><p>1、在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</p><p>看write()方法，只包含一行代码 <em>obj</em> = <strong>new</strong> FinalMemory();。这一行代码包含两个步骤：</p><p>构造一个FinalMemory类型的对象。</p><p>把这个对象的引用赋值给引用变量obj。</p><p>假设线程B读对象引用（FinalMemory object = obj）与读对象的成员域之间（int a = object.i;int b = object.j）没有重排序，下面的图是一种可能的执行时序：</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jna6n40yj30h40gwjt7.jpg" alt></p><p>从上面可能的时序图中我们可以看到，写普通域被编译器重排序到了构造函数之外，读线程B错误的读取了普通变量i初始化之前的值。而写final域的操作，被写final域的重排序规则“限制”到了构造函数之内，读线程B正确读取了final变量初始化之后的值。</p><p>总结：写final域的重排序规则可以确保在对象引用为任意线程可见之前，对象的final域已经被正常的初始化了，而普通域不具有这样的保证。</p><p>2、初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序</p><p>在一个线程中，<strong>初次读对象引用与初次读该对象包含的</strong> <strong>final</strong> <strong>域</strong>，JMM禁止处理器重排序这两个操作。<strong>编译器会在读</strong> <strong>final</strong> <strong>域操作的前面插入一个</strong> <strong>LoadLoad</strong> <strong>屏障</strong>。</p><p>reader()方法包含3个步骤：</p><p>初次读引用变量obj</p><p>初次读引用变量obj指向对象的普通域 i</p><p>初次读引用变量obj指向对象的final域 j</p><p> 我们假设写线程A没有发生任何重排序，则下图是一种可能的时序：</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jna6ib52j309i07nq31.jpg" alt></p><p>读对象的普通域的操作被处理器重排序到读对象引用之前。读普通域时，该域还没有被线程A写入，所以上面的是一个错误的读取操作。但是读final域的重排序规则把读对象final域的操作“限定”在读对象引用之后，该final域已经被A线程初始化了，是一个正确的读取操作。</p><p>总结：读final域的重排序规则可以确保在读一个对象的final域之前，一定会先读包含这个final域的对象的引用。</p><h3 id="final域为引用类型"><a href="#final域为引用类型" class="headerlink" title="final域为引用类型"></a>final域为引用类型</h3><p>我们以代码cn.enjoyedu.ch9.semantics. FinalRefMemory来说明</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jnazkxp3j30i10fs759.jpg" alt></p><p>在上面的代码中，final域是一个引用类型，它引用了一个int类型的数组，对于引用类型，写final域的重排序规则对编译器和处理器增加了一下的约束：在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</p><p>我们假设线程A先执行write0操作，执行完后线程B执行write1操作，执行完后线程C执行reader操作，下图是一种可能的执行时序：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jnazaq8hj30gp0hp765.jpg" alt></p><p>1是对final域的写入，2是对这个final域引用的对象的成员域的写入，3是把被构造的对象的引用赋值给某个引用变量。这里除了前面提到的1不能和3重排序外，2和3也不能重排序。</p><p>JMM可以确保读线程C至少能看到写线程A在构造函数中对final引用对象的成员域的写入。即C至少能看到数组下标0的值为1。而写线程B对数组元素的写入，读线程C可能看得到，也可能看不到。JMM不保证线程B的写入对读线程C可见，因为写线程B和读线程C之间存在数据竞争，此时的执行结果不可预知。</p><p>如果想要确保读线程C看到写线程B对数组元素的写入，写线程B和读线程C之间需要使用同步（lock或volatile）来确保内存可见性。</p><h3 id="final引用不能从构造函数内逃逸"><a href="#final引用不能从构造函数内逃逸" class="headerlink" title="final引用不能从构造函数内逃逸"></a>final引用不能从构造函数内逃逸</h3><p>写final域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。其实，要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程所见，也就是对象引用不能在构造函数中逃逸。</p><p> 我们以cn.enjoyedu.ch9.semantics. FinalEscape为例来说明</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnaz4ujyj30ct0ciaag.jpg" alt></p><p>假设一个线程A执行writer()方法，另一个线程B执行reader()方法。这里的操作2使得对象还未完成构造前就为线程B可见。即使这里的操作2是构造函数的最后一步，且在程序中操作2排在操作1后面，执行read()方法的线程仍然可能无法看到final域被初始化后的值，因为这里的操作1和操作2之间可能被重排序。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jnbljlajj30o80jx76l.jpg" alt></p><p>因此在构造函数返回前，被构造对象的引用不能为其他线程所见，因为此时的final域可能还没有被初始化。</p><h3 id="final语义的实现"><a href="#final语义的实现" class="headerlink" title="final语义的实现"></a>final语义的实现</h3><p>会要求编译器在final域的写之后，构造函数return之前插入一个StoreStore障屏。</p><p>读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障</p><h2 id="锁的内存语义"><a href="#锁的内存语义" class="headerlink" title="锁的内存语义"></a>锁的内存语义</h2><p>当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。</p><p>当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。 </p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jnblfr4uj30ld071gmv.jpg" alt></p><p>如果我们回顾第一章的VolatileCase，我们知道，为了让子线程可以及时看到<em>ready</em>变量的修改，我们需要将ready变量以volatile来修饰。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jnblbvuwj30ln0cpaau.jpg" alt></p><p>但是，当我们将程序做如下改造</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jnc6f0n2j30hy0c90tj.jpg" alt></p><p>我们可以看见子线程同样可以中止，为何？我们观察System.out.println的实现，</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jnc6b2g3j309203ejr9.jpg" alt></p><p>结合前面锁的内存语义，我们可以知道，当进入<strong>synchronized</strong>语句块时，子线程会被强制从主内存中读取共享变量，其中就包括了ready变量，所以子线程同样中止了。</p><h2 id="synchronized的实现原理"><a href="#synchronized的实现原理" class="headerlink" title="synchronized的实现原理"></a>synchronized的实现原理</h2><p>Synchronized在JVM里的实现都是基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。</p><p>对同步块，MonitorEnter指令插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor的所有权，即尝试获得该对象的锁，而monitorExit指令则插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit。</p><p>对同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来实现，相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。</p><p>JVM就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。</p><p>synchronized使用的锁是存放在Java对象头里面，</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jnc66d26j30l303at9f.jpg" alt></p><p>具体位置是对象头里面的MarkWord，MarkWord里默认数据是存储对象的HashCode等信息，</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jncslqshj30l101twer.jpg" alt></p><p>但是会随着对象的运行改变而发生变化，不同的锁状态对应着不同的记录存储方式</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jncsiq68j30g7075wer.jpg" alt></p><h2 id="了解各种锁"><a href="#了解各种锁" class="headerlink" title="了解各种锁"></a>了解各种锁</h2><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。</p><p>但是线程自旋是需要消耗CPU的，说白了就是让CPU在做无用功，线程不能一直占用CPU自旋做无用功，所以需要设定一个自旋等待的最大时间。</p><p>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p><h4 id="自旋锁的优缺点"><a href="#自旋锁的优缺点" class="headerlink" title="自旋锁的优缺点"></a>自旋锁的优缺点</h4><p>自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起操作的消耗！</p><p>但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，占着XX不XX，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。</p><h4 id="自旋锁时间阈值"><a href="#自旋锁时间阈值" class="headerlink" title="自旋锁时间阈值"></a>自旋锁时间阈值</h4><p>自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋次数很重要</p><p>JVM对于自旋次数的选择，jdk1.5默认为10次，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。</p><p>JDK1.6中-XX:+UseSpinning开启自旋锁； JDK1.7后，去掉此参数，由jvm控制；</p><h3 id="锁的状态"><a href="#锁的状态" class="headerlink" title="锁的状态"></a>锁的状态</h3><p>一共有四种状态，<strong>无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态</strong>，它会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。</p><h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>引入背景：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁，减少不必要的CAS操作。</p><p>偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，减少加锁／解锁的一些CAS操作（比如等待队列的一些CAS操作），这种情况下，就会给线程加一个偏向锁。 如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</p><p>偏向锁获取过程：</p><p>步骤1、 访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</p><p>步骤2、 如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</p><p>步骤3、 如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</p><p>步骤4、 如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</p><p>步骤5、 执行同步代码。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jncsexotj30ku0octdm.jpg" alt></p><p>偏向锁的释放：</p><p>偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放偏向锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p><p>偏向锁的适用场景</p><p>始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作； </p><p>在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用。</p><p>jvm开启/关闭偏向锁</p><p>开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0</p><p>关闭偏向锁：-XX:-UseBiasedLocking</p><h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁； </p><p>轻量级锁的加锁过程：</p><p>在代码进入同步块的时候，如果同步对象锁状态为无锁状态且不允许进行偏向（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。</p><p>拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤4，否则执行步骤5。</p><p>如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态</p><p>如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，当竞争线程尝试占用轻量级锁失败多次之后，轻量级锁就会膨胀为重量级锁，重量级线程指针指向竞争线程，竞争线程也会阻塞，等待轻量级线程释放锁后唤醒他。锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jndhqd1cj30mg0lcwke.jpg" alt></p><h3 id="不同锁的比较"><a href="#不同锁的比较" class="headerlink" title="不同锁的比较"></a>不同锁的比较</h3><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jndhkklvj30hc0audgk.jpg" alt></p><h3 id="JDK对锁的更多优化措施"><a href="#JDK对锁的更多优化措施" class="headerlink" title="JDK对锁的更多优化措施"></a>JDK对锁的更多优化措施</h3><h4 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h4><p>如果证明一个对象不会逃逸方法外或者线程外，则可针对此变量进行优化：</p><p>同步消除synchronization Elimination，如果一个对象不会逃逸出线程，则对此变量的同步措施可消除。</p><h4 id="锁消除和粗化"><a href="#锁消除和粗化" class="headerlink" title="锁消除和粗化"></a>锁消除和粗化</h4><p>锁消除：虚拟机的运行时编译器在运行时如果检测到一些要求同步的代码上不可能发生共享数据竞争，则会去掉这些锁。</p><p>锁粗化：将临近的代码块用同一个锁合并起来。</p><p>消除无意义的锁获取和释放，可以提高程序运行性能。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;JMM基础-计算机原理&quot;&gt;&lt;a href=&quot;#JMM基础-计算机原理&quot; class=&quot;headerlink&quot; title=&quot;JMM基础-计算机原理&quot;&gt;&lt;/a&gt;JMM基础-计算机原理&lt;/h2&gt;&lt;p&gt;Java内存模型即Java Memory Model，简称JMM。J
      
    
    </summary>
    
      <category term="并发编程" scheme="https://ellenjack.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="多线程" scheme="https://ellenjack.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>并发安全</title>
    <link href="https://ellenjack.github.io/2019/06/20/thread-6/"/>
    <id>https://ellenjack.github.io/2019/06/20/thread-6/</id>
    <published>2019-06-20T14:44:57.000Z</published>
    <updated>2020-03-29T11:28:31.523Z</updated>
    
    <content type="html"><![CDATA[<p>如果多线程下使用这个类，不过多线程如何使用和调度这个类，这个类总是表示出正确的行为，这个类就是线程安全的。</p><p>类的线程安全表现为：</p><p>l  操作的原子性</p><p>l  内存的可见性</p><p>不做正确的同步，在多个线程之间共享状态的时候，就会出现线程不安全。</p><h1 id="怎么才能做到类的线程安全？"><a href="#怎么才能做到类的线程安全？" class="headerlink" title="怎么才能做到类的线程安全？"></a>怎么才能做到类的线程安全？</h1><h2 id="栈封闭"><a href="#栈封闭" class="headerlink" title="栈封闭"></a>栈封闭</h2><p>所有的变量都是在方法内部声明的，这些变量都处于栈封闭状态。</p><h2 id="无状态"><a href="#无状态" class="headerlink" title="无状态"></a>无状态</h2><p>没有任何成员变量的类，就叫无状态的类</p><h2 id="让类不可变"><a href="#让类不可变" class="headerlink" title="让类不可变"></a>让类不可变</h2><p>让状态不可变，两种方式：</p><p>1，加final关键字，对于一个类，所有的成员变量应该是私有的，同样的只要有可能，所有的成员变量应该加上final关键字，但是加上final，要注意如果成员变量又是一个对象时，这个对象所对应的类也要是不可变，才能保证整个类是不可变的。</p><p>2、根本就不提供任何可供修改成员变量的地方，同时成员变量也不作为方法的返回值</p><h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><p>保证类的可见性，最适合一个线程写，多个线程读的情景，</p><h2 id="加锁和CAS"><a href="#加锁和CAS" class="headerlink" title="加锁和CAS"></a>加锁和CAS</h2><h2 id="安全的发布"><a href="#安全的发布" class="headerlink" title="安全的发布"></a>安全的发布</h2><p>类中持有的成员变量，特别是对象的引用，如果这个成员对象不是线程安全的，通过get等方法发布出去，会造成这个成员对象本身持有的数据在多线程下不正确的修改，从而造成整个类线程不安全的问题。</p><h2 id="TheadLocal"><a href="#TheadLocal" class="headerlink" title="TheadLocal"></a>TheadLocal</h2><h2 id="Servlet"><a href="#Servlet" class="headerlink" title="Servlet"></a>Servlet</h2><p>不是线程安全的类，为什么我们平时没感觉到，：2、在需求上，很少有共享的需求，第二，接收到了请求，返回应答的时候，都是由一个线程来负责的。</p><h1 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h1><p>资源一定是多于1个，同时小于等于竞争的线程数，资源只有一个，只会产生激烈的竞争。</p><p>死锁的根本成因：<strong>获取锁的顺序不一致导致。</strong></p><h2 id="简单的"><a href="#简单的" class="headerlink" title="简单的"></a>简单的</h2><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn03d6ngj30xi04zweu.jpg" alt> <img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jn0392dyj30x504fq37.jpg" alt></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jn032ltqj30qk0fzdgx.jpg" alt></p><p>怀疑发送死锁：</p><p>通过jps 查询应用的 id，</p><p>再通过jstack id 查看应用的锁的持有情况</p><p><strong>解决办法：保证加锁的顺序性</strong></p><h3 id="动态的"><a href="#动态的" class="headerlink" title="动态的"></a>动态的</h3><p>动态顺序死锁，在实现时按照某种顺序加锁了，但是因为外部调用的问题，导致无法保证加锁顺序而产生的。</p><p>解决：</p><p>1、 通过内在排序，保证加锁的顺序性</p><p>2、 通过尝试拿锁，也可以。</p><h1 id="其他安全问题"><a href="#其他安全问题" class="headerlink" title="其他安全问题"></a>其他安全问题</h1><h2 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h2><p>尝试拿锁的机制中，发生多个线程之间互相谦让，不断发生拿锁，释放锁的过程。</p><p>解决办法：每个线程休眠随机数，错开拿锁的时间。</p><h2 id="线程饥饿"><a href="#线程饥饿" class="headerlink" title="线程饥饿"></a>线程饥饿</h2><p>低优先级的线程，总是拿不到执行时间</p><h1 id="性能和思考"><a href="#性能和思考" class="headerlink" title="性能和思考"></a>性能和思考</h1><p>使用并发的目标是为了提高性能，引入多线程后，其实会引入额外的开销，如线程之间的协调、增加的上下文切换，线程的创建和销毁，线程的调度等等。<strong>过度</strong>的使用和不恰当的使用，会导致多线程程序甚至比单线程还要低。</p><p>衡量应用的程序的性能：服务时间，延迟时间，吞吐量，可伸缩性等等，其中服务时间，延迟时间（多快），吞吐量（处理能力的指标，完成工作的多少）。多快和多少，完全独立，甚至是相互矛盾的。</p><p>对服务器应用来说：多少（可伸缩性，吞吐量）这个方面比多快更受重视。</p><p>我们做应用的时候：</p><p><strong>1、</strong> <strong>先保证程序正确，确实达不到要求的时候，再提高速度。（黄金原则）</strong></p><p><strong>2、</strong> <strong>一定要以测试为基准。</strong></p><p>一个应用程序里，串行的部分是永远都有的。</p><p>Amdahl定律  ：  1/(F+(1-N)/N)   F:必须被串行部分,程序最好的结果， 1/F。</p><h2 id="影响性能的因素"><a href="#影响性能的因素" class="headerlink" title="影响性能的因素"></a>影响性能的因素</h2><h3 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h3><p>是指CPU 从一个进程或线程切换到另一个进程或线程。一次上下文切换花费5000~10000个时钟周期，几微秒。在上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行。从这个角度来看，上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们需要记住每本书当前读到的页码。</p><p>上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。</p><h2 id="内存同步"><a href="#内存同步" class="headerlink" title="内存同步"></a>内存同步</h2><p>一般指加锁，对加锁来说，需要增加额外的指令，这些指令都需要刷新缓存等等操作。</p><h2 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h2><p>会导致线程挂起【挂起：挂起进程在操作系统中可以定义为暂时被淘汰出内存的进程，机器的资源是有限的，在资源不足的情况下，操作系统对在内存中的程序进行合理的安排，其中有的进程被暂时调离出内存，当条件允许的时候，会被操作系统再次调回内存，重新进入等待被执行的状态即就绪态，系统在超过一定的时间没有任何动作】。很明显这个操作包括两次额外的上下文切换。</p><h2 id="减少锁的竞争"><a href="#减少锁的竞争" class="headerlink" title="减少锁的竞争"></a>减少锁的竞争</h2><h3 id="减少锁的粒度"><a href="#减少锁的粒度" class="headerlink" title="减少锁的粒度"></a>减少锁的粒度</h3><p>使用锁的时候，锁所保护的对象是多个，当这些多个对象其实是独立变化的时候，不如用多个锁来一一保护这些对象。但是如果有同时要持有多个锁的业务方法，要注意避免发生死锁</p><h3 id="缩小锁的范围"><a href="#缩小锁的范围" class="headerlink" title="缩小锁的范围"></a>缩小锁的范围</h3><p>对锁的持有实现快进快出，尽量缩短持由锁的的时间。将一些<strong>与锁无关的代码</strong>移出锁的范围，特别是一些耗时，可能阻塞的操作</p><h4 id="避免多余的缩减锁的范围"><a href="#避免多余的缩减锁的范围" class="headerlink" title="避免多余的缩减锁的范围"></a>避免多余的缩减锁的范围</h4><p>两次加锁之间的语句非常简单，导致加锁的时间比执行这些语句还长，这个时候应该进行锁粗化—扩大锁的范围。</p><h3 id="锁分段"><a href="#锁分段" class="headerlink" title="锁分段"></a>锁分段</h3><p>ConcurrrentHashMap就是典型的锁分段。</p><h3 id="替换独占锁"><a href="#替换独占锁" class="headerlink" title="替换独占锁"></a>替换独占锁</h3><p>在业务允许的情况下：</p><p>1、 使用读写锁，</p><p>2、 用自旋CAS</p><p>3、 使用系统的并发容器</p><h1 id="线程安全的单例模式"><a href="#线程安全的单例模式" class="headerlink" title="线程安全的单例模式"></a>线程安全的单例模式</h1><h2 id="双重检查锁定"><a href="#双重检查锁定" class="headerlink" title="双重检查锁定"></a>双重检查锁定</h2><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jn119x2rj30ra0dit9t.jpg" alt></p><p>解决办法，加<strong>volatile</strong> <strong>关键字</strong></p><h2 id="解决之道"><a href="#解决之道" class="headerlink" title="解决之道"></a>解决之道</h2><h3 id="懒汉式"><a href="#懒汉式" class="headerlink" title="懒汉式"></a>懒汉式</h3><p>类初始化模式，也叫延迟占位模式。在单例类的内部由一个私有静态内部类来持有这个单例类的实例。</p><p>延迟占位模式还可以用在多线程下实例域的延迟赋值。</p><h3 id="饿汉式"><a href="#饿汉式" class="headerlink" title="饿汉式"></a>饿汉式</h3><p>在声明的时候就new这个类的实例，因为在JVM中，对类的加载和类初始化，由虚拟机保证线程安全。</p><p>或者使用枚举</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如果多线程下使用这个类，不过多线程如何使用和调度这个类，这个类总是表示出正确的行为，这个类就是线程安全的。&lt;/p&gt;
&lt;p&gt;类的线程安全表现为：&lt;/p&gt;
&lt;p&gt;l  操作的原子性&lt;/p&gt;
&lt;p&gt;l  内存的可见性&lt;/p&gt;
&lt;p&gt;不做正确的同步，在多个线程之间共享状态的时候，就
      
    
    </summary>
    
      <category term="并发编程" scheme="https://ellenjack.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="多线程" scheme="https://ellenjack.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>线程池</title>
    <link href="https://ellenjack.github.io/2019/06/20/thread-5/"/>
    <id>https://ellenjack.github.io/2019/06/20/thread-5/</id>
    <published>2019-06-20T14:31:21.000Z</published>
    <updated>2020-03-29T11:28:31.537Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是线程池？为什么要用线程池？"><a href="#什么是线程池？为什么要用线程池？" class="headerlink" title="什么是线程池？为什么要用线程池？"></a>什么是线程池？为什么要用线程池？</h1><p>1、 降低资源的消耗。降低线程创建和销毁的资源消耗；</p><p>2、 提高响应速度：线程的创建时间为T1，执行时间T2,销毁时间T3，免去T1和T3的时间</p><p>3、 提高线程的可管理性。</p><h1 id="JDK中的线程池和工作机制"><a href="#JDK中的线程池和工作机制" class="headerlink" title="JDK中的线程池和工作机制"></a>JDK中的线程池和工作机制</h1><h2 id="线程池的创建"><a href="#线程池的创建" class="headerlink" title="线程池的创建"></a>线程池的创建</h2><p>ThreadPoolExecutor，jdk所有线程池实现的父类</p><h3 id="各个参数含义"><a href="#各个参数含义" class="headerlink" title="各个参数含义"></a>各个参数含义</h3><p><strong>int</strong> corePoolSize  ：线程池中核心线程数，&lt; corePoolSize  ，就会创建新线程，= corePoolSize  ，这个任务就会保存到BlockingQueue，如果调用prestartAllCoreThreads（）方法就会一次性的启动corePoolSize  个数的线程。</p><p><strong>int</strong> maximumPoolSize, 允许的最大线程数，BlockingQueue也满了，&lt; maximumPoolSize时候就会再次创建新的线程</p><p><strong>long</strong> keepAliveTime, 线程空闲下来后，存活的时间，这个参数只在&gt; corePoolSize才有用</p><p>TimeUnit unit, 存活时间的单位值</p><p>BlockingQueue<runnable> workQueue, 保存任务的阻塞队列</runnable></p><p>ThreadFactory threadFactory, 创建线程的工厂，给新建的线程赋予名字</p><p>RejectedExecutionHandler handler ：饱和策略</p><p>AbortPolicy ：直接抛出异常，默认；</p><p>CallerRunsPolicy：用调用者所在的线程来执行任务</p><p>DiscardOldestPolicy：丢弃阻塞队列里最老的任务，队列里最靠前的任务</p><p>DiscardPolicy ：当前任务直接丢弃</p><p>实现自己的饱和策略，实现RejectedExecutionHandler接口即可</p><h2 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h2><p>execute(Runnable command)  不需要返回</p><p>Future<t> submit(Callable<t> task) 需要返回</t></t></p><h2 id="关闭线程池"><a href="#关闭线程池" class="headerlink" title="关闭线程池"></a>关闭线程池</h2><p>shutdown(),shutdownNow();</p><p>shutdownNow():设置线程池的状态，还会尝试停止正在运行或者暂停任务的线程</p><p>shutdown()设置线程池的状态，只会中断所有没有执行任务的线程</p><h2 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h2><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jmxm3wb1j30pl0dpjsl.jpg" alt></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmxlv3kdj30mh0m0gpr.jpg" alt></p><h1 id="合理配置线程池"><a href="#合理配置线程池" class="headerlink" title="合理配置线程池"></a>合理配置线程池</h1><p>根据任务的性质来：计算密集型（CPU），IO密集型，混合型</p><p>计算密集型：加密，大数分解，正则…….， 线程数适当小一点，最大推荐：机器的Cpu核心数+1，为什么+1，防止页缺失，(机器的Cpu核心=Runtime.<em>getRuntime</em>().availableProcessors();)</p><p>IO密集型：读取文件，数据库连接，网络通讯, 线程数适当大一点，机器的Cpu核心数*2,</p><p>混合型：尽量拆分，IO密集型&gt;&gt;计算密集型，拆分意义不大，IO密集型~计算密集型</p><p>队列的选择上，应该使用有界，无界队列可能会导致内存溢出，OOM</p><h1 id="预定义的线程池"><a href="#预定义的线程池" class="headerlink" title="预定义的线程池"></a>预定义的线程池</h1><h2 id="FixedThreadPool"><a href="#FixedThreadPool" class="headerlink" title="FixedThreadPool"></a>FixedThreadPool</h2><p>创建固定线程数量的，适用于负载较重的服务器，使用了无界队列</p><h2 id="SingleThreadExecutor"><a href="#SingleThreadExecutor" class="headerlink" title="SingleThreadExecutor"></a>SingleThreadExecutor</h2><p>创建单个线程，需要顺序保证执行任务，不会有多个线程活动，使用了无界队列</p><h2 id="CachedThreadPool"><a href="#CachedThreadPool" class="headerlink" title="CachedThreadPool"></a>CachedThreadPool</h2><p>会根据需要来创建新线程的，执行很多短期异步任务的程序，使用了SynchronousQueue</p><h2 id="WorkStealingPool（JDK7以后）"><a href="#WorkStealingPool（JDK7以后）" class="headerlink" title="WorkStealingPool（JDK7以后）"></a>WorkStealingPool（JDK7以后）</h2><p>基于ForkJoinPool实现</p><h2 id="ScheduledThreadPoolExecutor"><a href="#ScheduledThreadPoolExecutor" class="headerlink" title="ScheduledThreadPoolExecutor"></a>ScheduledThreadPoolExecutor</h2><p>需要定期执行周期任务，Timer不建议使用了。</p><p>newSingleThreadScheduledExecutor：只包含一个线程，只需要单个线程执行周期任务，保证顺序的执行各个任务</p><p>newScheduledThreadPool 可以包含多个线程的，线程执行周期任务，适度控制后台线程数量的时候</p><p>方法说明：</p><p>schedule：只执行一次，任务还可以延时执行</p><p>scheduleAtFixedRate：提交固定时间间隔的任务</p><p>scheduleWithFixedDelay：提交固定延时间隔执行的任务</p><p>两者的区别：</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jmxloga8j30re0cjaab.jpg" alt></p><p>scheduleAtFixedRate任务超时：</p><p>规定60s执行一次，有任务执行了80S，下个任务马上开始执行</p><p>第一个任务 时长 80s，第二个任务20s，第三个任务 50s</p><p>第一个任务第0秒开始，第80S结束；</p><p>第二个任务第80s开始，在第100秒结束；</p><p>第三个任务第120s秒开始，170秒结束</p><p>第四个任务从180s开始</p><p>参加代码：ScheduleWorkerTime类，执行效果如图：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jmybst9sj30pt0d4dgy.jpg" alt></p><p> 建议在提交给ScheduledThreadPoolExecutor的任务要住catch异常。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;什么是线程池？为什么要用线程池？&quot;&gt;&lt;a href=&quot;#什么是线程池？为什么要用线程池？&quot; class=&quot;headerlink&quot; title=&quot;什么是线程池？为什么要用线程池？&quot;&gt;&lt;/a&gt;什么是线程池？为什么要用线程池？&lt;/h1&gt;&lt;p&gt;1、 降低资源的消耗。降低线
      
    
    </summary>
    
      <category term="并发编程" scheme="https://ellenjack.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="多线程" scheme="https://ellenjack.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>并发容器</title>
    <link href="https://ellenjack.github.io/2019/06/20/thread-4/"/>
    <id>https://ellenjack.github.io/2019/06/20/thread-4/</id>
    <published>2019-06-20T13:40:13.000Z</published>
    <updated>2020-03-29T11:28:31.542Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h1><p>Hashmap多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。</p><p>HashTable使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。</p><p>putIfAbsent() ：没有这个值则放入map，有这个值则返回key本来对应的值。</p><h2 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h2><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p>散列，哈希：把任意长度的输入通过一种算法（散列），变换成为固定长度的输出，这个输出值就是散列值。属于压缩映射，容易产生哈希冲突。Hash算法有直接取余法等。</p><p>产生哈希冲突时解决办法：开放寻址；2、再散列；3、链地址法（相同hash值的元素用链表串起来）。</p><p>ConcurrentHashMap在发生hash冲突时采用了链地址法。</p><p>md4,md5,sha-hash算法也属于hash算法，又称摘要算法。</p><h3 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h3><p><strong>int</strong> <strong>类型的位</strong></p><p><strong>高位</strong>                                                                                                                      <strong>低位</strong></p><table><thead><tr><th>31</th><th>30</th><th>29</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th>5</th><th>4</th><th>3</th><th>2</th><th>1</th><th>0</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr></tbody></table><p>2的0次方 = 1，2的1次方=2…….，以上表格代表数字 （2的5次方+2的3次方）= 40</p><p>由上面的表格可以看出，数字类型在数字渐渐变大时，是由低位慢慢向高位扩展的。</p><p>Java实际保存int型时 正数  第31位 =0      负数：第31位=1</p><p>常用位运算有：</p><p>l  位与  &amp;  (1&amp;1=1       1&amp;0=0     0&amp;0=0)</p><p>l  位或  |   (1|1=1        1|0=1  0|0=0)</p><p>l  位非  ~  （ ~1=0       ~0=1）</p><p>l  位异或  ^   (1^1=0    1^0=1   0^0=0) </p><p>l  &lt;&lt;有符号左移     &gt;&gt;有符号的右移    &gt;&gt;&gt;无符号右移  例如：8 &lt;&lt; 2 = 32    8&gt;&gt;2 = 2</p><p>l  取模的操作 a % (Math.pow(2,n)) 等价于 a&amp;( Math.pow(2,n)-1)</p><p><strong>位运算适用</strong>：权限控制，物品的属性非常多时的保存</p><h2 id="1-7中原理和实现"><a href="#1-7中原理和实现" class="headerlink" title="1.7中原理和实现"></a>1.7中原理和实现</h2><h3 id="ConcurrentHashMap中的数据结构"><a href="#ConcurrentHashMap中的数据结构" class="headerlink" title="ConcurrentHashMap中的数据结构"></a>ConcurrentHashMap中的数据结构</h3><p>ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment实际继承自可重入锁（ReentrantLock），在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，每个Segment里包含一个HashEntry数组，我们称之为table，每个HashEntry是一个链表结构的元素。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfiojbmej30fu08g756.jpg" alt></p><p><strong>面试常问：</strong></p><p><strong>1、</strong> <strong>ConcurrentHashMap</strong> <strong>实现原理是怎么样的或者问ConcurrentHashMap</strong> <strong>如何在保证高并发下线程安全的同时实现了性能提升？</strong></p><p>答：ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了<strong>锁分离</strong>技术。它使用了多个锁来控制对hash表的不同部分进行的修改。内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hash table，只要多个修改操作发生在不同的段上，它们就可以并发进行。</p><h3 id="初始化做了什么事？"><a href="#初始化做了什么事？" class="headerlink" title="初始化做了什么事？"></a>初始化做了什么事？</h3><p>初始化有三个参数</p><p><strong>initialCapacity</strong>：初始容量大小 ，默认16。</p><p><strong>loadFactor,</strong> 扩容因子，默认0.75，当一个Segment存储的元素数量大于initialCapacity* loadFactor时，该Segment会进行一次扩容。</p><p><strong>concurrencyLevel</strong> 并发度，默认16。并发度可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。如果并发度设置的过小，会带来严重的锁竞争问题；如果并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。</p><p><strong>构造方法中部分代码解惑：</strong></p><p>1、</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfiogmarj30bv02j744.jpg" alt></p><p>保证Segment数组的大小，一定为2的幂，例如用户设置并发度为17，则实际Segment数组大小则为32</p><p>2、</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfioebfej30cs024745.jpg" alt></p><p>保证每个Segment中tabel数组的大小，一定为2的幂，初始化的三个参数取默认值时，table数组大小为2</p><p>3、</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfj6fvh7j30o504o3ys.jpg" alt></p><p>初始化Segment数组，并实际只填充Segment数组的第0个元素。</p><p>4、</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfj6cu4aj30br01d0sl.jpg" alt></p><p>用于定位元素所在segment。segmentShift表示偏移位数，通过前面的int类型的位的描述我们可以得知，int类型的数字在变大的过程中，低位总是比高位先填满的，为保证元素在segment级别分布的尽量均匀，计算元素所在segment时，总是取hash值的高位进行计算。segmentMask作用就是为了利用位运算中取模的操作：    a % (Math.pow(2,n)) 等价于 a&amp;( Math.pow(2,n)-1)</p><h3 id="在get和put操作中，是如何快速定位元素放在哪个位置的？"><a href="#在get和put操作中，是如何快速定位元素放在哪个位置的？" class="headerlink" title="在get和put操作中，是如何快速定位元素放在哪个位置的？"></a>在get和put操作中，是如何快速定位元素放在哪个位置的？</h3><p>对于某个元素而言，一定是放在某个segment元素的某个table元素中的，所以在定位上，</p><p><strong>定位segment</strong> <strong>：</strong>取得key的hashcode值进行一次再散列（通过Wang/Jenkins算法），拿到再散列值后，以再散列值的高位进行取模得到当前元素在哪个segment上。</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfj68s4lj30xk040mxw.jpg" alt></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfjskqhhj30mo09wdgj.jpg" alt></p><p>定位table：同样是取得key的再散列值以后，用再散列值的全部和table的长度进行取模，得到当前元素在table的哪个元素上。</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfjsh6xaj30ol037aa7.jpg" alt></p><h3 id="get（）方法"><a href="#get（）方法" class="headerlink" title="get（）方法"></a>get（）方法</h3><p>定位segment和定位table后，依次扫描这个table元素下的的链表，要么找到元素，要么返回null。</p><p><strong>在高并发下的情况下如何保证取得的元素是最新的？</strong></p><p>答：用于存储键值对数据的HashEntry，在设计上它的成员变量value等都是volatile类型的，这样就保证别的线程对value值的修改，get方法可以马上看到。</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfjsdqimj30gq03rjre.jpg" alt></p><h3 id="put-方法"><a href="#put-方法" class="headerlink" title="put()方法"></a>put()方法</h3><p>1、首先定位segment，当这个segment在map初始化后，还为null，由ensureSegment方法负责填充这个segment。</p><p>2、 对Segment 加锁</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfkako3sj30k402tmx7.jpg" alt></p><p>3、定位所在的table元素，并扫描table下的链表，<strong>找到时：</strong></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfkah4n4j30m70bt0tp.jpg" alt></p><p><strong>没有找到时：</strong></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfkackvsj30mn09o0tt.jpg" alt></p><h3 id="扩容操作"><a href="#扩容操作" class="headerlink" title="扩容操作"></a>扩容操作</h3><p>Segment 不扩容，扩容下面的table数组，每次都是将数组翻倍</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfkvqoffj30im04eglu.jpg" alt></p><p><strong>带来的好处</strong></p><p>假设原来table长度为4，那么元素在table中的分布是这样的：</p><table><thead><tr><th>Hash值</th><th>15</th><th>23</th><th>34</th><th>56</th><th>77</th></tr></thead><tbody><tr><td>在table中下标</td><td>3  = 15%4</td><td>3 = 23 % 4</td><td>2 = 34%4</td><td>0 = 56%4</td><td>1 = 77 % 4</td></tr></tbody></table><p>扩容后table长度变为8，那么元素在table中的分布变成：</p><table><thead><tr><th>Hash值</th><th>56</th><th></th><th>34</th><th></th><th></th><th>77</th><th></th><th>15,23</th></tr></thead><tbody><tr><td>下标</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td></tr></tbody></table><p>可以看见 hash值为34和56的下标保持不变，而15,23,77的下标都是在原来下标的基础上+4即可，可以快速定位和减少重排次数。</p><h3 id="size方法"><a href="#size方法" class="headerlink" title="size方法"></a>size方法</h3><p>size的时候进行两次不加锁的统计，两次一致直接返回结果，不一致，重新加锁再次统计</p><h3 id="弱一致性"><a href="#弱一致性" class="headerlink" title="弱一致性"></a>弱一致性</h3><p>get方法和containsKey方法都是通过对链表遍历判断是否存在key相同的节点以及获得该节点的value。但由于遍历过程中其他线程可能对链表结构做了调整，因此get和containsKey返回的可能是过时的数据，这一点是ConcurrentHashMap在弱一致性上的体现。</p><h2 id="1-8"><a href="#1-8" class="headerlink" title="1.8"></a>1.8</h2><h3 id="与1-7相比的重大变化"><a href="#与1-7相比的重大变化" class="headerlink" title="与1.7相比的重大变化"></a>与1.7相比的重大变化</h3><p>1、 取消了segment数组，直接用table保存数据，锁的粒度更小，减少并发冲突的概率。</p><p>2、 存储数据时采用了链表+红黑树的形式，纯链表的形式时间复杂度为O(n)，红黑树则为O（logn），性能提升很大。什么时候链表转红黑树？当key值相等的元素形成的链表中元素个数超过8个的时候。</p><h3 id="主要数据结构和关键变量"><a href="#主要数据结构和关键变量" class="headerlink" title="主要数据结构和关键变量"></a>主要数据结构和关键变量</h3><p>Node类存放实际的key和value值。</p><p>sizeCtl：</p><p>负数：表示进行初始化或者扩容,-1表示正在初始化，-N，表示有N-1个线程正在进行扩容</p><p>正数：0 表示还没有被初始化，&gt;0的数，初始化或者是下一次进行扩容的阈值</p><p>TreeNode 用在红黑树，表示树的节点, TreeBin是实际放在table数组中的，代表了这个红黑树的根。</p><h3 id="初始化做了什么事？-1"><a href="#初始化做了什么事？-1" class="headerlink" title="初始化做了什么事？"></a>初始化做了什么事？</h3><p>只是给成员变量赋值，put时进行实际数组的填充</p><h3 id="在get和put操作中，是如何快速定位元素放在哪个位置的？-1"><a href="#在get和put操作中，是如何快速定位元素放在哪个位置的？-1" class="headerlink" title="在get和put操作中，是如何快速定位元素放在哪个位置的？"></a>在get和put操作中，是如何快速定位元素放在哪个位置的？</h3><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfkvn261j30u60ct75t.jpg" alt></p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfkviq4kj30ny053glu.jpg" alt></p><h3 id="get（）方法-1"><a href="#get（）方法-1" class="headerlink" title="get（）方法"></a>get（）方法</h3><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfljlcocj30q30cbq3z.jpg" alt></p><h3 id="put-方法-1"><a href="#put-方法-1" class="headerlink" title="put()方法"></a>put()方法</h3><p>数组的实际初始化</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfljg8w3j30rv0dt3zp.jpg" alt></p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfljch3pj30r90fe75r.jpg" alt></p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfm3prkvj30mu07zt91.jpg" alt></p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfm3lptvj30lp075weo.jpg" alt></p><h3 id="扩容操作-1"><a href="#扩容操作-1" class="headerlink" title="扩容操作"></a>扩容操作</h3><p>transfer()方法进行实际的扩容操作，table大小也是翻倍的形式，有一个并发扩容的机制。</p><h3 id="size方法-1"><a href="#size方法-1" class="headerlink" title="size方法"></a>size方法</h3><p>估计的大概数量，不是精确数量</p><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>弱一致</p><h1 id="更多的并发容器"><a href="#更多的并发容器" class="headerlink" title="更多的并发容器"></a>更多的并发容器</h1><h2 id="ConcurrentSkipListMap-和-ConcurrentSkipListSet"><a href="#ConcurrentSkipListMap-和-ConcurrentSkipListSet" class="headerlink" title="ConcurrentSkipListMap  和 ConcurrentSkipListSet"></a>ConcurrentSkipListMap  和 ConcurrentSkipListSet</h2><p>TreeMap和TreeSet有序的容器，这两种容器的并发版本</p><h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p>SkipList，以空间换时间，在原链表的基础上形成多层索引，但是某个节点在插入时，是否成为索引，随机决定，所以跳表又称为概率数据结构。</p><h2 id="ConcurrentLinkedQueue"><a href="#ConcurrentLinkedQueue" class="headerlink" title="ConcurrentLinkedQueue"></a>ConcurrentLinkedQueue</h2><p>无界非阻塞队列，底层是个链表，遵循先进先出原则。</p><p>add,offer将元素插入到尾部，peek（拿头部的数据，但是不移除）和poll（拿头部的数据，但是移除）</p><h2 id="写时复制容器"><a href="#写时复制容器" class="headerlink" title="写时复制容器"></a>写时复制容器</h2><p>写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以写时复制容器也是一种读写分离的思想，读和写不同的容器。如果读的时候有多个线程正在向容器添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的，只能保证最终一致性。</p><p>适用读多写少的并发场景，常见应用：白名单/黑名单， 商品类目的访问和更新场景。</p><p>存在内存占用问题。</p><h1 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h1><h2 id="概念、生产者消费者模式"><a href="#概念、生产者消费者模式" class="headerlink" title="概念、生产者消费者模式"></a>概念、生产者消费者模式</h2><p>1)当队列满的时候，插入元素的线程被阻塞，直达队列不满。</p><p>2)队列为空的时候，获取元素的线程被阻塞，直到队列不空。</p><h3 id="生产者和消费者模式"><a href="#生产者和消费者模式" class="headerlink" title="生产者和消费者模式"></a>生产者和消费者模式</h3><p>生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这种生产消费能力不均衡的问题，便有了生产者和消费者模式。生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过阻塞队列来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。</p><h2 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h2><table><thead><tr><th>方法</th><th>抛出异常</th><th>返回值</th><th>一直阻塞</th><th>超时退出</th></tr></thead><tbody><tr><td>插入方法</td><td>add</td><td>offer</td><td>put</td><td>Offer(time)</td></tr><tr><td>移除方法</td><td>remove</td><td>poll</td><td>take</td><td>Poll(time)</td></tr><tr><td>检查方法</td><td>element</td><td>peek</td><td>N/A</td><td>N/A</td></tr></tbody></table><p>l  <strong>抛出异常</strong>：当队列满时，如果再往队列里插入元素，会抛出IllegalStateException（”Queuefull”）异常。当队列空时，从队列里获取元素会抛出NoSuchElementException异常。</p><p>l  <strong>返回特殊值</strong>：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回null。</p><p>l  <strong>一直阻塞</strong>：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到队列可用或者响应中断退出。当队列空时，如果消费者线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。</p><p>l  <strong>超时退出</strong>：当阻塞队列满时，如果生产者线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，生产者线程就会退出。</p><h2 id="常用阻塞队列"><a href="#常用阻塞队列" class="headerlink" title="常用阻塞队列"></a>常用阻塞队列</h2><p>·<strong>ArrayBlockingQueue</strong>：一个由数组结构组成的有界阻塞队列。</p><p>按照先进先出原则，要求设定初始大小</p><p>·<strong>LinkedBlockingQueue</strong>：一个由链表结构组成的有界阻塞队列。</p><p>按照先进先出原则，可以不设定初始大小，Integer.Max_Value</p><p><strong>ArrayBlockingQueue</strong> <strong>和LinkedBlockingQueue</strong> <strong>不同：</strong></p><p>l  锁上面：ArrayBlockingQueue只有一个锁，LinkedBlockingQueue用了两个锁，</p><p>l  实现上：ArrayBlockingQueue直接插入元素，LinkedBlockingQueue需要转换。</p><p>·<strong>PriorityBlockingQueue</strong>：一个支持优先级排序的无界阻塞队列。</p><p>默认情况下，按照自然顺序，要么实现compareTo()方法，指定构造参数Comparator</p><p>·<strong>DelayQueue</strong>：一个使用优先级队列实现的无界阻塞队列。</p><p>支持延时获取的元素的阻塞队列，元素必须要实现Delayed接口。适用场景：实现自己的缓存系统，订单到期，限时支付等等。</p><p>·<strong>SynchronousQueue</strong>：一个不存储元素的阻塞队列。</p><p>每一个put操作都要等待一个take操作</p><p>·<strong>LinkedTransferQueue</strong>：一个由链表结构组成的无界阻塞队列。</p><p>transfer()，必须要消费者消费了以后方法才会返回，tryTransfer()无论消费者是否接收，方法都立即返回。</p><p>·<strong>LinkedBlockingDeque</strong>：一个由链表结构组成的双向阻塞队列。</p><p>可以从队列的头和尾都可以插入和移除元素，实现工作密取，方法名带了First对头部操作，带了last从尾部操作，另外：add=addLast;       remove=removeFirst;    take=takeFirst</p><h2 id="阻塞队列的实现原理"><a href="#阻塞队列的实现原理" class="headerlink" title="阻塞队列的实现原理"></a>阻塞队列的实现原理</h2><p>比如，ArrayBlockingQueue就是基于Lock和Condition实现的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ConcurrentHashMap&quot;&gt;&lt;a href=&quot;#ConcurrentHashMap&quot; class=&quot;headerlink&quot; title=&quot;ConcurrentHashMap&quot;&gt;&lt;/a&gt;ConcurrentHashMap&lt;/h1&gt;&lt;p&gt;Hashmap多线程
      
    
    </summary>
    
      <category term="并发编程" scheme="https://ellenjack.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="多线程" scheme="https://ellenjack.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>docker进阶</title>
    <link href="https://ellenjack.github.io/2019/03/05/docker-2/"/>
    <id>https://ellenjack.github.io/2019/03/05/docker-2/</id>
    <published>2019-03-05T05:48:53.000Z</published>
    <updated>2020-03-25T16:12:24.794Z</updated>
    
    <content type="html"><![CDATA[<h1 id="仓库使用"><a href="#仓库使用" class="headerlink" title="仓库使用"></a><strong>仓库使用</strong></h1><h2 id="docker官方仓库"><a href="#docker官方仓库" class="headerlink" title="docker官方仓库"></a><strong>docker官方仓库</strong></h2><h3 id="注册"><a href="#注册" class="headerlink" title="注册"></a><strong>注册</strong></h3><p><a href="https://hub.docker.com" target="_blank" rel="noopener">https://hub.docker.com</a></p><p>自由注册，邮件激活即可使用</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jf80y1zjj30an05ewf0.jpg" alt></p><h3 id="命令使用"><a href="#命令使用" class="headerlink" title="命令使用"></a><strong>命令使用</strong></h3><p>Docker  pull/search/login/push/tag</p><p>tag [镜像名：版本]  [仓库]/[镜像名：版本]：标记本地镜像，将其归入某一仓库</p><p>Push [仓库]/[镜像名：版本]: 推送镜像到仓库  –需要登陆 </p><p>Search [镜像名]：在仓库中查询镜像 – 无法查询到tag版本 </p><p>Pull [镜像名：版本]： 下载镜像到本地 </p><p>Login：登陆仓库 </p><p>1、命令登陆dockerhub</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jf80n6p5j30b602xwff.jpg" alt></p><p>2、再使用tag命令标记一个镜像，指定自己的仓库</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jf80jt87j30fe047q4s.jpg" alt></p><p>3、使用push命令推送此镜像到仓库里</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jf8c9oanj30fe01igm5.jpg" alt></p><p>4、打开查询自己仓库的镜像</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jf8c67l3j308405674g.jpg" alt></p><h2 id="私有仓库"><a href="#私有仓库" class="headerlink" title="私有仓库"></a><strong>私有仓库</strong></h2><h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a><strong>搭建</strong></h3><p>下载registry镜像：docker pull registry</p><p>—–可配置加速器加速下载 </p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jf8c3w87j30fe02fwf3.jpg" alt></p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a><strong>启动</strong></h3><p>docker run -d –name reg -p 5000:5000 registry</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jf8nl5a3j30fe01idga.jpg" alt></p><p>然后可以通过restful接口查看仓库中的镜像（当前仓库是空的）</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jf8niq5tj30fe01jdgd.jpg" alt></p><h3 id="配置http传输"><a href="#配置http传输" class="headerlink" title="配置http传输"></a><strong>配置http传输</strong></h3><p>私服默认只能使用https，需要配置开放http</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jf8nfacnj30fe039wfg.jpg" alt></p><p>配置完毕重启下docker服务</p><p>systemctl daemon-reload </p><p>systemctl restart docker</p><h3 id="私服仓库推送镜像"><a href="#私服仓库推送镜像" class="headerlink" title="私服仓库推送镜像"></a><strong>私服仓库推送镜像</strong></h3><p>docker tag hello-world <a href="http://192.168.244.5:5000/hello-world" target="_blank" rel="noopener">http://192.168.244.7:5000/hello-world</a> </p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jf942rrej30fe01adge.jpg" alt></p><p>docker push 192.168.244.7:5000/hello-world</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jf940krxj30fe01mmxx.jpg" alt></p><p>查询镜像：<a href="http://192.168.244.5:5000/v2/_catalog" target="_blank" rel="noopener">http://192.168.244.5:5000/v2/_catalog</a>   </p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jf93vbhuj30fe01b0t5.jpg" alt></p><p>查询hello版本：      <a href="http://192.168.244.5:5000/v2/hello/tags/list" target="_blank" rel="noopener">http://192.168.244.5:5000/v2/hello/tags/list</a> </p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jf9wosjwj30fe014aaf.jpg" alt></p><h2 id="commit镜像并上传仓库"><a href="#commit镜像并上传仓库" class="headerlink" title="commit镜像并上传仓库"></a><strong>commit镜像并上传仓库</strong></h2><h3 id="创建一个centos容器："><a href="#创建一个centos容器：" class="headerlink" title="创建一个centos容器："></a><strong>创建一个centos容器：</strong></h3><p>启动后自动进入此容器</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jf9wkh7zj30fe00yaac.jpg" alt></p><h3 id="容器内安装nginx服务："><a href="#容器内安装nginx服务：" class="headerlink" title="容器内安装nginx服务："></a><strong>容器内安装nginx服务：</strong></h3><p>添加一下nginx源：</p><p>rpm -ivh <a href="http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm" target="_blank" rel="noopener">http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm</a></p><p>yum search nginx    ##搜索一下看看</p><p>yum install nginx -y    ## 安装</p><p>启动nginx服务</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jf9when6j30fe01w74x.jpg" alt></p><p>ctrl +P+Q退出容器，在主机环境内校验nginx请求，正常得到欢迎页</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfa98umwj30fe0av77m.jpg" alt></p><h3 id="commit服务为一个nginx镜像"><a href="#commit服务为一个nginx镜像" class="headerlink" title="commit服务为一个nginx镜像"></a><strong>commit服务为一个nginx镜像</strong></h3><p>现在要将cent容器提交成为一个镜像，命令如下：</p><p>docker commit cent cent-ng:v1</p><p>可看到得到了新的镜像cent-ng:v1</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfa93yjzj30fe02xwfj.jpg" alt></p><h3 id="启动此nginx镜像"><a href="#启动此nginx镜像" class="headerlink" title="启动此nginx镜像"></a><strong>启动此nginx镜像</strong></h3><p>1、使用新建的镜像创建容器，并进入查看，发现已安装有nginx，但nginx并未启动</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfa8zdifj30fe01lt99.jpg" alt></p><p>容器内启动nginx服务，并退出容器。在主机方校验，nginx欢迎页面出现</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfatefp0j30fe06a0u9.jpg" alt></p><p>2、现在我们希望启动容器时，直接启动nginx服务，怎么做？</p><p>docker run -d –name ngx3 cent-ng:v1  /usr/sbin/nginx  -g  “daemon off;”</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfat9s86j30fe01c3yt.jpg" alt></p><p>可看到，容器内nginx服务也已正常运行</p><p>ps:后面运行的命令都是容器命令，由于nginx命令没有设置到path中，所以全路径启动，</p><p>而nginx -g这个参数是指可以在外面添加指令到nginx的配置文件中，</p><p>daemon off是指nginx服务不运行在后端，而是在前台运行（container中的服务必须运行在前台）</p><h2 id="commit创建镜像方式的本质"><a href="#commit创建镜像方式的本质" class="headerlink" title="commit创建镜像方式的本质"></a><strong>commit创建镜像方式的本质</strong></h2><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfat76q8j30fe05p3zc.jpg" alt></p><p>原容器与commit后的镜像，在文件系统上并无区别。只是把容器层原来的可写属性，置成了只读。于是变成了一个不可改的镜像</p><h1 id="数据管理"><a href="#数据管理" class="headerlink" title="数据管理"></a><strong>数据管理</strong></h1><p>docker容器运行，产生一些数据/文件/等等持久化的东西，不应该放在容器内部。应当以挂载的形式存在主机文件系统中。</p><h2 id="docker的文件系统"><a href="#docker的文件系统" class="headerlink" title="docker的文件系统"></a><strong>docker的文件系统</strong></h2><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfb923bej30fe04c3zb.jpg" alt></p><p>\1. 镜像与容器读写层，通过联合文件系统，组成系统文件视角</p><p>\2. 容器服务运行中，一定会生成数据</p><p>\3. 容器只是运行态的服务器，是瞬时的，不承载数据的持久功能</p><h2 id="volume文件挂载的探究"><a href="#volume文件挂载的探究" class="headerlink" title="volume文件挂载的探究"></a><strong>volume文件挂载的探究</strong></h2><p>1、volume参数创建容器数据卷</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfb8xcbaj30fe00hwej.jpg" alt></p><p>2、我们通过docker inspect data查看容器元数据，可看到挂载信息</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfb8uxusj30b700st8s.jpg" alt></p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfbmc3hfj30fe03nt9f.jpg" alt></p><p>3、在容器端添加一个文件</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfbm9pxzj30f004qmym.jpg" alt></p><p>回主机目录查看，果然存在此文件：</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfbm5egej30fe00xt8x.jpg" alt></p><p>4、在主机方添加一个文件</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfbx34d5j30fe00c0sr.jpg" alt></p><p>回容器里查看，果然也同步增加了此文件</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfbx0d68j30db03pmyi.jpg" alt></p><p>5、指定主机目录方式挂载文件</p><p>格式：-v path1：path2</p><p>如下命令，容器方会自动增加一个data目录</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfbwx7f7j30fe03m3ze.jpg" alt></p><p>宿主机方，同样自动增加一个/opt/data目录</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfcch0hnj30fe014t8v.jpg" alt></p><h2 id="volumes-from引用数据卷"><a href="#volumes-from引用数据卷" class="headerlink" title="volumes-from引用数据卷"></a><strong>volumes-from引用数据卷</strong></h2><p>新启一容器，引入上一步的data容器目录</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4jfccec9fj30fe00nq34.jpg" alt></p><p>自动得到同一个目录，内容与data容器里挂载一样</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfccbyw8j30e3028t9e.jpg" alt></p><h2 id="备份-恢复数据卷"><a href="#备份-恢复数据卷" class="headerlink" title="备份/恢复数据卷"></a><strong>备份/恢复数据卷</strong></h2><p>备份：docker run –rm –volumes-from data -v $(pwd):/backup centos tar cvf /backup/data.tar /opt/data</p><p>恢复：docker run –rm –volumes-from data -v $(pwd):/backup centos tar xvf /backup/data.tar -C /</p><p>释义：</p><p>docker  run –rm —– 启动一个新的容器，执行完毕删除</p><p>–volumes-from data ——- data容器中挂载卷</p><p>-v $(pwd):/backup   ——–挂载当前目录到容器中为backup</p><p>cvf /backup/data.tar /opt/data ——— 备份/opt/data目录（即卷中所有的数据）为data.tar</p><p>xvf /backup/data.tar -C /  ———- 解压data.tar 到根目录/ ，因tar归档中已包含了/opt/data路径</p><h2 id="删除数据卷："><a href="#删除数据卷：" class="headerlink" title="删除数据卷："></a><strong>删除数据卷：</strong></h2><p>docker rm -v data</p><h1 id="Dockerfile使用"><a href="#Dockerfile使用" class="headerlink" title="Dockerfile使用"></a><strong>Dockerfile使用</strong></h1><h2 id="dockerfile方式创建容器"><a href="#dockerfile方式创建容器" class="headerlink" title="dockerfile方式创建容器"></a><strong>dockerfile方式创建容器</strong></h2><p>最简单的dockerfile</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfcrbmk5j30fe0323z2.jpg" alt></p><p>创建镜像</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfcr84xdj30fe06jgns.jpg" alt></p><p>使用此镜像运行一个容器</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfcr1z2kj30f401aglu.jpg" alt></p><h3 id="dockerfile基本要素"><a href="#dockerfile基本要素" class="headerlink" title="dockerfile基本要素"></a><strong>dockerfile基本要素</strong></h3><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfdaok9cj30fe08i0w4.jpg" alt></p><h3 id="dockerfile指令"><a href="#dockerfile指令" class="headerlink" title="dockerfile指令"></a><strong>dockerfile指令</strong></h3><h4 id="FROM："><a href="#FROM：" class="headerlink" title="FROM："></a><strong>FROM：</strong></h4><p>　　FROM {base镜像}</p><p>　　必须放在DOckerfile的第一行，表示从哪个baseimage开始构建 </p><h4 id="MAINTAINER："><a href="#MAINTAINER：" class="headerlink" title="MAINTAINER："></a><strong>MAINTAINER：</strong></h4><p>可选的，用来标识image作者的地方</p><h4 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a><strong>RUN</strong></h4><p>RUN都是启动一个容器、执行命令、然后提交存储层文件变更。</p><p>第一层 RUN command1 的执行仅仅是当前进程，一个内存上的变化而已，其结果不会造成任何文件。</p><p>而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。</p><p>而如果需要将两条命令或者多条命令联合起来执行需要加上&amp;&amp;。</p><p>如：cd /usr/local/src &amp;&amp; wget xxxxxxx</p><h4 id="CMD："><a href="#CMD：" class="headerlink" title="CMD："></a><strong>CMD：</strong></h4><p>　　CMD的作用是作为执行container时候的默认行为（容器默认的启动命令）</p><p>　　当运行container的时候声明了command，则不再用image中的CMD默认所定义的命令</p><p>一个Dockerfile中只能有一个有效的CMD，当定义多个CMD的时候，只有最后一个才会起作用</p><h4 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a><strong>EXPOSE</strong></h4><p>EXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。</p><h4 id="entrypoint："><a href="#entrypoint：" class="headerlink" title="entrypoint："></a><strong>entrypoint：</strong></h4><p>entrypoint的作用是，把整个container变成可执行的文件，且不能够通过替换CMD的方法来改变创建container的方式。但是可以通过参数传递的方法影响到container内部</p><p>每个Dockerfile只能够包含一个entrypoint，多个entrypoint只有最后一个有效</p><p>当定义了entrypoint以后，CMD只能够作为参数进行传递</p><h4 id="ADD-amp-COPY："><a href="#ADD-amp-COPY：" class="headerlink" title="ADD &amp; COPY："></a><strong>ADD &amp; COPY：</strong></h4><p>　　把host上的文件或者目录复制到image中（能够进行自动解压压缩包）　 </p><h4 id="ENV："><a href="#ENV：" class="headerlink" title="ENV："></a><strong>ENV：</strong></h4><p>　　用来设置环境变量，后续的RUN可以使用它所创建的环境变量 </p><h4 id="WORKDIR："><a href="#WORKDIR：" class="headerlink" title="WORKDIR："></a><strong>WORKDIR：</strong></h4><p>　　用来指定当前工作目录（或者称为当前目录） </p><h4 id="USER："><a href="#USER：" class="headerlink" title="USER："></a><strong>USER：</strong></h4><p>　　运行RUN指令的用户 </p><h4 id="VOLUME："><a href="#VOLUME：" class="headerlink" title="VOLUME："></a><strong>VOLUME：</strong></h4><p>　　用来创建一个在image之外的mount point</p><h3 id="nginx镜像制作实战"><a href="#nginx镜像制作实战" class="headerlink" title="nginx镜像制作实战"></a><strong>nginx镜像制作实战</strong></h3><h4 id="编译-安装nginx"><a href="#编译-安装nginx" class="headerlink" title="编译/安装nginx"></a><strong>编译/安装nginx</strong></h4><p>mkdir一个目录，在此目录内下载nginx源码包</p><p>wget  <a href="http://nginx.org/download/nginx-1.13.2.tar.gz" target="_blank" rel="noopener">http://nginx.org/download/nginx-1.13.2.tar.gz</a></p><p>并创建一个Dockerfile文件，文件内制作一系列nginx的编译安装流程，内容如文件：</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfdaj4wjj30fe08l0w6.jpg" alt></p><p>其中，每一个RUN就是增加一个镜像层文件，一层层的RUN命令最终形成一系列镜像层</p><p>运行build指令（注意最后的.代表当前路径），制作镜像</p><p>docker build -t cent-ngx2  .</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfdaelrcj30fe045dhl.jpg" alt></p><p>我们查看一下这个镜像的层次历史</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfdno3lwj30fe03bjsx.jpg" alt></p><p>可看到，此镜像层基本与dockerfile文件的RUN是一一对应的</p><p>使用制作的nginx镜像，创建一个容器。</p><p>因此镜像无前台命令，因为必须指定启动命令 ：/usr/local/nginx/sbin/nginx -g “daemon off;”</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfdnkr54j30fe02caar.jpg" alt></p><h4 id="为镜像指定环境变量，挂载目录，默认启动命令"><a href="#为镜像指定环境变量，挂载目录，默认启动命令" class="headerlink" title="为镜像指定环境变量，挂载目录，默认启动命令"></a><strong>为镜像指定环境变量，挂载目录，默认启动命令</strong></h4><p>在上一版镜像的基础上，我们新加配置</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4jfdngzdwj30fe04k0tt.jpg" alt></p><p>执行：docker build -t cent-ngx3  .</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4jfe1dbcej30eo05sgol.jpg" alt></p><p>查看镜像的历史，可看到比ngx2的镜像多了几个层</p><p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4jfe194myj30fe04sacu.jpg" alt></p><p>ngx3的镜像创建容器，已经不需要再指定cmd命令了</p><p>可执行命令自行校验：docker run -d –name ng2 cent-ngx3</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;仓库使用&quot;&gt;&lt;a href=&quot;#仓库使用&quot; class=&quot;headerlink&quot; title=&quot;仓库使用&quot;&gt;&lt;/a&gt;&lt;strong&gt;仓库使用&lt;/strong&gt;&lt;/h1&gt;&lt;h2 id=&quot;docker官方仓库&quot;&gt;&lt;a href=&quot;#docker官方仓库&quot; class=
      
    
    </summary>
    
      <category term="工具" scheme="https://ellenjack.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="docker" scheme="https://ellenjack.github.io/categories/%E5%B7%A5%E5%85%B7/docker/"/>
    
    
      <category term="docker" scheme="https://ellenjack.github.io/tags/docker/"/>
    
  </entry>
  
</feed>
